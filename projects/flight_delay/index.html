<!DOCTYPE html>
<html lang="en">
<head>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-7REHTK4CJ8"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-7REHTK4CJ8');
    </script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;600;700&display=swap" rel="stylesheet">    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/devicons/devicon@latest/devicon.min.css">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="icon" type="image/png" href="/chadvo-ds-website/assets/img/favicon.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/chadvo-ds-website/assets/img/favicon.png">

    <link rel="stylesheet" href="../../css/style.css">

    <style>
        /* FIX: Push content down so it doesn't hide behind the fixed header */
        body { padding-top: 90px; }

        /* Class Imbalance Chart Styles */
        .imbalance-chart-wrapper {
            background: white;
            padding: 40px;
            border-radius: 12px;
            box-shadow: 0 2px 12px rgba(0,0,0,0.08);
            max-width: 100%;
        }
        .chart-header { margin-bottom: 10px; }
        .chart-title {
            font-size: 18px;
            font-weight: 600;
            color: #1a1a1a;
            margin-bottom: 4px;
        }
        .chart-subtitle {
            font-size: 13px;
            color: #666;
            margin: 0;
        }
        .chart-legend {
            display: flex;
            gap: 24px;
            margin: 30px 0;
            font-size: 13px;
        }
        .legend-item {
            display: flex;
            align-items: center;
            gap: 8px;
        }
        .legend-color {
            width: 16px;
            height: 16px;
            border-radius: 2px;
        }
        .chart-inner {
            position: relative;
            padding-left: 0px;  /* Changed from 60px */
            padding-top: 40px;
            padding-bottom: 60px;
        }
        .y-axis-container {
            position: absolute;
            left: 0;
            top: 40px;
            bottom: 60px;
            width: 20px;  /* Changed from 60px */
            display: flex;
            align-items: center;
        }
        .y-axis-line {
            position: absolute;
            right: 0;
            top: 0;
            bottom: 0;
            width: 1px;
            background: #ddd;
        }
        .y-axis-label {
            position: absolute;
            left: 50%;
            top: 50%;
            transform: translateX(-50%) translateY(-50%) rotate(-90deg);
            font-size: 12px;
            color: #666;
            white-space: nowrap;
        }
        .y-ticks {
            position: absolute;
            right: 5px;
            top: 0;
            bottom: 0;
            width: 40px;
        }
        .y-ticks span {
            position: absolute;
            right: 0;
            font-size: 11px;
            color: #666;
            text-align: right;
        }
        .chart-area {
            position: relative;
            height: 400px;
        }
        .grid-lines {
            position: absolute;
            left: 0;
            right: 0;
            top: 0;
            bottom: 0;
            pointer-events: none;
        }
        .grid-lines div {
            position: absolute;
            left: 0;
            right: 0;
            height: 1px;
            background: #e8e8e8;
        }
        .x-axis-line {
            position: absolute;
            left: 0;
            right: 0;
            bottom: 0;
            height: 1px;
            background: #ddd;
        }
        .bars-container {
            position: absolute;
            left: 0;
            right: 0;
            bottom: 0;
            top: 0;
            display: flex;
            gap: 60px;
        }
        .bar-group {
            flex: 1;
            display: flex;
            flex-direction: column;
            position: relative;
            height: 100%;
        }
        .bars {
            position: absolute;
            left: 0;
            right: 0;
            bottom: 0;
            display: flex;
            gap: 12px;
            justify-content: center;
            height: 100%;
        }
        .bar {
            width: 45%;
            position: absolute;
            bottom: 0;
        }
        .bar:first-child { left: 0; }
        .bar:last-child { right: 0; }
        .bar-class0 .bar-fill { background: #4a7ba7; }
        .bar-class1 .bar-fill { background: #8fb3d1; }
        .bar-fill {
            width: 100%;
            height: 100%;
            transform-origin: bottom;
            transform: scaleY(0);
            transition: transform 1.5s ease-out;
        }
        .bar-label {
            position: absolute;
            top: -22px;
            left: 50%;
            transform: translateX(-50%);
            font-size: 12px;
            font-weight: 600;
            color: #1a1a1a;
            white-space: nowrap;
            opacity: 0;
            transition: opacity 0.5s ease-out;
        }
        .dataset-label {
            position: absolute;
            bottom: -40px;
            left: 50%;
            transform: translateX(-50%);
            font-size: 13px;
            color: #1a1a1a;
            text-align: center;
            white-space: nowrap;
        }
        #classImbalanceChart.animate .bar-group:nth-child(1) .bar:nth-child(1) .bar-fill {
            transform: scaleY(1);
            transition-delay: 0s;
        }
        #classImbalanceChart.animate .bar-group:nth-child(1) .bar:nth-child(2) .bar-fill {
            transform: scaleY(1);
            transition-delay: 0.1s;
        }
        #classImbalanceChart.animate .bar-group:nth-child(2) .bar:nth-child(1) .bar-fill {
            transform: scaleY(1);
            transition-delay: 0.2s;
        }
        #classImbalanceChart.animate .bar-group:nth-child(2) .bar:nth-child(2) .bar-fill {
            transform: scaleY(1);
            transition-delay: 0.3s;
        }
        #classImbalanceChart.animate .bar-group:nth-child(3) .bar:nth-child(1) .bar-fill {
            transform: scaleY(1);
            transition-delay: 0.4s;
        }
        #classImbalanceChart.animate .bar-group:nth-child(3) .bar:nth-child(2) .bar-fill {
            transform: scaleY(1);
            transition-delay: 0.5s;
        }

        /* Animate labels with delays matching bars */
        #classImbalanceChart.animate .bar-group:nth-child(1) .bar:nth-child(1) .bar-label {
            opacity: 1;
            transition-delay: 0.9s;
        }
        #classImbalanceChart.animate .bar-group:nth-child(1) .bar:nth-child(2) .bar-label {
            opacity: 1;
            transition-delay: 1.1s;
        }
        #classImbalanceChart.animate .bar-group:nth-child(2) .bar:nth-child(1) .bar-label {
            opacity: 1;
            transition-delay: 1.3s;
        }
        #classImbalanceChart.animate .bar-group:nth-child(2) .bar:nth-child(2) .bar-label {
            opacity: 1;
            transition-delay: 1.5s;
        }
        #classImbalanceChart.animate .bar-group:nth-child(3) .bar:nth-child(1) .bar-label {
            opacity: 1;
            transition-delay: 1.7s;
        }
        #classImbalanceChart.animate .bar-group:nth-child(3) .bar:nth-child(2) .bar-label {
            opacity: 1;
            transition-delay: 1.9s;
        }
        #classImbalanceChart.animate .bar-label { opacity: 1; }
        
        .dark-mode .imbalance-chart-wrapper { background: #1a1a1a; }
        .dark-mode .chart-title,
        .dark-mode .bar-label,
        .dark-mode .dataset-label { color: #e8e8e8; }
        .dark-mode .chart-subtitle,
        .dark-mode .y-axis-label,
        .dark-mode .y-ticks span { color: #999; }
        
        /* Modal & Caption Styles */
        #imageModal {
            display: none; 
            position: fixed;
            z-index: 1000;
            left: 0;
            top: 0;
            width: 100%;
            height: 100%;
            background-color: rgba(0,0,0,0.9);
        }

        #imageModal.active {
            display: flex !important;    
            flex-direction: column;      
            justify-content: center;     
            align-items: center;         
        }

        .image-modal-close {
            position: absolute;
            top: 20px;
            right: 35px;
            z-index: 1001; 
        }

        .image-modal-content {
            margin: 0 auto 15px auto;  
            display: block;
            max-width: 90%;
            max-height: 80vh;
        }

        #caption {
            margin: 0 auto;       
            height: auto;         
            display: block;
            width: 80%;
            max-width: 700px;
            text-align: center;
            color: #ccc;
            padding: 5px 0;
            font-family: 'Montserrat', sans-serif;
            font-size: 16px;
            animation-name: zoom;
            animation-duration: 0.6s;
        }

        /* Ensure the caption text shrinks on smaller screens */
        @media only screen and (max-width: 700px){
            #caption {
                width: 100%;
                font-size: 14px;
            }
        }
    </style>
</head>
<body data-page="flight_delay">

    <header id="stickyHeader" class="sticky-header"></header>

    <section class="container text-center mt-4 mb-5">
        <h1 class="display-4 fw-bold hero-name">Flight Delay Predictions</h1>
        <p class="text-muted mb-2" style="font-size: 0.95rem;">
            Amy Steward, Chad Vo, Kristen Lin, Priscilla Siow, Uma Rao Krishnan
        </p>
        <p class="article-meta text-muted mb-3"
            data-published="2026-1-12">
            <span id="publishDate"></span> •
            <span id="readingTime"></span>
        </p>

        <p class="text-muted mb-3" style="font-size: 0.85rem; max-width: 800px; margin-left: auto; margin-right: auto;">
            <strong>Tech Stack:</strong> Apache Spark 3.x • Databricks • PySpark MLlib • XGBoost • PyTorch (FT-Transformer) • NetworkX • NVIDIA T4 GPU
        </p>
        <div class="d-flex justify-content-center gap-4 mb-4 project-actions">
            <a href="https://github.com/chadpvo/ML-flight-delay-prediction" target="_blank" rel="noopener noreferrer" title="Project Repository">
                <i class="fab fa-github"></i>
            </a>
            <a href="assets/final_report.ipynb" download title="Download Jupyter Notebook">
                <i class="fas fa-file-code"></i>
            </a>
        </div>
        <div class="decorative-separator mx-auto"></div>
        <p class="lead text-muted mx-auto" style="max-width: 700px;">
            <strong>Summary:</strong> How we engineered a distributed ML pipeline to predict flight delays at scale—from 1.7M to 30M rows using weather data, operational features, and graph-based network analysis.
        </p>
    </section>

    <section class="project-article container mb-5">
        <article class="article-body">

            <header>
                <p class="lead">
                    <strong>TL;DR:</strong> We built a machine learning pipeline to predict flight delays using 30 million flight records and 132 million weather observations. The core challenge wasn't picking the right model—it was engineering a distributed data pipeline that could join massive spatiotemporal datasets without exploding. Our custom join strategy achieved 99.99% match rates while reducing missing values by 10x. The Feature Tokenizer Transformer won with the best generalization (Recall: 0.59, F2: 0.53), but the real victory was proving that data engineering matters as much as hyperparameter tuning.
                </p>
            </header>

            <div class="article-visual">
                <img src="assets/flight_delay_cover.jpg" alt="Flight Delay Prediction System" class="img-fluid rounded shadow zoomable-image" style="max-width: 100%;">
                <p class="mt-3"><em>Predicting delays across 30M+ flights in the US aviation network</em></p>
            </div>

            <h2>The "$33 Billion Delays" Problem</h2>

            <p>
                Flight delays cost the US economy billions annually. Airlines need to predict delays before they happen—ideally two hour before scheduled departure—to optimize operations, reduce compensation costs, and improve passenger satisfaction.
            </p>

            <p>
                The challenge? Building a prediction system that works at the scale of the entire US aviation network. But easier said than done right?
            </p>

            <h2>Big Data Challenge</h2>

            <p>
                We started with two massive, incompatible datasets spanning 2015-2019 (we chose pre-pandemic data to avoid COVID-19 disruptions).
            </p>
            <p>
                The problem? These datasets don't naturally join. Flight times are in local timezones. Weather data is in UTC. Airports aren't always co-located with weather stations. A naive Cartesian join would create trillions of comparisons.
            <br><br>
                Below is a summary of our data sources, sizes, and quality issues.
            </p>

            <table class="table table-bordered">
                <thead>
                    <tr>
                        <th style="width: 20%;">Source</th>
                        <th style="width: 25%;">Dimensions & Size</th>
                        <th style="width: 25%;">Brief Description</th>
                        <th style="width: 30%;">Data Quality & Analysis</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>
                            <strong>Flight Info</strong><br>
                            <span class="text-muted">Source: <a href="https://www.transtats.bts.gov/homepage.asp" target="_blank">US DOT</a></span>
                        </td>
                        <td>
                            <strong>Rows x Cols:</strong><br>
                            2.8M x 109 (3M)<br>
                            5.7M x 109 (6M)<br>
                            14.8M x 109 (1Y)<br>
                            74.1M x 109 (2015-2021)<br>
                            <br>
                            <strong>Size:</strong><br>
                            0.01 GB - 2.80 GB
                        </td>
                        <td>Primary Dataset for Analysis. Includes scheduled/actual flight times, delay reasons, airlines, and origin/destination airports.</td>
                        <td>
                            <strong>Missing:</strong> Significant blank data for diversions, Delay/Cancelled Codes, and Ground times.<br>
                            <strong>Duplicates:</strong> All rows duplicated and removed.<br>
                            <strong>Note:</strong> Diversion/Cancellation columns were dropped as they are irrelevant to our scope.
                        </td>
                    </tr>

                    <tr>
                        <td>
                            <strong>Weather</strong><br>
                            <span class="text-muted">Source: <a href="https://www.ncei.noaa.gov/access/metadata/landing-page/bin/iso?id=gov.noaa.ncdc:C00679" target="_blank">NOAA</a></span>
                        </td>
                        <td>
                            <strong>Rows x Cols:</strong><br>
                            30.5M x 124 (3M)<br>
                            61.2M x 124 (6M)<br>
                            74.1M x 124 (1Y)<br>
                            131.9M x 124 (2015-2021)<br>
                            <br>
                            <strong>Size:</strong><br>
                            1.11 GB - 4.84 GB
                        </td>
                        <td>Hourly weather conditions, including temperature, precipitation, wind speed, etc.</td>
                        <td>
                            <strong>Missing:</strong> >99% nulls for Monthly/Daily accumulation & backup columns.<br>
                            <strong>Duplicates:</strong> None.<br>
                            <strong>Note:</strong> Columns for accumulations and backups were removed due to lack of usable data.
                        </td>
                    </tr>

                    <tr>
                        <td>
                            <strong>Stations Data</strong><br>
                            <span class="text-muted">Source: US DOT</span>
                        </td>
                        <td>
                            <strong>Rows x Cols:</strong><br>
                            2,004,169 x 12<br>
                            <br>
                            <strong>Size:</strong><br>
                            52.08 MB
                        </td>
                        <td>Reference table containing metadata for weather stations, including location and distance to airports.</td>
                        <td>
                            <strong>Missing:</strong> 0% nulls.<br>
                            <strong>Duplicates:</strong> None.<br>
                            <strong>Note:</strong> Complete metadata table.
                        </td>
                    </tr>

                    <tr>
                        <td>
                            <strong>Airport Codes</strong><br>
                            <span class="text-muted">Source: <a href="https://datahub.io/core/airport-codes" target="_blank">Datahub.io</a></span>
                        </td>
                        <td>
                            <strong>Rows x Cols:</strong><br>
                            82,780 x 13<br>
                            <br>
                            <strong>Size:</strong><br>
                            8.18 MB
                        </td>
                        <td>Reference table containing standardized IATA/ICAO codes and airport metadata (coordinates, etc.).</td>
                        <td>
                            <strong>Missing:</strong> icao_code (90%), iata_code (89%).<br>
                            <strong>Duplicates:</strong> None.<br>
                            <strong>Note:</strong> 100% of target flights map successfully. Missing codes are mostly helipads/small ports.
                        </td>
                    </tr>
                </tbody>
            </table>

            <h3>Exploratory Data Analysis</h3>
            <p>
                For the purpose of focusing on the fundamentals of Machine Learning at Scale, I will not touch much on <strong> Exploratory Data Analysis</strong> in this article despite our extensive efforts on that step. For more details, please refer to our report or our EDA section at the bottom of this page.
            </p>
            
            <h2>Data Engineering Strategy: Custom Spatiotemporal Joins</h2>

            <p>
                Since we couldn't just merge these tables, we had to creatively engineer a custom join strategy that respects both space and time.
            </p>

            <h3>1. Geographic Matching: Finding the Right Weather Station</h3>

            <p>
                First challenge: match each airport to its nearest weather station. We used station metadata containing distance calculations to identify the closest station for each airport, prioritizing stations within airport boundaries (distance = 0 miles).
            </p>

            <h3>2. Temporal Alignment: The 6-Hour Window</h3>

            <p>
                Second challenge: match weather readings to flights. We needed weather conditions from exactly 1 hour before scheduled departure, but weather stations report at irregular intervals.
            </p>

            <p><strong>Our solution:</strong></p>

            <ul>
                <li>Convert all flight times from local to UTC (handling daylight savings)</li>
                <li>Create a 6-hour validity window around each flight departure</li>
                <li>Use <code>repartitionByRange</code> to co-locate records by station and time</li>
                <li>Select the weather reading closest to T-1 hour</li>
            </ul>

            <p>
                This approach led us to a <strong>99.99% match rate</strong> for short timeframes and 75% for the full 5-year dataset while dramatically reducing data shuffling across the Spark cluster.
            </p>

            <h3>The Unexpected Win: Data Quality Repair</h3>

            <p>
                Our custom join didn't just match records—it <em>fixed</em> the data (at least most of them). The right join strategy improved data quality by an order of magnitude.
            </p>

            <p>
                By selecting optimal weather readings within our time window, we reduced missing values without synthetic imputation:
            </p>

            <ul>
                <li>Visibility: 35% → 3.5% missing</li>
                <li>Sky Conditions: 42.8% → 12.1% missing</li>
                <li>Relative Humidity: 33% → 3.5% missing</li>
                <li>Wind Speed: 25.4% → 3.5% missing</li>
            </ul>

            <h2>Feature Engineering at Scale</h2>

            <p>
                Looking at the raw weather data table initially, we concluded that raw weather codes and flight data aren't ready for ML models. Therefore, we engineered features across four critical dimensions:
            </p>

            <p>
                <strong>Weather Decoding:</strong> NOAA data arrives as cryptic codes like <code>"RA:61,TS:95"</code>. We built regex parsers to decode these into binary indicators for rain, snow, freezing conditions, and severe weather.
            </p>

            <p>
                <strong>Graph Features:</strong> We modeled the US aviation system as a directed weighted graph (nodes = airports, edges = flight routes) and calculated PageRank, out-degree, and in-degree centrality. This captured network effects—delays at major hubs like ATL, ORD, and DFW cascade downstream more severely than delays at smaller airports.
            </p>

            <p>
                <strong>Temporal Lag Features:</strong> The most predictive features came from tracking previous flights by the same aircraft—previous arrival delay, actual vs. scheduled turnaround time, and planned turnaround buffer. Critical constraint: only use data available >1 hour before current departure to prevent leakage. These features alone accounted for <strong>70% of XGBoost's information gain</strong>.
            </p>

            <p>
                <strong>Cyclic Time Encodings:</strong> We used sine/cosine transformations for month and day-of-week to capture cyclical patterns—December is close to January, not infinitely far.
            </p>

            <h2>Addressing The Data Leakage Problem</h2>

            <p>
                Building a time-series prediction model requires extreme care to avoid leakage. After performing extensive exploratory analysis, we removed 20+ features that would only be known after departure (e.g., actual taxi-out time, airborne time, delay reason codes).
            </p>

            <p>
                We also implemented <strong>time-aware cross-validation</strong> using rolling windows—training always on past data, validating on strictly future data. No temporal leakage allowed.
            </p>

            <div class="article-visual">
                <img src="assets/windows_strategy.png" alt="Time-Series Cross-Validation Windows" class="img-fluid rounded shadow zoomable-image" style="max-width: 100%;">
                <p class="mt-3"><em>Rolling window validation ensures temporal integrity—training always on past, validating on future</em></p>
            </div>

            <h2>Handling Class Imbalance At Scale: The Downsampling Dilemma</h2>

            <p>
                The distribution of delayed vs. non-delayed flights remained remarkably consistent across all timeframes, with delays hovering around 18-22% regardless of dataset size.
            </p>


            <p>
                We initially tried SMOTE (Synthetic Minority Over-sampling Technique) and standard upsampling to balance classes. Both approaches failed spectacularly:
            </p>

            <ul>
                <li><strong>SMOTE:</strong> Generating synthetic samples for millions of minority class records caused memory explosions across Spark executors</li>
                <li><strong>Upsampling:</strong> Duplicating minority samples ballooned dataset size, multiplying processing time and cloud compute costs</li>
                <li><strong>Runtime impact:</strong> Both methods would have extended training from hours to days, making experimentation impossible</li>
            </ul>

            <p>
                Instead, we downsampled the majority class to achieve 50:50 balance, accepting information loss in exchange for computational feasibility and faster training.
            </p>

            <div class="article-visual">
                <div id="classImbalanceChart" class="chart-container"></div>
                <p class="mt-3"><em>Class distribution remains stable across 3-month, 1-year, and 5-year datasets</em></p>
            </div>

            <p>
                <strong>The Pragmatic Solution: Downsampling the Majority Class</strong>
            </p>

            <p>
                Flight delays suffer from severe class imbalance—only 18-22% of flights are delayed. This creates both a modeling challenge and a <strong>computational cost problem</strong>.
                So instead of adding data, we removed it. We randomly downsampled on-time flights (majority class) to achieve a 50:50 balance with delayed flights. This approach worked for us because:
            </p>

            <ul>
                <li>Reduced overall dataset size by ~40%, dramatically cutting compute time and costs</li>
                <li>Retained at least 60% of original training data's information</li>
                <li>Enabled rapid experimentation—training iterations that would have taken 6+ hours completed in under 2 hours</li>
                <li>Made GPU training feasible for neural networks (memory constraints loosened)</li>
            </ul>

            <p>
                <strong>The Trade-off:</strong> We accepted some information loss from the majority class in exchange for computational feasibility. At 30 million rows, this was the right call—we needed a pipeline that could iterate within reasonable time and budget constraints.
            </p>

            <p>
                This decision exemplifies a core principle in production ML: <strong>pragmatic solutions that work at scale beat theoretically optimal solutions that never finish running</strong>.
            </p>

            <p>
                <strong>Key insight:</strong> At 30M rows, sometimes the pragmatic solution beats the theoretical ideal.
            </p>
            
            <h2>The Pipeline: 7-Stage Checkpointing Strategy</h2>

            <p>
                Utilizing the technology of Spark was definitely a double-edged sword because its "lazy" evaluation is powerful but dangerous. If a job fails after 2 hours, you might recompute everything.
                Therefore, in order to combat that, we implemented a rigorous checkpointing strategy, saving intermediate results at seven critical stages broken down as follows:
            </p>

            <ol>
                <li>Raw data joins (FASW dataset creation)</li>
                <li>Null handling and feature engineering</li>
                <li>Train/test split (2015-2018 train, 2019 test)</li>
                <li>Rolling window creation for cross-validation</li>
                <li>Feature scaling and vectorization per window</li>
                <li>Processed final train/test sets</li>
                <li>Model training results via MLflow</li>
            </ol>
            <p>
                This decoupled data engineering from model training. We could iterate rapidly on models without re-triggering expensive joins.
            </p>
            <div class="article-visual">
                <img src="assets/updated_pipeline.jpeg" alt="ML Pipeline Architecture" class="img-fluid rounded shadow zoomable-image" style="max-width: 100%;">
                <p class="mt-3"><em>7-stage checkpoint strategy decouples data engineering from model training</em></p>
            </div>

            <h2>Model Comparison: Data Engineering Beats Hyperparameter Tuning</h2>

            <p>
                As we evaluated six model architectures, prioritizing <strong>Recall</strong> (catching actual delays) over Precision (avoiding false alarms). The surprise? Performance differences came from feature engineering, not model architecture.
            </p>

            <table class="table table-bordered">
                <thead>
                    <tr>
                        <th>Model</th>
                        <th>Test Recall</th>
                        <th>Test Precision</th>
                        <th>Test F2</th>
                        <th>Test PR-AUC</th>
                        <th>Key Insight</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Logistic Regression</td>
                        <td>0.53</td>
                        <td>0.88</td>
                        <td>0.58</td>
                        <td>0.29</td>
                        <td>Fast baseline, struggled with non-linear patterns</td>
                    </tr>
                    <tr>
                        <td>Decision Tree</td>
                        <td>0.11</td>
                        <td>0.73</td>
                        <td>0.13</td>
                        <td>0.41</td>
                        <td>Severe overfitting—collapsed on test set</td>
                    </tr>
                    <tr>
                        <td>Random Forest</td>
                        <td>0.67</td>
                        <td>0.31</td>
                        <td>0.55</td>
                        <td>0.37</td>
                        <td>Strong recall, excellent feature importance</td>
                    </tr>
                    <tr>
                        <td>XGBoost</td>
                        <td>0.68</td>
                        <td>0.30</td>
                        <td>0.55</td>
                        <td>0.44</td>
                        <td>70% of gain from 2 features: turnaround time</td>
                    </tr>
                    <tr>
                        <td>MLP (Neural Net)</td>
                        <td>0.56</td>
                        <td>0.33</td>
                        <td>0.49</td>
                        <td>0.35</td>
                        <td>Similar to XGBoost but 10x slower training</td>
                    </tr>
                    <tr style="background-color: #d4edda;">
                        <td><strong>FT-Transformer</strong></td>
                        <td><strong>0.59</strong></td>
                        <td><strong>0.36</strong></td>
                        <td><strong>0.53</strong></td>
                        <td><strong>0.45</strong></td>
                        <td><strong>Best generalization, Focal Loss for imbalance</strong></td>
                    </tr>
                </tbody>
            </table>

            <p>
                <strong>The Winner: Feature Tokenizer Transformer. </strong>(Shoutout to my teammate Amy Steward for leading this model training)
            </p>

            <p>
                The FT-Transformer won not through superior raw metrics, but through <strong>temporal stability</strong>. While other models showed train-validation gaps indicating overfitting, the FT-Transformer maintained consistent performance across all splits—proof it learned true patterns rather than memorizing noise.
            </p>

            <p>
                <strong>Key technical advantages:</strong>
            </p>

            <ul>
                <li><strong>Feature tokenization:</strong> Each feature becomes its own embedded token, enabling cross-feature attention (time × weather × airline interactions)</li>
                <li><strong>Custom Focal Loss:</strong> Handles class imbalance natively (γ=1, α≈0.8) instead of requiring downsampling</li>
                <li><strong>Multi-head self-attention:</strong> Captures complex feature interactions that tree models miss</li>
                <li><strong>GPU requirement:</strong> 4 hours on NVIDIA T4 vs. 15+ hours on CPU</li>
            </ul>

            <p> For more details on how our Transformer works, check out Amy's <a href="https://medium.com/@aestew/feature-tokenizer-transformer-model-performance-in-predicting-flight-delays-96126989e133">detailed write-up</a>.</p>

            <h2>Machine Learning at Scale: Linear Growth</h2>

            <p>
                Due to the sheer volume of data, our pipeline scaled nearly linearly with data volume as we broke down our milestones from 3 months to 1 year to 5 years:
            </p>

            <table class="table table-bordered">
                <thead>
                    <tr>
                        <th>Timeframe</th>
                        <th>Rows</th>
                        <th>Size</th>
                        <th>Processing Time</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>3 months</td>
                        <td>1.7M</td>
                        <td>0.25 GB</td>
                        <td>3m 39s</td>
                    </tr>
                    <tr>
                        <td>1 year</td>
                        <td>7.1M</td>
                        <td>1.43 GB</td>
                        <td>10m 57s</td>
                    </tr>
                    <tr>
                        <td>5 years</td>
                        <td>30.1M</td>
                        <td>6.29 GB</td>
                        <td>1h 49m</td>
                    </tr>
                </tbody>
            </table>

            <p>
                <strong>This is what "ML at scale" means:</strong> algorithms that remain efficient as data grows by orders of magnitude.
            </p>

            <h2>Key Lessons: What Actually Mattered</h2>

            <p>After weeks of experimentation and iteration, there were tons of lessons to learn, insights to share, and lots of milestones to celebrate.  Here's a summary of the most important ones:</p>

            <h3>1. Data Engineering is As Equally important As Hyperparameter Tuning</h3>

            <p>
                The biggest performance gains came from thoughtful feature engineering rather than exhaustive hyperparameter searches. Our aircraft turnaround time features alone accounted for 70% of XGBoost's information gain, while tweaking tree depths and learning rates provided only marginal improvements. The lesson: invest engineering time in understanding domain patterns and creating features that capture real operational dynamics before diving into model optimization.
            </p>

            <h3>2. Temporal Validation is Non-Negotiable</h3>

            <p>
                Standard k-fold cross-validation would have given catastrophically optimistic results by allowing future information to leak into training. Our time-series rolling windows—where training always occurred on strictly past data and validation on future periods—revealed the true generalization performance. The Decision Tree's dramatic test set collapse (from 0.64 validation recall to 0.11 test recall) proved why temporal integrity matters in production forecasting systems.
            </p>

            <h3>3. The Right Join Strategy Fixes Data Quality</h3>

            <p>
                Our spatiotemporal window join didn't just match records—it fundamentally improved data quality without synthetic imputation. By selecting optimal weather readings within a 6-hour validity window and matching to the nearest station, we reduced missing values by 10x (visibility: 35% → 3.5%, humidity: 33% → 3.5%). Sometimes the best solution to bad data isn't sophisticated imputation algorithms—it's better data engineering from the start.
            </p>

            <h3>4. Pragmatism Over Purity at Scale</h3>

            <p>
                Downsampling sacrificed theoretical optimality for computational feasibility, but at 30 million rows, this was the right engineering decision. SMOTE and upsampling would have extended training from hours to days while exploding memory usage across our Spark cluster. By accepting a 40% dataset reduction, we enabled rapid experimentation and made GPU training viable for neural networks. "Good enough and fast" beats "perfect but impossible" when operating under real-world constraints.
            </p>

            <h3>5. GPU Requirements for Deep Learning at Scale</h3>

            <p>
                The FT-Transformer's 4-hour GPU training time versus 15+ hours on CPU illustrated that hardware choices have first-order impacts on iteration speed and project feasibility. For production ML systems handling millions of records, GPU acceleration isn't a luxury—it's a practical requirement that determines whether experimentation cycles take hours or days. The upfront infrastructure cost pays for itself in engineering velocity.
            </p>

            <h2>Conclusion: The Model is Only as Good as the Pipeline</h2>

            <p>
                Predicting flight delays isn't just a modeling problem, but it's also a <strong>data engineering problem</strong>.
            </p>

            <p>
                The FT-Transformer achieved the best results not because of superior architecture and onpoint feature engineering, but we truly believe that it's because we built a pipeline that could feed it clean, properly joined, temporally valid data at scale.
            </p>

            <p>
                In real life, production ML systems, distributed joins, checkpointing strategies, and feature engineering pipelines matter just as much as model selection. As we master the infrastructure, and the models will follow.
            </p>

            <p class="article-note mt-5 text-center">
                <strong>Full code and technical details</strong>
            </p>
            <div class="d-flex justify-content-center gap-4 mt-3 project-actions">
                <a href="https://github.com/chadpvo/ML-flight-delay-prediction" target="_blank" rel="noopener noreferrer" title="Project Repository">
                    <i class="fab fa-github"></i>
                </a>
                <a href="assets/final_report.ipynb" download title="Download Jupyter Notebook">
                    <i class="fas fa-file-code"></i>
                </a>
            </div>

        </article>
    </section>

    <section class="eda-gallery">
        <div class="eda-gallery-header">
            <h5>Miscellaneous EDA</h5>
            <div class="eda-gallery-arrows">
                <button onclick="scrollEDA('left')" aria-label="Scroll left"><i class="fas fa-chevron-left"></i></button>
                <button onclick="scrollEDA('right')" aria-label="Scroll right"><i class="fas fa-chevron-right"></i></button>
            </div>
        </div>
        <div class="eda-gallery-scroll" id="edaScroll">
            <div class="eda-card">
                <div class="eda-card-img">
                    <img src="assets/delay_analysis_by_size.png" 
                        alt="Delay Analysis by Aircraft Size" 
                        class="zoomable-image">
                </div>
                <p>Delay Analysis by Aircraft Size</p>
            </div>
            
            <div class="eda-card">
                <div class="eda-card-img">
                    <img src="assets/delay_percentage_by_airline.png" 
                        alt="Delay Percentage by Airline" 
                        class="zoomable-image">
                </div>
                <p>Delay Percentage by Airline</p>
            </div>

            <div class="eda-card">
                <div class="eda-card-img">
                    <img src="assets/delay_percentage_by_hour_day.png" 
                        alt="Delay Percentage by Hour and Day" 
                        class="zoomable-image">
                </div>
                <p>Delay Percentage by Hour and Day</p>
            </div>

            <div class="eda-card">
                <div class="eda-card-img">
                    <img src="assets/distribution_of_arrival_delays_by_minutes.png" 
                        alt="Distribution of Arrival Delays by Minutes" 
                        class="zoomable-image">
                </div>
                <p>Distribution of Arrival Delays by Minutes</p>
            </div>

            <div class="eda-card">
                <div class="eda-card-img">
                    <img src="assets/precip_by_report_locations.png" 
                        alt="Precipitation by Report Locations" 
                        class="zoomable-image">
                </div>
                <p>Precipitation by Report Locations Map</p>
            </div>

            <div class="eda-card">
                <div class="eda-card-img">
                    <img src="assets/top_delay_routes_by_top5_airports.png" 
                        alt="Top Delay Routes by Top 5 Airports" 
                        class="zoomable-image">
                </div>
                <p>Top Delay Routes by Top 5 Airports</p>
            </div>

            </div>
    </section>
    <section class="bg-light-blue py-5 text-center footer-section" id="contact"></section>

    <div id="imageModal" class="image-modal">
        <span class="image-modal-close">&times;</span>
        <img class="image-modal-content" id="modalImage">
        
        <div id="caption"></div>
    </div>

    <button id="scrollToTop" class="scroll-top-btn" aria-label="Scroll to top">
        <i class="fas fa-arrow-up"></i>
    </button>

    <script src="../../js/page-config.js"></script>
    <script src="../../js/seo-injector.js"></script>
    <script src="../../js/ui-manager.js"></script>

    <script>
        // Sticky Header Scroll Effect
        window.addEventListener('scroll', () => {
            const stickyHeader = document.getElementById('stickyHeader');
            if (stickyHeader) {
                if (window.scrollY > 50) {
                    stickyHeader.classList.add('floating');
                } else {
                    stickyHeader.classList.remove('floating');
                }
            }
        });

        // Image Zoom Logic
        const modal = document.getElementById('imageModal');
        const modalImg = document.getElementById('modalImage');
        const captionText = document.getElementById("caption");
        const closeBtn = document.querySelector('.image-modal-close');
        const zoomableImages = document.querySelectorAll('.zoomable-image');

        zoomableImages.forEach(img => {
            img.addEventListener('click', function(e) {
                e.preventDefault();
                modal.classList.add('active');
                modalImg.src = this.src;
                modalImg.alt = this.alt;
                captionText.innerHTML = this.alt;
                document.body.style.overflow = 'hidden';
            });
        });

        function closeModal() {
            modal.classList.remove('active');
            document.body.style.overflow = 'auto';
        }

        closeBtn.addEventListener('click', closeModal);

        modal.addEventListener('click', function(e) {
            if (e.target === modal) {
                closeModal();
            }
        });

        document.addEventListener('keydown', function(e) {
            if (e.key === 'Escape' && modal.classList.contains('active')) {
                closeModal();
            }
        });

        // Scroll to Top Logic
        const scrollBtn = document.getElementById('scrollToTop');
        window.addEventListener('scroll', () => {
            scrollBtn.style.display = window.scrollY > 300 ? 'block' : 'none';
        });
        scrollBtn.addEventListener('click', () => {
            window.scrollTo({ top: 0, behavior: 'smooth' });
        });

        // Meta Data Logic
        const meta = document.querySelector('.article-meta');
        if (meta) {
            const published = new Date(meta.dataset.published);
            document.getElementById('publishDate').textContent =
                published.toLocaleDateString(undefined, {
                    year: 'numeric',
                    month: 'long',
                    day: 'numeric'
                });

            const articleText = document.querySelector('.article-body').innerText;
            const words = articleText.trim().split(/\s+/).length;
            const minutes = Math.ceil(words / 225);
            document.getElementById('readingTime').textContent = `${minutes} min read`;
        }

        // ==========================================
        //  Class Imbalance Chart Logic
        // ==========================================
        function createClassImbalanceChart() {
            const chartHTML = `
                <div class="imbalance-chart-wrapper">
                    <div class="chart-header">
                        <div class="chart-title">Class Imbalance Distribution Across Datasets</div>
                        <p class="chart-subtitle">Class labels calculated using ARR_DEL15</p>
                    </div>

                    <div class="chart-legend">
                        <div class="legend-item">
                            <div class="legend-color" style="background: #4a7ba7;"></div>
                            <span>Class 0 (Non-Delayed)</span>
                        </div>
                        <div class="legend-item">
                            <div class="legend-color" style="background: #8fb3d1;"></div>
                            <span>Class 1 (Delayed)</span>
                        </div>
                    </div>

                    <div class="chart-inner">
                        <div class="chart-area">
                            <div class="grid-lines">
                                <div style="top: 0;"></div>
                                <div style="top: 25%;"></div>
                                <div style="top: 50%;"></div>
                                <div style="top: 75%;"></div>
                            </div>
                            <div class="x-axis-line"></div>
                            
                            <div id="chartBars" class="bars-container">
                                ${createBarGroup('78.9', '21.1', '3-Month')}
                                ${createBarGroup('80.9', '19.1', '1-Year')}
                                ${createBarGroup('81.4', '18.6', '5-Year (2015-2019)')}
                            </div>
                        </div>
                    </div>
                </div>
            `;
            
            document.getElementById('classImbalanceChart').innerHTML = chartHTML;
            initScrollAnimation();
        }

        function createBarGroup(class0Pct, class1Pct, label) {
            return `
                <div class="bar-group">
                    <div class="bars">
                        <div class="bar bar-class0" style="height: ${class0Pct}%;">
                            <div class="bar-fill"></div>
                            <div class="bar-label">${class0Pct}%</div>
                        </div>
                        <div class="bar bar-class1" style="height: ${class1Pct}%;">
                            <div class="bar-fill"></div>
                            <div class="bar-label">${class1Pct}%</div>
                        </div>
                    </div>
                    <div class="dataset-label">${label}</div>
                </div>
            `;
        }

        function initScrollAnimation() {
            const chart = document.getElementById('classImbalanceChart');
            if (!chart) return;

            const observer = new IntersectionObserver((entries) => {
                entries.forEach(entry => {
                    if (entry.isIntersecting) {
                        chart.classList.add('animate');
                    } else {
                        chart.classList.remove('animate');
                    }
                });
            }, { threshold: 0.3 });

            observer.observe(chart);
        }

        // ==========================================
        //  EDA Gallery Scroll Logic
        // ==========================================
        function scrollEDA(dir) {
            const el = document.getElementById('edaScroll');
            el.scrollBy({ left: dir === 'left' ? -220 : 220, behavior: 'smooth' });
        }

        // Initialize chart when page loads
        window.addEventListener('DOMContentLoaded', createClassImbalanceChart);
    </script>

</body>
</html>