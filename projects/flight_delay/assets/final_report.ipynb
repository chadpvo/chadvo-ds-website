{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "edc7057a-036a-4bd5-b445-d96fb3b7ac73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Predicting Flight Delays\n",
    "##### Written and compiled by: Team 2-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3d09217-b29f-4c68-a5ad-3059169c1869",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Phase Leader Plan\n",
    "\n",
    "One member of the team will assume the project manager role for an entire phase, as agreed upon. The designated project manager for each phase is highlighted below:\n",
    "\n",
    "| Phase | Weeks | Phase Description | Phase Leader |\n",
    "|-|-|-|-|\n",
    "| 1 + Off Week| October 27, 2025 - November 9, 2025 | Project Plan, describe datasets, joins, tasks, and metrics | Kristen Lin |\n",
    "| 2 + Off Week| November 10, 2025 - November 23, 2025 | EDA, baseline pipeline, Scalability, Efficiency, Distributed/parallel Training, and Scoring Pipeline | Amy Steward |\n",
    "| 3 + Off Week| November 24, 2025 - December 12, 2025  | Select the optimal algorithm, fine-tune and submit a final report | Priscilla Siow |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b03d18b7-7d27-4b13-bbeb-77af48352d13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Credit Assignment Plan - Everyone\n",
    "\n",
    "The below documents the contributions each member has made and their planned contributions in future phases:\n",
    "\n",
    "| Team Member         | Phase 1 | Phase 2 (Current) | Phase 3 (Planned) |\n",
    "|---------------------|------------------|-------------------|-------------------|\n",
    "| **Amy Steward** | - 10/26 - Reviewed and explored all provided datasets (Flight, Weather, Station, and Airplane tables) (8 hrs) <br> - 10/27, 10/30 - Created comprehensive data dictionaries for each dataset, including column definitions, formats, and missingness analysis. (2 hrs) <br> - 10/28 Filtered, cleaned, and standardized data fields ; removed redundant or low-value columns.(1 hr) <br> - 10/31, Partnered with Kristen to join datasets (Weather × Flight × Station)(16 hrs). <br> - Created and managed a GitHub repository (`aestew/261_pix`) to host project-related images and visual assets. (1 hr)<br> - 10/27 - Conducted initial descriptive and statistical EDA of OTPW datasets. (2 hrs) <br> - 11/2 Identified class imbalance and delay frequency patterns across regions and time. (1 hr) <br> - 11/2 - Created visualizations and dataset summaries for the team notebook, including EDA write-ups and histograms.(1 hr) <br> - 11/2 - Defined classification framing (binary 15-minute arrival delay = “Yes” or “No”).(1 hr) <br> - 11/2 - Authored methodology and documentation for the Logistic Regression model. (1 hr) <br> - 11/2 - Partnered with Kristen on model evaluation metrics — Recall, Precision, F-score, PR AUC — and model generalization checks (2 hrs) (training vs. validation). <br> - 10/29,10/30, 11/2 - Designed and documented the model pipeline diagram and checkpointing workflow. (16 hrs)<br> - 10/30, 11/2 - Wrote, QC'd built and created the abstract, background, data description, preprocessing, EDA, and ML pipeline sections as well as overall editing and refinement for report. (16 hrs) <br> - 11/3 Conducted literature research on flight delay prediction, delay propagation networks, and weather-related delay impacts. (4 hrs) <br> **64 Hours Clocked**|**Phase 2 Leader** <br>-  11/11, 11/12 Created custom logic and imputating to remove and manage nulls by features for k-fold split (16 hours)  <br> - 11/13-11/14 Finalize, QC, productize and run Kristen's log, scale, k-fold pipeline, and upscaling  (8 hrs) <br> - 11/15-11/16 Feature Selection and cleaning for FT transformer model (10 hr) <br> - November -  Support team with data questions (2 hrs) <br> - 11/17 Compelete slides on Joins, EDA, and data filtering and cleaning (4 hrs) <br>- 11/1 Ownership Grid (1hr) <br> 11/16 - 11/17 - Prepare and review presentation slides (1 hour)<br>- 11/18-11/19 Write sections on Feature Selection, FT Neural Network Feature Selection, Handling Missing Values and Dupe Records (6hrs)<br> 11/18,11/21,11/22 Run EDA on overall flights for UA and matricies, Data pre-processing, joining, (10 hrs)  <br> - 11/21 Re-run models to include UA + input Kristen's Fold code into final pipeline and re-run (2 hrs) <br> Additional EDA on all time data with flights (7 hours)<br>- Complete QC / EDA, build visuals and productize data for join - including null visuals, data sizes, explanation of join <br>- Create final checklist for team, add additional visuals (8 hrs)<br><br> **75 hours clocked** <br><br><br> **(Not included: 6+ hours of meetings/working sessions/debrief calls)**| - 11/30-12/1: Build airport to airport graph features, build lag time series features, add to and re-run pipeline (8hrs) <br> -12/1 MLP NN model <br> 12/2 - Tune, finalize MLP NN model, test multiple archectures, run on 3m and all time data, frame, and test FT NN model (10 hours) <br>- 12/3 - Build, run, test and troubleshoot FTNN model on GPU (4 hours)<br> 12/4 - rebuild FTNN  (1 hr) <br> -Build, test and train and tune Tabular Neural Network and Feature Tokenizer Transformer and MLP models on GPU (9 hours) <br> - 12/4 start writing paper (1hr) <br> 12/5 - Run blind test on Feature Tokenizer Transformer and MLP. Implement automatic stopping on FTT (8 hrs) <br> -12/6: Create result charts, start writting NN section (2 hrs) <br> 12/7 - Creating tables, organizing data for deck <br> 12/8 - Outline Neural Network section, create tables and curate results, review complete slides for overall results, neural network and next steps, complete writing MLP sections (10 hours) <br> 12/9 - Review presentation requirements, update presentation with top features, format slide on results, create slide with all train/test outcomes, compute generalization metrics (14 hours) <br><br> <br><br><br><br>Ensuring model generalization (1 hr) <br>- 12/5 -Reviewing model tuning (2 hr) <br>- Supporting final write-up (5 hrs)<br>- Supporting final model selection  (1 hr)<br>- Troubleshooting, QA and clean up pipelines and datasets (5 hrs)|\n",
    "| Chad Vo             | - **10/22 - 10/30:** General Team Meetings, Catchup & Collab Calls (**6 hours**) <br>- **10/22-10/23** Basic EDA for all 4 provided datasets (**3 hours**) <br> - **10/23** - Data pre-processing for weather data (**2 hours**) <br> - **10/23** - **10/25** - Provided initial codes for weather/sky conditions parsing (**4 hours**) <br> - **10/23-10/24:** Initial Research and prepared intial test codes from provided sample's workbook on SMOTE and sampling techniques (**2 hours**) <br> - **10/24:** Research and prepare codes on K-Fold Splitting (**4 hours**) <br> - **10/25** - Research o Random Forest as the baseline model or improved model (**1 hour**) <br> - **10/25-10/26** Write-up on Background Context, Reference/Research, Random Forest (**5 hours**) <br>- **10/24-10/26** - Create Gantt Chart & Project Timeline (**2 hours**) <br> - **10/26** - Finalize Source's Formatting and Appendix Section (**2 hours**) <br> - **10/26** - Prepare the initial code for Random Forest and test running parameter on 3m OTPW via Spark (**1 hour**) <br> **Total Hours: 32**          |- **10/27 - 11/23:** Weekly Team Meetings/Debrief (**6 hours**) <br> - **10/31 - 11/16:** Initial Random Forest Model Framework Building, Building Eval Loop for K-Fold Splitting & Rolling Windows (**5 hours**)  <br> - **11/3 - 11/16:** Research, prepare code, and perform various testing with SMOTE, upsampling, downsampling, and adding-weight class to incorporate in with Rolling Window's Code (**12 hours**) <br> - **10/27 - 11/16:** Build and Experiment with Grid Search by testing with Random Forest (**4 hours**) <br>- **11/16 - 11/17:** QA & Perform Diagnostic Test on Training Data (i.e. null analysis, imputation, log, etc.) (**4 hours**)  <br>- **11/18 - 11/19:** Features Selections and Features Alignment Test across all rolling windows (**3 hours**) <br> **11/17:** Presentation practice and planning with group (**2 hours**) <br>- **11/16 - 11/17** - Prepare and review presentation slides (**1 hour**) <br>- **11/18:** QA and assist Priscilla with Baseline Model / Logistic Regression Troubleshooting (**2 hour**)  <br>- **11/19 - 11/23** : Create Visualization and EDA for Phase 2 Reports on 1yr and 5yr joined data along with additional visualizations for other sections (**7 hours**) <br>- **11/21-11/23:** Pilot Testing Pre-Processing Code at model level for Testing Data and run group's first blind test (**8 hours**) <br>- **11/22-11/23** Write up Random Forest, Class Imbalance Handling, and expand more write up on other sectios for final report (**3 hours**) <br> **Total Hours: 57**    | **11/24 - 12/10:** HW Assignment Leader (during break week) (**12 hours**) <br> **12/1:** Redid Random Forest notebook and model setup due to new changes on Model Pipeline and add ML Flow (**4 hours**) <br> **12/2:** Experiment w/ New Vectorized Columns (**5 hours**) <br> **12/2:** Feature Importance Analysis and Feature Selection Final Study using updated pipeline (**3 hours**) <br> **12/1 - 12/7:** Random Forest Model Training and Grid Search (**10 hours**) <br> **12/1-12/3:** Blind Test Diagnostic and QA strategies on Blind Test due to class's imbalances (**8 hours**) <br> **11/24-12/7:** Consolidate all EDAs visuals in final notebook with 5-year data and added additional EDAs (**12 hours**) <br> **12/4 - 12/6:** Assist Kristen w/ Pipeline Visualization (**3 hours**) <br> **11/30 - 12/7:** Write-ups for EDAs, Random Forest, Graph Features Engineer and revising part of appendix section (**8 hours**) <br> **12/1-12/7:** Finalizing presentations and added designated slides (**3 hours**) <br> **Total Hours: 68**  |\n",
    "| Kristen Lin         |  **>Phase 1 Leader**<br> <br> **10/22-10/25:** Initial EDA on all datasets and data quality evaluation **(8 hours)** <br> **10/26:** Partnered with Amy to define new join conditions for new OTPW dataset with ideation on checkpointing **(3 hours)**; Null summary analysis in Appendix **(1 hour)** <br> **10/27:** Converted all required local timestamps to UTC **(4 hours)** <br> **10/28:** Worked on report outline **(1 hour)** <br> **10/29:** Finalized evaluation metrics, relevant formulas, and model comparison strategy **(2 hour)** <br> **10/31:** Revised pre-processing strategy and feature selection **(1 hour)**; Research and write-up on LightGBM, Decision Tree Classifer models, and hyperparameter tuning **(5 hours)** <br> **11/1:** Uploading images and attached all images in report for html export compatibility **(1 hour)**; Visualizations for trend lines, timestamp difference distributions, and correlation heatmap **(5 hours)**; Write-up on data dictionary (first pass) and data challenges **(3 hours)** <br> **11/2:** Revised Gantt chart**(1 hour)**; Incorporated business context for all report sections **(2 hours)**; Writeup on ML pipeline and reviewed/revised remaining report sections **(7 hours)** <br><br> **Total hours: 43 <br><br> (Not included: 6+ hours of meetings/working sessions/debrief calls)**| **11/5:** Partnered with Amy to join flight data with weather and design data engineering pipeline with checkpointing stages **(4 hours)** <br>**11/6:** Entity-relationship diagram for joined datasets & data/model pipeline diagram **(2 hours)** <br>**11/7, 11/9-11/10:** Pair coding with Amy on troubleshooting pipeline; data ingestion, pipeline setup, checkpointing, and scaling (for all data ranges - 3M/6M/1Y/5Y) **(12 hours)** <br> **11/11-11/12:** Cross-validation folds for time-series (forward chaining), imputing data, optimizing code, and testing (for data ranges - 3M/6M/1Y) **(6 hours)** <br> **11/14:** Update checkpointing and logic for forward chaining time-series CV to rolling windows with fixed training sets (with directory housekeeping) **(4 hours)**; Pipeline setup with initial LightGBM training and hyperparameter tuning **(3 hours)** <br>**11/16:** Phase 2 Check-In PPT - background, business case, ERD, model pipeline & visuals **(2 hours)** <br>**11/17:** Presentation practice and planning with group **(2 hours)** <br>**11/18:** Added holiday period indicators and reran pipelines for 3M/6M/1Y **(3 hour)**  <br>**11/19:** Revised report sections on joining data, initial data sizes and details, data challenges and approach - including repopulating tables **(6 hours)** <br> **11/20:** Revised and reformatted report sections on model comparison strategy and modeling pipeline **(4 hours)** <br>**11/21:** Further pre-processing and QC to address data issues encountered during training **(6 hours)**; Pipeline testing and regenerated files with fixes for 3M **(3 hours)**  <br>**11/22-11/23:** Shifting work to XGBoost model (scrapping LightGBM) and work on respective evaluation metrics **(3 hours)**; Minor feature engineering and vectorization **(2 hours)**; Training on 3M and 1Y using MLFlow + learning/setting Up MLFlow **(5 hours)**; Peer-reviewed model experiments and conclusion **(1 hour)** <br><br> **Total hours: 68 <br><br> (Not included: 6+ hours of meetings/working sessions/debrief calls)** | **11/24-11/25:** Redesigned entire pipeline with additional checkpointing to reduce reprocessing time. Revised code to address data quality issues and reprocessed joins for all years (QC included) **(17 hours)** <br> **11/26:** Further data refinement and additional null handling, additional feature engineering and simplified features. Reprocessed splits and rolling windows for proper cross-validation and testing (QC included) **(10 hours)** <br> **11/27-11/28:** Created checkpoint pipeline for transforming rolling windows for train and val datasets for each timeframe. Created new, separate vectorized columns for specifically linear/sigmoid regression and tree models. Processed data for each timeframe (QC included) **(11 hours)**. <br> **11/29:** Created checkpoint pipeline for processing/transforming overall train and unseen test datasets. Processed data for each timeframe. Basic housekeeping across notebooks (6 notebooks for each checkpoint of the pipeline, QC included). **(5 hours)** <br> **12/3:** Feature importance analysis and engineering, minimized selection and re-vectorized fields for graph features **(6 hours)** <br> **12/4:** Additional grid search for XGB model with colsample and regularization **(4 hours)** <br> **12/5:** Additional feature importance analysis, re-tuning models, final train and test with best model parameters, debugging executor OOM issues **(5 hours)** Consolidate NEW overall pipeline steps and re-design diagram with Chad **(2 hours)** <br> **12/6:**  Consolidation of experiment results and write-up on XGBoost, including reviewing other sections **(6 hours)** <br> **12/7-8:** Complete write-up on data leakage and overall model comparison table; Revise data pipeline section to reflect new architecture **(5 hours)** <br> **12/9:** Help review and finalize other report sections, finalize presentation and group planning; Evaluate all model performances for final model selection **(3 hours)**  <br><br> **Not available after 12/9 due to having to travel and prepare for family wedding overseas**<br><br> **Total hours: 74**\n",
    "| Priscilla Siow      |  - Weekly Team Meetings **(5 hours, weekly)** <br> - Scheduled Team Meetings **(5 min, weekly)** <br> - Abstract **(15min, 11/1)** <br> - EDA on OTPW data **(1 hour, 10/26)** <br> - Feature Selection writeup first pass **(1 hour, 10/28)** <br> - Class imbalance research on class imbalance and upsampling implementation **(2 hours, 10/27)**  <br> - Feature engineering writeup first pass **(1 hours, 10/30)** <br> - Train, Test Split planning first pass write-up **(2 hours, 10/30)** | - Scheduling Team Meetings **(5 min, weekly)**  <br> - Implementation of upsampling, downsampling, and class weights **(2 hours, 11/5)** <br> - Baseline model creation (Logistic Regression --previously tested poorly performing Baseline Majority /model) **(12 hours, 11/10, 11/15, 11/20)** <br> - Quality checking pre-processing data **(5 hours, 11/8)** <br> - Correlation Analysis **(5 hours, 11/20)**  <br> - Logistic Regression Feature Selection **(5 hours, 11/15)** <br> - Phase 2 Presentation ownership and delegation **(2 hours, 11/10, 11/18)** - Weekly Team Meetings **(5 hours, weekly)** <br> - Phase 3 planning **(2 hours, 11/23)** <br> - Meeting Notetaker, delegation, and notebook organization in Databricks **(30min, weekly)** - Report Conclusion **(1 hour, 11/23)** <br> - Final Phase 2 Report Review**(2 hour, 11/24)**  <br> - Report Abstract and Project Description **(2 hours, 11/22)** <br> Estimated Total: ~50 Hours | **>Phase 3 Leader** <br> - Bayesian Hyperparameter tuning for Logistic  Regression Model **(10 hours, 11/20-11/23)** <br> - Continued Further Feature Selection and Feature Engineering **(5 hours, 11/21)** <br> - Model Experimenting in MLFlow **(5 hours, 11/23)** <br> - Graph Analysis and creation of graph features **(5 hours, 11/26)** <br> - Schedule and lead weekly team meetings **(2 hours weekly)** <br> Create action plan and timeline for Phase 3, presentation, and final report **(2 hours, 11/19)** <br> - Creation and management of Cluster Usage tracker **(1 hour, 11/20)**  <br> - Final turn in and review of the entire report **(2 hour, 12/10)** <br> - Delegation and completion of assigned presentation and report sections **(2 hours, 12/7)** <br>  - Assist Chad with HW 5 **(2 hours, 11/23)** <br> **Total Estimated Hours**: 50 hours |\n",
    "| Uma Rao Krishnan    |    - **Largely dealing with medical crisis so not able to contribute as much as desired** <br> - Helped with decision tree model (1 hour, 11/1) <br> - Reviewed model pipeline data ingestion, checkpointing and supplemented (2 hours, 10/28, 11/1) <br> - Supplementary EDA (2 hours, 10/28)<br>            |   - Decision Tree Modeling (5 hours, 11/20-11/22) <br> - EDA and chartbuilding for 5 year and one year datasets (7 hours 11/20-11/23) <br> - QC for missing null values (4 hours, 11/19,11/20) <br> -grid search attempts (2 hours 11/15) <br> -sampling  attempts (2 hours 11/11) <br> -presentation preparation (2 hours, 11/16-11/18)              | - Improve decision tree with grid search **(6 hours, 12/2, 12/5)** <br> -Decision Tree incorporate ML flow and improve **(2 hrs 12/3)**  <br> -Fix logging issue **(3 hr 12/10)**  Final report write up, presentation prep, team meetings **(4hrs over last two weeks)** <br> - could not help as much due to back flare up <br> Total: (17h)             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7884bb19-b778-4e52-8a79-0d1c172dc044",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/aestew/261_pix/cdb250f9a9de5d08e9c7cbd74a042cff5657a49b/team_pic.png\" alt=\"Final Project Team Photo.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d2eb896-d9c0-43fd-b271-c05cbb0cd2bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Abstract\n",
    "\n",
    "Our team will leverage weather data from the National Oceanic and Atmospheric Administration (NOAA) and flight data from the US Department of Transportation (US DOT) to predict if flights will arrive more than 15 minutes delayed. The aim of this project is to support US Airlines and reduce their costs associated with delayed arrivals. While preliminary EDA analysis and preliminary research indicate that only 5-10% of flight delays are due to weather, we aim to take a more cohesive approach to identify impacts of individual planes, locations, taxiing, and more to improve current delay models. \n",
    "\n",
    "Our team will use a custom joined data set looking at data from US weather stations closest to each airport and flight delay data to input into machine learning models to categorically predict a 15 minute arrival delay as \"Yes\" or \"No\" by 1 hour before takeoff. Our baseline model is a Logistic Regression model. We picked this as our baseline since it's simple and easy to interpret, and we will improve upon it by implementing more complex models in future iterations. In the immediate term we plan to build models including Random Forest, Decision Tree, XGBoost, and an FT Neural Network. In this phase, we implemented a Random Forest along with our baseline model. In our future steps we plan to improve these models with improved hyperparameter tuning and feature selection. Algorithm quality will be assessed using the following evaluation metrics: Recall, PR AUC, F-score and Precision. Model generalization will be assessed by comparing training and validation data metrics with a goal of having a well generalized model. We are most interested in recall, since we want to focus on the costly impacts of false negatives. Addressing false negatives is important because if a flight is delayed and incorrectly labeled, this could result in a plethora of issues, including financial costs at the operational and compensation levels. Airlines could also take a hit to their reputation from a lack of trust and/or satisfaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b24c0784-c4b7-40e3-8431-20df45a53008",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Project Description\n",
    "\n",
    "Flight delays cause significant inconvenience and have an estimated economic impact of over $30 billion annually. Given the widespread availability of public flight information, there has been extensive research into the causes and prediction of flight delays. The US Department of Transportation began collecting flight data in 1987, with public access available since 1995 and the addition of a 'Delay Reason' field in 2003.\n",
    "\n",
    "Current research involve a delay propagation network that indicates while many delays may be identified as “carrier” or “NAS” (staffing), the underlying reasons may be due to weather and propagated throughout the network (Bombelli & Sallan, 2023). Bombelli and Sallan also noted that different carrier network setups (e.g., hub-and-spoke vs. point-to-point) impact delay times differently. For instance, if there is a major weather event at a hub, almost all flights for that network will be impacted, whereas point-to-point networks will have limited overall impacts. However, for one-off delays, hub-and-spoke networks have more equipment at their hub to help mitigate those risks. The impact of delay propagation is highlighted within previous papers, showing that weather may potentially have more downstream impacts even if the results are coded as “carrier delay.” This gives us some clear options and directions as we continue to dive into the data and build out our models.\n",
    "\n",
    "Since our team is aware of severe class imbalances within the dataset, we believe that accuracy is not sufficient enough of a metric to evaluate the model's performances. For our research, we are more concerned with ensuring the flights that should have been flagged were not missed. Therefore, our primary metric to focus on during model training is recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "049e20c2-90b1-4a2d-9789-5c7f2bcc2e8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Overall Project Timeline\n",
    "<img src=\"https://raw.githubusercontent.com/aestew/261_pix/439740a92689d149ad798373e8f956bff8452d57/Gantt.png\" alt=\"Team 2-1 Gantt Chart\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc092201-bcd2-40c7-817e-c8c8a8a6fcc7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Data Description\n",
    "\n",
    "The primary dataset was sourced from US DOT focusing on departure and arrival delays and reasons for flights from 2015 to 2019. This data was paired with weather data from NOAA for this time period. Supplementary datasets containing station metadata and standardized airport codes for IATA and ICAO standards were used to facilitate joins between the datasets. Additionally, we were provided a super snapshot of the combined datasets (labeled as the On-Time Performance Waiver or OTPW dataset) used foundation for our initial reporting and analysis due to the data completness. For completeness our team defined all columns in each provided dataset with data dictionaries provided in Appendix A, with A.1.1: Flight data, A.1.2: Airport Identification, A.1.3: Weather Station Identification Data, A.1.4: Weather Data. \n",
    "\n",
    "### Data Challenges and Approach\n",
    "While the original OTPW dataset seemed to be joined well, we noticed discrepancies in station location and the timing of weather data to takeoff, which may be due to the fact that the flight timestamps are provided in local time, whereas the weather data is recorded in UTC. In order to ensure accurate joining between flight and weather features, all local flight times must be converted to UTC while adjusting for Daylight Savings. Additionally, it would have been better to include weather conditions from both the origin airport at the time of departure and the destination airport at the time of arrival. For these reasons, our group opted to create a new dataset - herein called **FASW (Flights, Airlines, Stations and Weather)** using new join logic which will be covered in the next section.\n",
    "\n",
    "Another observation was that weather records are generally recorded at various intervals for each station, which limits the granularity needed to interpolate weather conditions before and near the time of departure.  We also found that the weather station metadata for nearest neighbors includes non-local or out-of-state features and places and that weather readings are based on the weather station's location instead of the airports. Since weather conditions matter the most around the airport where airplanes are taking off, we plan to use the nearest station from each airport for weather readings. Additionally, our join will filter for the record closest to 1 hour from takeoff, which is our target prediction time.\n",
    "\n",
    "This analysis only focuses on flights completed to original destination and therefore does not include Cancelled and Diverted flights. These flights were removed from the analysis. \n",
    "\n",
    "### Initial EDA: Flights, Weather, Stations and Airports Raw Tables\n",
    "\n",
    "To understand the data's structure and perform basic analysis, we analyzed the 3-month and 1-year individual tables of weather, flights, stations, and individual airline data. All analysis, calculations, and findings are based on the datasets mentioned in the below table. We have also included the multi-year datasets to show comparison of the data sizes and the expectations of data scale. While most of the analysis is performed on 3 months and 1 year of data, we believe the samples should still generally be reflective of later flight behaviors and is sufficient to identify relationships between different features. We will continue to validate our pre-processing methods and feature engineering strategies iteratively as we scale the analysis for the full duration of flight data.\n",
    "\n",
    "The below table shows a summary of the raw data and its sizes before pre-processing and joining for all timeframes (3M, 6M, 1Y, and 5Y+). More details of the pre-processing and joining workflow can be found below in the [Pre-Processing Section](https://dbc-fae72cab-cf59.cloud.databricks.com/editor/notebooks/2421064614439958?o=4021782157704243#command/2421064614439969).\n",
    "\n",
    "| Dataset | Source | Rows x Columns | Brief Description | Size | Join Keys | % Missing | Duplicates | Null and Missing Value(s) Summary |\n",
    "|---------|--------|----------------|-------------------|------|-----------|-----------|-----------|---------------------|\n",
    "| Flight Info | US DOT | 2,806,942 x 109 (3M)<br/>5,779,024 x 109 (6M)<br/>14,844,074 x 109 (1Y)<br/>74,177,433 x 109 (2015-2021) | Primary Dataset for Analysis. Scheduled and actual flight times, delay reasons, airline, origin/destination airports, and more | 0.01 GB (3M)<br/>0.21 GB (6M)<br/>0.59 GB (1Y)<br/>2.80 GB (2015-2021) | PK - CRS Departure Date<br/>PK - Tail Number<br/>PK - Origin (IATA)<br/>PK - Destination (IATA) | Significant blank data for diversions, Delay and Cancelled Codes and Ground times | All rows duplicated and removed | These columns are not relevant to our analysis as we are not covering diversion or cancelled flights. Delay information is expected to be skewed. |\n",
    "| Weather | NOAA | 30,528,602 x 124 (3M)<br/>61,204,666 x 124 (6M)<br/>74,177,433 x 124 (1Y)<br/>131,937,550 x 124 (2015-2021) | Hourly weather conditions, including temperature, precipitation, wind speed, etc. | 1.11 GB (3M)<br/>2.30 GB (6M)<br/>3.26 GB (1Y)<br/>4.84 GB (2015-2021) | PK - Station ID<br/>Time/Date (UTC) | Over 99% nulls for Monthly, Daily accumulation columns, Backup columns | No Identified Duplicates | Significant nulls in this dataset. Columns for accumulations and backup columns and other columns with nulls were removed as they contain no usable data. |\n",
    "| Stations Data | US DOT | 2,004,169 x 12 | Reference table containing metadata for weather stations, including location and distance to airports | 52.08 MB | PK - Stations ID<br/>FK - Neighbor Call (ICAO) | 0% nulls | No Identified Duplicates | Complete metadata table |\n",
    "| Airport Codes | Datahub.io | 82,780 x 13 | Reference table containing standardized IATA/ICAO codes and airport metadata, such as coordinates | 8.18 MB | PK - ICAO Codes<br/>PK - IATA Codes | icao_code: 90.64%<br/>iata_code: 89.00% | No Identified Duplicates | Airport Codes is joined to Flight Info on IATA number. Analysis showed that 100% of target flights (Continental US + Alaska + HI) have both icao and iata codes in Airport Codes. Missing Codes are primarily for helipads, small airports, sea planes, balloon ports and non-Continental US airports. This means that the join will not omit any data. |\n",
    "\n",
    "\n",
    "Links to raw sources:\n",
    "- [US DOT TranStats Homepage for Flights and Stations](https://www.transtats.bts.gov/homepage.asp)\n",
    "\n",
    "- [NOAA Repository for Weather and Stations](https://www.ncei.noaa.gov/access/metadata/landing-page/bin/iso?id=gov.noaa.ncdc:C00679)\n",
    "\n",
    "- [Airport Codes for IATA/ICAO](https://datahub.io/core/airport-codes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cae57a92-ddb2-40cd-8829-523ff2d39ce7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Custom Join for FASW Dataset\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://raw.githubusercontent.com/aestew/261_pix/d985477b03bce6447c89b77974d00076c62a3717/erd_diagram.png\" />\n",
    "  <br>\n",
    "  <em>High Level ERD of Custom Join showing Primary and Foreign keys from critical join tables</em>\n",
    "</p>\n",
    "\n",
    "\n",
    "#### 1: Joining Flights with Nearest Station\n",
    "Using the flights dataset as the source of truth, we filtered all other data to include only stations and locations relevant to the airports. Additionally, we also filtered for airport codes within the United States since our focus is purely on domestic flights. To optimize our join, we first left joined the smaller tables of airport and station, then left joined the result to the flights table on ICAO code. This resulted in a 1 flight to many stations join. We then used a window function and partitioned by IATA code, sorted by distance to neighbors, and filtered for the station with the lowest \"distance to neighbor\". The `CRS_DEP_TIME` was also converted to UTC to match the respective UTC timezone used for the `DATE` field in the weather data to ensure more accurate joining. \n",
    "\n",
    "#### 2: Final Join with Weather\n",
    "This left us with 2 tables: **Flights joined with Stations** and **Weather**. Because weather had a significant number of records per station (at minimum one weather datapoint every 3 hours per station), we joined each flight with all weather data within a 1-6 hour time-frame from departure. Data was joined using RepartitionbyRange to ensure that epoch values associated with each station were grouped within the same partition to optimize join performance. This left us with several datapoints per departure. Within each Station and Time partition, the remaining datapoints were sorted using partionBy and orderBy and the datapoint closest to 1 hour before departure was chosen. The resulting dataset was then checkpointed and saved, serving as the finalized input for the first stage of the machine learning pipeline.\n",
    "\n",
    "### Post-Processing data analysis\n",
    "Post join EDA and QC included validating join coverage, confirming there were no additional nulls, ensuring the best station was chosen for each departure airport. \n",
    "\n",
    "##### Station to Airport Check \n",
    "\n",
    "Using the 'distance_to_neighbor' field in the Stations table, we can see that all the stations were within 0 miles of the airport. While there were other stations different distances away, our group chose to use the station closest to the airport for immediate weather.  \n",
    "\n",
    "##### Weather Reading to Depature Time\n",
    "\n",
    "To check the difference between 1 hour of planned departure time to weather station reading, we calcualted the difference between the target time (1 hour before planned takeoff) and weather reading in epoch. Looking at a histogram of distributions, we can see that over 99.8% of the distributions are within 1 hour of our target time. \n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "![Difference: Weather reading time to 1 hour from takeoff](https://raw.githubusercontent.com/aestew/261_pix/refs/heads/main/offset%20CRS.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "##### Overall null analysis\n",
    "\n",
    "Analysis of overall nulls from before and after joining show improvment for almost every field. \n",
    "\n",
    "| Column Name | FASW Null (%) | Pre Join: Weather Null (%) | Pre Join: Flights Null (%) |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| HourlyWindGustSpeed | 89.60 | 90.38 | null |\n",
    "| HourlyPresentWeatherType | 87.34 | 88.98 | null |\n",
    "| CARRIER_DELAY | 78.92 | null | 82.56 |\n",
    "| WEATHER_DELAY | 78.92 | null | 82.56 |\n",
    "| NAS_DELAY | 78.92 | null | 82.56 |\n",
    "| SECURITY_DELAY | 78.92 | null | 82.56 |\n",
    "| LATE_AIRCRAFT_DELAY | 78.92 | null | 82.56 |\n",
    "| HourlyPressureChange | 68.89 | 88.27 | null |\n",
    "| HourlyPressureTendency | 68.89 | 88.22 | null |\n",
    "| MeanBase_ft_agl | 36.14 | null | null |\n",
    "| WindEquipmentChangeDate | 34.71 | 88.42 | null |\n",
    "| LowestBase_ft_agl | 32.48 | null | null |\n",
    "| HighestBase_ft_agl | 32.48 | null | null |\n",
    "| BaseRange_ft_agl | 32.48 | null | null |\n",
    "| HourlyPrecipitation | 24.25 | 79.74 | null |\n",
    "| HourlyAltimeterSetting | 20.37 | 35.80 | null |\n",
    "| HourlySkyConditions | 12.11 | 42.75 | null |\n",
    "| HourlySeaLevelPressure | 10.22 | 74.75 | null |\n",
    "| has_few | 7.37 | null | null |\n",
    "| has_sct | 7.37 | null | null |\n",
    "| has_bkn | 7.37 | null | null |\n",
    "| has_ovc | 7.37 | null | null |\n",
    "| overall_oktas | 7.37 | null | null |\n",
    "| overall_cloud_frac_0_1 | 7.37 | null | null |\n",
    "| HourlyWetBulbTemperature | 4.37 | 41.40 | null |\n",
    "| HourlyStationPressure | 4.33 | 40.66 | null |\n",
    "| HourlyWindDirection | 3.92 | 27.60 | null |\n",
    "| HourlyRelativeHumidity | 3.50 | 32.96 | null |\n",
    "| HourlyWindSpeed | 3.50 | 25.43 | null |\n",
    "| HourlyDewPointTemperature | 3.49 | 32.95 | null |\n",
    "| HourlyDryBulbTemperature | 3.49 | 3.03 | null |\n",
    "| HourlyVisibility | 3.47 | 35.02 | null |\n",
    "| REM | 0.24 | 37.80 | null |\n",
    "| ARR_DATETIME_UTC | 0.04 | null | null |\n",
    "| DEP_DATETIME_UTC | 0.01 | null | null |\n",
    "| WX_STATION | 0.00 | null | null |\n",
    "| MATCHED_OBS_TIME_UTC | 0.00 | null | null |\n",
    "*Chart showing null percents from inital data compmared to joined data*\n",
    "\n",
    "##### Total Matching\n",
    "\n",
    "To optimize partitions and prevent significant overloading due to sorting on our window function - as well an ensure we had the most accurate weather data, we limited the range where a weather datapoint could match to a flight to less than 6 hours. This led to some reduction in data, however it will optimize our data pipelines. The below table shows data loss due to non-matching weather data.\n",
    "\n",
    "| Timeframe | % Weather Match | Matched Rows | Un-Matched Rows |\n",
    "|-------|-------|-------|-------|\n",
    "| 3M | 99.99% | 1,338,506 | 1,338,511 |\n",
    "| 6M | 99.99% | 2,781,655| 2,781,663 |\n",
    "| 1Y | 99.98% | 7,197,318| 7,198,116  |\n",
    "| 5Y+ (2015-2021) | 75.23% | 30,836,766 | 40,988,863|\n",
    "\n",
    "\n",
    "\n",
    "#### Data Engineering and Ingestion Checkpoints\n",
    "Two checkpoints were documented in this process:\n",
    "1.  Raw data on flights, weather, stations, and supporting datasets for 3 months, 6 months, 1 year, and 5 years were already checkpointed in the file system. We leveraged these existing datasets to create our own joined OTPW dataset for each timeframe.\n",
    "2. Our custom joined FASW dataset was checkpointed by timeframe (3 months, 6 months, 1 year, and 5 years) and had its own folder. Dataframes were all saved as parquet files. Four folders were generated during this process to store each OTPW join.\n",
    "\n",
    "For full details on the overall pipeline and checkpoint strategy, please refer to the **Overall Pipeline Checkpoint Strategy** under the Machine Learning and Engineering Pipeline section.\n",
    "\n",
    "The final code for our join process can be referenced here: [01 pipeline: final_join](https://dbc-fae72cab-cf59.cloud.databricks.com/editor/notebooks/1792055957781844?o=4021782157704243)\n",
    "\n",
    "#### Join Statistics\n",
    "The below table documents the final sizes of the OTPW dataset and approximate times to run joins for each timeframe, given a cluster with the following specs:\n",
    "\n",
    "- 2-8 Workers: 32-128 GB Memory, 8-32 Cores\n",
    "- 1 Driver: 16 GB Memory, 4 Cores\n",
    "- Runtime: 16.4 LTS\n",
    "\n",
    "| Timeframe | Rows (92 Columns) | Size | Processing Time |\n",
    "|-------|-------|-------|-------|\n",
    "| 3M | ~1.7M | 0.25 GB | 3m 39s |\n",
    "| 6M | ~2.8M | 0.53 GB | 4m 40s |\n",
    "| 1Y | ~7.1M | 1.43 GB | 10m 57s |\n",
    "| 5Y+ (2015-2021) | ~30.1M | 6.29 GB | 1h 49m |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc9c8994-2a47-4f6d-a50d-acb4e4c0dbd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Data Pre-Processing\n",
    "\n",
    "To address the data challenges discussed earlier, we developed our own dataset by joining the raw source files. Quality control will be implemented in all data processing and to ensure data integrity, correct datatypes, and maximize model performance.\n",
    "\n",
    "Final data pre-processing pipelines included cleaning flight, station, airport and weather data to remove significantly co-linear columns (e.g. multiple departure and landing time columns), columns with > 95% nulls. For the flight data, we removed any flights that were cancelled or diverted as they are not part of our analysis. We then removed duplicate columns showing similar information to reduce any multicollinarity. Because the arrival and departure times only constitute the hour and second without the date, we had to apply custom logic to identify and append the correct date to the times to create a full timestamp format. Since the full timestamp was still in local timezones, we leveraged the geographical coordinates to parse the timezone and the respective timestamp in UTC. Given unavoidable seasonal travel periods, we also manually encoded a boolean feature that indicates if a departure date falls within three days (before or after) of a major US holiday, considering flexible travel schedules.\n",
    "\n",
    "Analysis of the NOAA Weather data indicated that 97 out of 124 columns have greater than 95% null data. Due to the nature of machine learning, such sparse null data cannot be properly imputed or processed and therefore these columns were removed. To identify optimal weather stations to associate with each airport, weather data was joined using US DOT data containing information on station distance to airports. Stations with the smallest distance to the airport and the most information were chosen to use for each airport. We realize that limiting the data to the station nearest to the airpot may restrict some of the analysis, as weather patterns in surrounding areas can also impact flights, we believe that this is the most achievable approach given the current timeframe of this project.\n",
    "\n",
    "Hourly numeric data is available for each weather station, including temperature, precipitation and humidity. More dense fields including sky conditions and present weather conditions contained a significant amount of information. To operationlize this data, we separated and parsed the raw encoded observations of the sky and weather conditions using *regex* logic, following the structures shared in the provided documentations.  As the result, we added a several additional raw \"tokenized\" columns that contain the raw encoded versions of the observations.  Afterward, we created a data frame using the provided dictionary in the documentations, which we then used to join our master dataframe and to decode those weather/sky observations. For examples, \"SN:03,FZ:8,FG:2\" was decoded into “Snow, Freezing Rain, Fog”, and \"RA:61,TS:95\" became “Rain, Thunderstorm”. Through this decoding step, we improved the data readability and interpretability, enabling downstream models and analyses to work with clear categorical weather descriptions.\n",
    "\n",
    "### Handling Missing Values and Duplicate Records\n",
    "Within our pipeline, we productized a systematic cleanup of the data focusing on missing values, redundancy, and duplicate records and applied it to all 4 datasets (3m, 6m, 12m, all). Columns with null percentage between ***95%-100%*** were removed as they either contributed nothing or very little (Appendix B). \n",
    "\n",
    "We implemented **feature-specific null handling strategies** tailored to the characteristics and semantic meaning of each feature type. Numerical columns were analyzed individually to determine the most appropriate imputation method for each feature based on its distribution and domain meaning. Features with continuous variables such as temperature and pressure were imputed using custom logic that considered temporal patterns and physical constraints—for instance, temperature nulls were filled using the median temperature for that airport and time period.\n",
    "\n",
    "Binary features representing presence/absence conditions were handled differently, with null values replaced with 0 to indicate the absence of the condition. Cloud height data required specialized treatment where derived calculations were used when partial information was available, otherwise defaulting to 0 to represent clear conditions. Categorical columns with blank or missing values were explicitly encoded as \"Unknown\" to preserve the information that data was missing rather than arbitrarily assigning to an existing category, allowing the model to learn patterns associated with missing categorical information. This differentiated null handling approach ensured that domain knowledge informed data preprocessing rather than applying uniform imputation strategies that might introduce bias or lose valuable signal across diverse feature types.\n",
    "\n",
    "<br>\n",
    "<img src=\"https://raw.githubusercontent.com/aestew/261_pix/6fdc3e9be65cb6d4e09ec59669a36a4ae5262787/newplot.png\" alt =\"Heat Map\" width = 100% />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "41283662-a3b7-49b3-957a-7469f3638ecf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Engineered Features\n",
    "To supplement raw data, our team developed 9 engineered features focused on flight patterns and previous flight arrival. Features are listed in the below table and described below.\n",
    "\n",
    "\n",
    "| Column Name                                   | Data Type   | What It Measures                                                                                                                                                                   |\n",
    "|-----------------------------------------------|-------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| origin_pagerank                               | Double      | Importance of origin airport in the flight network (0.0–1.0). Higher values indicate major hubs such as ATL, ORD, DFW.                                                             |\n",
    "| dest_pagerank                                 | Double      | Importance of destination airport in the flight network (0.0–1.0). Higher values indicate major hubs.                                                                              |\n",
    "| origin_out_degree                             | Double      | Total number of departing flights from the origin airport. Proxy for departure congestion.                                                                                         |\n",
    "| dest_in_degree                                | Double      | Total number of arriving flights to the destination airport. Proxy for arrival congestion and gate availability.                                                                   |\n",
    "| prev_flight_arr_delay_clean                   | Double      | Previous flight’s arrival delay in minutes (same aircraft/tail). Leak-free. Only populated if: (1) previous flight arrived >1h1m before current departure, AND (2) delay ≥ 0.      |\n",
    "| crs_time_to_next_flight_diff_mins             | Double      | Planned turnaround time in minutes: scheduled departure minus previous scheduled arrival. Based on airline schedule only (no leakage).                                             |\n",
    "| prev_crs_arr_time_utc                         | Timestamp   | Previous flight’s scheduled arrival time (UTC). Used for reference/debugging.                                                                                                      |\n",
    "| prev_crs_arr_time_utc_unix                    | Long        | Previous flight’s scheduled arrival time in UNIX timestamp format. Helper column for calculations.                                                                                 |\n",
    "| actual_to_crs_time_to_next_flight_diff_mins_clean | Double  | Actual turnaround time in minutes: scheduled departure minus previous actual arrival. Leak-free (only populated if previous arrival >1h1m before scheduled departure).                |\n",
    "\n",
    "\n",
    "\n",
    "## Graph Features\n",
    "Based on our extensive literature reviews combining with common knowledge, the network structure of the U.S. aviation system is quite complex.  Therefore, in order to capture its complexity, we proceeded to engineer graph-theoretic features on the full 5-year FASW dataset by constructing the directed weighted graph where nodes represent airports and edges representing flight routes, edge weights correspond to the total number of flights on each route. The graph construction process aimed to aggregate the flight counts across all origin-destination airport pairs then utilizing NetworkX combined with Spark's scalability for complete metric calculation.\n",
    "\n",
    "This complexity is demonstrated when analyzing delay patterns by prodivded reasons, which showed the volume of top delayed routes and their corresponding primary delay reasons. As observed, the routes with the largest number of delays, such as SFO to LAX (32,563 delays) and vice versa (32,494 delays), and ORD to LGA (25,984 delays), illustrate the high volume and bidirectional nature of significant traffic on key routes, underscoring the importance of treating these as weighted edges in our network analysis. Furthermore, the diagram reveals that the vast majority of delays across these top routes are attributed to 'NAS' (National Airspace System) and 'Late Aircraft' (Carrier), indicating that the most frequent disruptions are operational and systemic rather than weather-related, reinforcing the need for network-structure features like centrality to predict cascade effects.\n",
    "\n",
    "<br>\n",
    "<img src=\"https://raw.githubusercontent.com/aestew/261_pix/db7ef66312481a8af6b23e803896f649bc4a9a8f/sankey.png\" alt=\"Distribution of the Time Differences Between Departure and Weather\" width = 100% >\n",
    "\n",
    "For the added features, we extracted 4 key centrality metrics.  First, origin_pagerank and dest_pagerank, which identify airports that are not highly connected but also connected to other important airports, indicating critical hubs where delays cascade through multiple downstream connections. Second, out-degree centrality (origin_out_degree) counts total outbound flights that aim to capture airports with extensive spoke networks that potentially create many delay propagation opportunities. And last, In-Degree Centrality (dest_in_degree) measures inbound flights, identify airports that act as receiving hubs where delays may accummulate.  Once these metrics were computed, we then joined them with our main flight dataset using origin and destination airport codes.  For airports that are not present in the network due to minimal connectivity, we filled the graph features with zeros.\n",
    "\n",
    "These graph features are expected to complement the traditional operational and weather predictors by encoding each airport's structure importance within the aviation network. Our assumption is that airports with high PageRank and out-degree centrality should be at higher risk experiencing delays because disruptions at these locations have larger network-wide impacts.  Meanwhile, airports with higher in-degree may also show high delays probability due to accummulating disruptions across multiple origins. By explicitly quanityfying these network positions, all of our models can distinguish better that a weather delay at a higher centrality airport during peak hours would most likely create a higher downstream delay risk than ones with lower connectivity. \n",
    "\n",
    "## Temporal Features\n",
    "\n",
    "While graph features show flight route trends, previous flight information is critical to understanding if the next consecutive flight will be on time. In order to capture this data, we sorted flights by tail number and departure time. This allowed us to see previous flight scheduled and actual arrival time. With this, we calculated actual vs. scheduled turnaround time and scheduled turnaround time. \n",
    "\n",
    "These features significantly improved model training, particularily  _Actual vs. Scheduled Turnaround Time Difference (mins) -- `actual_to_crs_time_to_next_flight_diff_mins_clean` -- reduced impurity for Random Forest by 28%. \n",
    "\n",
    "\n",
    "## Data Leakage \n",
    "\n",
    "Calculating graph and temporal features introduced a meaningful risk of data leakage. Our initial approach computed graph features using the full dataset, which would have allowed information from future periods to influence past observations. To mitigate this, we now propose recalculating graph features using only the training portion of each rolling window. This adjustment fully removes leakage for the training data and limits it for the validation window, where some unavoidable look-ahead remains due to how rolling windows are structured.\n",
    "\n",
    "Temporal features were limited to arrivals before the 1 hour window (limited to 1 hour and 1 minute from scheduled departure). Additional leakage checks were in place for training data to ensure that no flight information was provided if not outside the 1 hour before takeoff window.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f8367340-46b6-4a56-83d4-93d51f89175e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "## Features Families\n",
    "In phase 3, our EDA will dive into three critical feature families that capture the temporal, operational, and environmental factors influencing flight delays. Our goal is to solidify our feature engineering strategy and to validate the inclusion of key predictors in our final modeling dataset.\n",
    "\n",
    "### Weather Features Family\n",
    "At the start, weather has been considered as a critically important feature family for predicting flight delays.  Through several analysis including the relationship between the intensity, duration, and type of precipitation and observed delay times, our EDA established a strong and statistically-based emphasis on the importance of these variables and how essential they are for our models.\n",
    "\n",
    "#### Precipitation, The Weather Wears Prada\n",
    "Using the mutual knowledge, precipitation is the most suspicious feature that would increase the delay risk significantly. At high level, the stark contrast between flights experiencing precipitation versus those without shows delay rates increasing from 18% in clear conditions to 27% when any precipitation is present.  This 9% difference differential underscores how light rain or drizzle can potentially create operational challenges that ripple through the aviation system.\n",
    "\n",
    "At this level of magnitude, precipitation is particularly notable because it represents an aggregate measure: precipitation encompasses everything from light drizzle to heavy snow and thunderstorms, yet even this broad categorization shows strong power for delay prediction. Therefore, even at this bird-eye view of an analysis, this finding validated our decision to include precipitation along with its categorical values (i.e. rain, snow, thunderstorm, freezing conditions) in our model as the combination captures both the presence of challenging weather and the specific operational constraints each precipitation type may impose.\n",
    "\n",
    "#### Cloudy with a Chance of Delay\n",
    "Last, as we looked into the effect of cloud ceiling heights as a variable, we found a very unexpected non-monotonic relationship with delays that reveals the operational complexity of low-visibility conditions. Very low ceilings below 500 feet show an 18% delay rate, while medium-low ceilings in the 500-1000 foot range peak at 23% delays—the highest of any ceiling category. Interestingly, higher ceilings in the 1000-2000 foot range moderate back to 19% delays, creating a dipping pattern rather than the linear relationship that we might expect.\n",
    "\n",
    "<br>\n",
    "<img src=\"https://raw.githubusercontent.com/aestew/261_pix/cdf6f2e59e692a7a11aa77489ae89b5617d1d3cf/precipitaiton_and_cloud.png\" alt=\"Distribution of the Time Differences Between Departure and Weather\" width = 100% >\n",
    "\n",
    "#### Gone with the Wind\n",
    "Another variable that we took a deep dive in is wind conditions as it presented a more nuanced relationship with delay rates, showing a progressive escalation as wind speeds increase. According to the visualization below, alm to light winds (0-5 mph) and moderate winds (5-15 mph) produce indistinguishable delay rates at 19% and 18% respectively, suggesting that normal operations can accommodate winds up to 15 mph without significant impact. However, as winds intensify into the 15-25 mph range, delay rates remain stable at 19%, before jumping noticeably to 23.7% when winds exceed 25 mph, which is a significant yet understandable increase. This threshold around 25 mph reflects expected operational crosswinds limitations and reduced airport acceptance rates that tend to occur when dealing with winds challenge during takeoff and landing.  \n",
    "\n",
    "##### Temporal and Seasonal Patterns\n",
    "The pattern of wind speeds reveals a pronounced mid-day intensification that coincides with peak flight operations with average wind speeds remain relatively calm during overnight and early morning hours (4-6 mph from midnight to 6 AM). It then escalate dramatically between 8 AM and 2 PM, peaking at 10.5 mph around noon. This daytime wind seems like a reflection of thermal heating and atmospheric mixing with winds remaining elevated at 9-10 mph through mid-afternoon before gradually decreasing back down to 6-7 mph by evening. This pattern, perhaps, is the reason why there is a compounding effect where wind-related operational constraints coincide precisely with the day's highest flight volumes, amplifying the cascading delay dynamics we observed later in our temporal analysis.\n",
    "\n",
    "In terms of seasonality pattern, our analysis shows even more and unexpected variation with spring months (March-May) experiencing the highest average wind speeds—March peaks at 10.4 while summer months (June-August) experience between 8.3-8.5 mph and fall and winter show intermediate speeds around 8.8-9.2 mph. These patterns really help explain why spring typically shows elevated delay rates despite generally favorable weather.\n",
    "\n",
    "<br>\n",
    "<img src=\"https://raw.githubusercontent.com/aestew/261_pix/d5a418cded730eb75d67da2cd5775d0826c46880/masterwind.png\" alt=\"Distribution of the Time Differences Between Departure and Weather\" width = 100% >\n",
    "\n",
    "##### Does size really matter?\n",
    "For additional validation, we created a scatterplot to examine the relationship between average wind speed, airport size, and delay rates.  This analysis reveals that wind impact varies substantially by airport classification, reflecting the critical role of runway configuration in mitigating effects of wind speed. According to FAA Advisory Circular 150/5300-13A, airport runway orientations are designed to provide at least 95% wind coverage within aircraft-specific crosswind limits, typically 10.5 knots (12 mph) for smaller aircraft, 13 knots (15 mph) for intermediate aircraft, and 16 knots (18 mph) for larger aircraft.\n",
    "\n",
    "According to the graph, large airports cluster mainly in the 8-11 mph wind range with delay rates spanning 10-25%, reflecting their superior runway infrastructure. Understandably, they typically feature multiple runways with diverse orientations, allowing controllers to select the most favorable runway based on real-time wind conditions and maintain higher acceptance rates even during wind events. On the other hand Medium airports show a much wider variability observing that some airports tend to experience winds as low as 5 mph while others face sustained 12+ mph conditions—with delay rates spanning 10-30%, suggesting the dual-runway configurations and alignment with prevailing winds provide moderate operational flexibility.Unfortunately, small airports demonstrate the most vulnerability: several experiencing moderate 8-10 mph winds show delay rates exceeding 30-35%. With limited runway options and designs optimized only for light aircraft crosswind thresholds (10.5 knots).  Therefore, even moderate winds can push operations beyond safe limits more frequently than at larger facilities. \n",
    "\n",
    "This specific analysis really reinforces our feature selection and modeling strategy of including airport-specific identifiers and wind direction features alongside wind speed metrics, as the interaction between wind vectors and airports' sizes determine operational impact. The weak overall correlation also validates that wind aone acts as a conditional constraint rather than an independent driver for delay rate because its impact depends entirely on other variables, in this case, airport sizes, consistent with FAA design principles prioritizing wind coverage optimization.\n",
    "\n",
    "### Airline & Carrier - Operational\n",
    "\n",
    "Our analysis on the weather features family proved to us that identical weather conditions produce dramatically different delay outcomes depending on airport location.  This led us to our analysis on more operational/carrier-specific features that mediating weather impacts in ways that aggregate weather statistics alone cannot capture.\n",
    "\n",
    "#### Location Location Location!\n",
    "After extensive analysis on weather feature family, our first instinct is to explore if the locations of the airports have any direct relationship there. At high level, we put together a bidirectional comparison reveals important asymmetries in how delay burdens distribute across the U.S. aviation network in terms of cities. Chicago emerges as the nation's most significant delay epicenter, generating more than 420,000 origin delays while receiving 363,671 destination delays. This ties back to our previous insights from analysis on weather, reflecting Chicago's convergence of weather vulnerabilities with airspace .\n",
    "\n",
    "Second, Atlanta shows the opposite pattern, functioning as a delay sink with 270,105 destination delays versus 299,467 origin delays, suggesting robust infrastructure and more favorable weather. Meanwhile, Denve and Dallas/Fort Worth display near-balanced profiles, though Denver's high-delay status reflects compounding effects of high-altitude operations and rapidly changing mountain weather we identified earlier.\n",
    "\n",
    "Other notable cities, such as Newark, Las Vegas, and Phoenix, also receive significantly more destination delays than they originate, serving as terminal points where network delays accumulate. Oon the other hand, Charlotte and San Francisco, generated more origin delays, which may reflect the marine layer fog and wind conditions that disproportionately impact departures. These insights motivated our examination of airport-specific features as critical mediating factors.\n",
    "\n",
    "<br>\n",
    "<img src=\"https://raw.githubusercontent.com/aestew/261_pix/79fd68c27829e74f13689734839bca5f7e5ed2cc/cities.png\" alt=\"Cities Summary\" >\n",
    "\n",
    "#### Total Flights & Delays Summary by Carriers\n",
    "As stated in phase 2, we began our analysis examining delays by carrier from our newly joined 1-year FASW dataset.  For this phase, we updated the table below, \"Percentage of Flights and Total Delays by Airline,\" summarizes these delay findings using our 5-year FASW dataset between 2015 and 2019. \n",
    "\n",
    "We used this table below to examine each airline and see their percentage of delays, which is lucrative information for carriers to look at and compare their competition.  At high level, the data reveals a major 14.5 percentage point spread between the best and worst performing carriers as Hawaiian Airlines (HA) demonstrates exceptional operational reliability with just 10.63% of flights delayed—likely benefiting from point-to-point Pacific routes with minimal connecting-flight complexities. \n",
    "\n",
    "On the other hand, budget airlines such as Frontier (F9) and JetBlue (B6) experience delay rates exceeding 25%, reflecting aggressive scheduling practices, limited aircraft redundancy, and hub operations at congested airports like New York JFK and Denver. Other budget friendly carriers, Spirit (NK) and Allegiant (G4), showed delay rates of 21.47% and 21.36% respectively, consistent with their business models that prioritize aircraft utilization over schedule padding.\n",
    "\n",
    "Looking into more mainstream carriers, Delta (DL) emerges as the clear leader with only 13.71% delay rate despite operating nearly 4.6 million flights, which suggested superior operational processes and resource allocation. American (AA) and United (UA) show higher delay rates around 19%, while Southwest (WN)—despite being the highest-volume carrier with over 6.4 million flights—maintains a moderate 18.87% delay rate through its point-to-point network model and operational flexibility from operating a single aircraft type.\n",
    "\n",
    "Other minor regional carriers, SkyWest (OO) and Endeavor (9E), were able to achieve moderate performances at 18.31% and 17.96% respectively, while other carroers like ExpressJet (EV) and Mesa (YV) struggled big times with delay rates exceeding 20%. From our initial assumptions, this result among regional carriers likely reflects differences in hub airport congestions and inefficient operational and maintenance. \n",
    "\n",
    "| Carrier Code | Carrier Name | num_flights | num_delayed_flights | Delay % | % of Total Flights | % of Total Delayed Flights |\n",
    "|---|---|---|---|---|---|---|\n",
    "| B6 | JetBlue Airways | 1,299,968 | 326,930 | 25.15 | 4.22 | 5.71 |\n",
    "| F9 | Frontier Airlines | 530,287 | 132,546 | 25.00 | 1.72 | 2.31 |\n",
    "| VX | Virgin America | 216,340 | 50,786 | 23.48 | 0.70 | 0.89 |\n",
    "| NK | Spirit Airlines | 758,743 | 162,938 | 21.47 | 2.46 | 2.84 |\n",
    "| G4 | Allegiant Air | 198,992 | 42,512 | 21.36 | 0.65 | 0.74 |\n",
    "| MQ | Envoy Air (American Eagle) | 877,946 | 183,499 | 20.90 | 2.85 | 3.20 |\n",
    "| YV | Mesa Airlines | 429,680 | 89,379 | 20.80 | 1.39 | 1.56 |\n",
    "| OH | Comair | 547,431 | 111,887 | 20.44 | 1.78 | 1.95 |\n",
    "| EV | ExpressJet Airlines | 1,684,391 | 335,284 | 19.91 | 5.46 | 5.85 |\n",
    "| AA | American Airlines | 4,249,608 | 829,568 | 19.52 | 13.78 | 14.48 |\n",
    "| UA | United Airlines | 2,824,191 | 540,283 | 19.13 | 9.16 | 9.43 |\n",
    "| YX | Republic Airlines | 625,867 | 118,606 | 18.95 | 2.03 | 2.07 |\n",
    "| WN | Southwest Airlines | 6,454,124 | 1,218,032 | 18.87 | 20.93 | 21.26 |\n",
    "| US | US Airways | 191,471 | 35,849 | 18.72 | 0.62 | 0.63 |\n",
    "| OO | SkyWest Airlines | 3,429,319 | 627,812 | 18.31 | 11.12 | 10.96 |\n",
    "| 9E | Endeavor Air | 491,350 | 88,245 | 17.96 | 1.59 | 1.54 |\n",
    "| AS | Alaska Airlines | 1,034,502 | 162,455 | 15.70 | 3.35 | 2.84 |\n",
    "| DL | Delta Air Lines | 4,595,569 | 629,913 | 13.71 | 14.90 | 11.00 |\n",
    "| HA | Hawaiian Airlines | 398,361 | 42,354 | 10.63 | 1.29 | 0.74 |\n",
    "| **Total** |  | **30,837,483** | **5,730,878** | **18.58** | **100.00** | **100.00** |\n",
    "\n",
    "#### Delay Minutes & Distribution by Airport Size\n",
    "Another variable/feature we paid attentions to is airport size and its nuanced relationship with delay frequency and duration. The scatter plot below mapped the percentage of delayed flights (y-axis) against average delay duration when delays occur (x-axis), with bubble size representing total flight volume and color indicating airport classification.\n",
    "\n",
    "Large airports (orange) in the lower-left quadrant, exhibiting delay rates between 15-25% with relatively shorter average delays of 30-45 minutes with major airports like Denver (DEN), Dallas/Fort Worth (DFW), and Chicago O'Hare (ORD) really stood out as it exhibited the understandable assumption that high traffic volumes create higher frequency in delays even with robust infrastructure and operational resources enable faster recovery. Meanwhile, medium airports (blue) display theri versatility, spreading across a wider range across the axis with average delays extending beyond 60 minutes due to its lack of operational flexibility from their larger counterparts on top of the regular congestion challenges.\n",
    "\n",
    "<br>\n",
    "<img src=\"https://raw.githubusercontent.com/aestew/261_pix/fee7a8560275afaa4706711dd81ed1a5828455e8/airport_by_size.png\" alt=\"Delay Minutes by Airport Size\" >\n",
    "\n",
    "#### Average Flight Distance and Total Flights by Airline\n",
    "ACcording to the Airline Delay Summary table, another suspicion that we had is the relationship between flight distance and carrier operations reveals fundamental strategic differences that influence delay patterns. \n",
    "\n",
    "From the visualization below, despite bigger and stronger operational support, carriers operating longer average distances (i.e. Alaska (AS), United (UA),etc.) most likely would face different operational challenges than versus short-haul regional operators like Comair (OH), Envoy (MQ), and ExpressJet (EV). High-volume carriers Southwest (WN) and SkyWest (OO) that tend to manage dense schedules tended to create huge exposure to delay propagation where one single disrupted incident or aircrate can cascade through numerous downstream flights.\n",
    "\n",
    "With that being said, our analysis suggested that flight distance would have moderate correlations with scheduled elapsed timeas distance captures route complexity and aircraft performance factors, while elapsed time reflects schedule padding decisions and expected ground operations.  What we find interesting is that even carriers with shorter average distances don't necessarily achieve better on-time performance.  For example, regional carriers that usually have below-500 mile routes often experience higher delay rates than their opposing partners.  These complexities and nuances are one of the reasons why carrier identity, distance, and elapsed time all merit inclusion as distinct features in our models.\n",
    "\n",
    "#### Geographic Concentration of High-Delay Routes\n",
    "To strengthen our assumptions, we created a visualization that highlighted critical geographic patterns in delay concentration by using the top five major airports, Chicago O'Hare (ORD), Denver (DEN), Dallas/Fort Worth (DFW), Atlanta (ATL), and Charlotte (CLT), serving as the primary nodes for the nation's most delay-prone routes, domestically. At first glance, these airports serve as super-connectors in the U.S. aviation network and their prominence in high-delay routes reflects both their operational complexity and their vulnerability to weather-related disruptions (i.e. Denver's high altitude location and its susceptibility to weather changes)\n",
    "\n",
    "Denver and Chicago appeared as the critical bottleneck with thick route clusters that expanded to both coasts and throughout the interior. The routes' color scale reveals that many of these high-delay routes experience delay rates exceeding 30-35% (deep red), nearly double the national average. This map helped validate our inclusion of origin/destination airport identifiers and their spatial coordinates as model features.\n",
    "<br>\n",
    "<img src=\"https://raw.githubusercontent.com/aestew/261_pix/6b204ddc0e6e1eb0049b9d5c65f283b6e206506a/avg_dist_plus_map.png\" alt=\"Average Distance by Airlines and Delay Route Map\" width = 100% >\n",
    "\n",
    "### Time-based / Temporal Features\n",
    "#### Delay Patterns by Date of Month\n",
    "As we now work with 5 full year worth of data, the daily trends in on-time and delayed flights validated our assumption in Phase 2 with consistent and predictable patterns throughout the month as on-time flights remain substantially higher each day (typically in the 180k–200k range) while delayed flights fluctuate between 40k–55k, highlighting the importance of class imbalance consideration throughout date of month. Unsurprisingly, what truly stood out to us here is that both classes show very stable patterns with very minimal variation, suggesting that day-of-month itself would carry quite limited independent predictive power beyond potential end-of-month effects (31st day of the month), where both on-time and delayed counts drop sharply to approximately 105k on-time and 25k delayed flights since not all months have 31 days.  \n",
    "\n",
    "#### Worst vs. Non-worst Hours to Fly\n",
    "Now, as we get to the hourly level, the heatmap reveals one of the most powerful predictive patterns: the systematic escalation of delays throughout the day combined with pronounced day-of-week effects.  Observely, delay rates tended to progress from a baseline of 8-11% during early morning hours (4-6 AM) across all days and slowly climbing to peak rates of 27-30% during evening departures (18-21 hours). This extreme spike truly reflected the \"peak hours\" of air travel and the cascading nature of aviation operations, where early disruptions propagate through aircraft rotations and crew pairings as the day advances.\n",
    "\n",
    "In terms of travel day of week, Thursday remained as the highest-risk day of the week, with delay rates reaching approximately 29.7% during late evening departures (hour 19), followed closely by Friday at 28.1% and Sunday at 27.8%—all days associated with peak business and leisure travel demand. On the other hand, Tuesday and Wednesday are the clear winners with the lowest delay rates across most hours, with mid-day Wednesday departures achieving rates as low as 9.9%.  Remarkably, the \"red-eye\" hour 3 (3 AM departures) also shows extreme variability by day, ranging from 9.3% on Wednesday to 45% on Monday even though these off-putting slots represent limited flight operations and may reflect irregular operations or maintenance-induced delays.\n",
    "\n",
    "This relationship between the temporal features truly validates our decision to consider these features separately rather than aggregating them, as their interaction effects are essential for capturing the true complexity of delay propagation dynamics in the aviation system.\n",
    "\n",
    "<br>\n",
    "<img src=\"https://raw.githubusercontent.com/aestew/261_pix/31f072886ef4a5b1c3a34ab7cee20e3e09f5eabb/updated_combine_graph_dayweek.png\" alt =\"Date of Month Trend\" />\n",
    "\n",
    "### Graph Features Family\n",
    "#### Top 10 Airports by PageRank\n",
    "\n",
    "The PageRank results reveal a clear structure in the U.S. air transportation network: major metropolitan hubs dominate network centrality because they serve as primary connection points for both regional and national air travel. Airports located in the country’s largest and most interconnected cities consistently achieve the highest PageRank scores, reflecting not only their large passenger volumes but also the diversity and density of their incoming and outgoing routes. The top ten airports by PageRank—Atlanta (ATL), Chicago O’Hare (ORD), Dallas/Fort Worth (DFW), Denver (DEN), Los Angeles (LAX), Minneapolis–St. Paul (MSP), Charlotte (CLT), San Francisco (SFO), Houston (IAH), and Phoenix (PHX)—stand out as critical nodes that link multiple regions of the country. These hubs function as key transfer points, support numerous high-frequency routes, and maintain strong connectivity even across geographically distant markets. Their high PageRank values illustrate their importance in sustaining the efficiency and resilience of the broader U.S. air traffic network.\n",
    "\n",
    "When comparing origin PageRank to destination PageRank, we observe that the rankings and magnitudes are nearly identical. This similarity arises because the U.S. domestic air network is highly reciprocal: most major airports have balanced flows of incoming and outgoing flights, and the underlying graph structure for origins mirrors that of destinations. In other words, the same airports that serve as major starting points for passenger itineraries are also major endpoints. As a result, the PageRank algorithm assigns nearly the same centrality scores whether we compute it on the origin graph, the destination graph, or the full directed network. This close alignment reinforces the interpretation that these major hubs are structurally indispensable in both sending and receiving traffic, underscoring their importance in sustaining the connectivity and resilience of the overall system.\n",
    "\n",
    "**Top 10 Origin and Destination by PageRank**\n",
    "\n",
    "![](https://raw.githubusercontent.com/aestew/261_pix/824b2b9c6af954fdbbf73417e1cc2b6d71673a99/pagerank_barchart.PNG)\n",
    "\n",
    "**Map of Top 10 Airports by PageRank**\n",
    "\n",
    "![](https://raw.githubusercontent.com/aestew/261_pix/main/pagerank_map.PNG)\n",
    "\n",
    "The network graph below illustrates the Top 10 PageRank airports (blue) and their most frequent destination airports (green), providing a visual overview of the major routes connected to highly influential hubs. The size of each node reflects its relative PageRank score, highlighting which airports hold the greatest structural importance in the network. The connecting arrows represent the most heavily traveled routes, allowing us to see not just where these major hubs are located geographically, but also how traffic flows outward from them. Together, the layout reveals clusters of connectivity, directional patterns in flight volumes, and the central role these top airports play in linking regional and cross-country travel.\n",
    "\n",
    "**Network Chart**\n",
    "\n",
    "![](https://raw.githubusercontent.com/aestew/261_pix/824b2b9c6af954fdbbf73417e1cc2b6d71673a99/Network%20Graph.PNG)\n",
    "\n",
    "**Table of Analyzed Graph Features**\n",
    "#### Graph Features\n",
    "| Feature Name                                       | Description                                                     |\n",
    "|----------------------------------------------------|-----------------------------------------------------------------|\n",
    "| origin_pagerank                                    | Rank importance of origin airport; higher = major hub          |\n",
    "| dest_pagerank                                      | Rank importance of destination airport; higher = major hub     |\n",
    "| origin_out_degree                                  | Total number of departing flights from origin airport          |\n",
    "| dest_in_degree                                     | Total number of arriving flights to destination airport        |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "44cc7f96-a53c-45d6-97bc-ef62ff3e88a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Feature Selection\n",
    "\n",
    "For feature selection, we focused on selecting features for our baseline, Logistic Regression, model. Since it's industry practice to compare the same feature set for all models, we will be using features from our baseline model to test against our other models. We removed highly correlated features using VIF, captured non-linear dependencies using Mutual Independence, and conducted Point Biserial Correlation Analysis. These methods were selected due to the following reasons:\n",
    "\n",
    "- **Variance Inflation Factor (VIF)**: Helps identify and remove multicollinearity among numeric features. Highly correlated predictors can destabilize Logistic Regression coefficients, making the model less interpretable and potentially inflating standard errors. Removing these ensures more stable and reliable model estimates.\n",
    "\n",
    "- **Mutual Information (MI)**: Captures non-linear dependencies between features and the target. While Pearson correlation only detects linear relationships, MI can detect complex associations that could improve predictive performance, ensuring that important non-linear signals are not overlooked.\n",
    "\n",
    "- **Point-Biserial Correlation**: Measures the relationship between numeric features and a binary target. This method is ideal for Logistic Regression, as it quantifies how strongly a numeric feature separates the two target classes, helping identify features most predictive of the outcome.\n",
    "\n",
    "#### Baseline Model: Logistic Regression\n",
    "\n",
    "Since Logistic Regression works best when all input features are meaningful numeric values, we first used VIF to remove features that displayed multicollinearity and also selected numerical features that were log-transformed since they reduce skew. We also included a selected OHE features that had low VIF score. Lastly, the temporal features (MONTH and DAY_OF_WEEK) were also dropped and replaced by cyclic sine/cosine features representations of MONTH and DAY_OF_WEEK. \n",
    "\n",
    "The table of selected features with their VIF scores is located in **Appendix D**\n",
    "\n",
    "#### Correlation Analysis\n",
    "\n",
    "Further correlation analysis was performed on selected features that had a VIF score of less than 5. After features were selected, we performed a Point Biserial Correlation Analysis. Since our target variable is ARR_DEL15 and it's a binary (0 or 1) output, and we focused on our numeric features for the Logistic Regression model, a Point Biserial Correlation Analysis is the best for our use case. Specifically, Point-biserial correlation is a special case of Pearson correlation where feature variables are continuous (numeric feature) and our target variable is binary (0/1 target). \n",
    "\n",
    "Mathematically, it’s equivalent to computing the difference in means of the numeric variable for the two groups of the binary variable, standardized by the overall standard deviation.\n",
    "$$\n",
    "r_{pb} = \\frac{\\bar{X}_1 - \\bar{X}_0}{s_X} \\cdot \\sqrt{\\frac{n_1 n_0}{n^2}}\n",
    "$$\n",
    "\n",
    "Based on our selected features, we created a quick table below of our results from conducting Point Biserial Correlation. \n",
    "\n",
    "**Summary Interpretation of Point Biserial Correlation**\n",
    "| Feature                | Correlation | Interpretation                            |\n",
    "| ---------------------- | ----------- | ----------------------------------------- |\n",
    "| CRS_DEP_TIME           | 0.245       | Scheduled departure time is the most informative/correlated |\n",
    "| CRS_ARR_TIME           | 0.202       | Scheduled arrival time is correlated and informative for predicting delays |\n",
    "| HourlyRelativeHumidity | 0.154       | More humid → slightly more likely delay   |\n",
    "| ORIGIN_LONG            | 0.066       | Very weak effect                          |\n",
    "| has_ovc, rain          | 0.05–0.06   | Slightly associated with delays           |\n",
    "| Most other features    | <0.05       | Negligible linear effect                  |\n",
    "\n",
    "Below is a barchart of **Point Biserial Correlation** of all features selected for the Logistic Regression Model\n",
    "\n",
    "![](https://raw.githubusercontent.com/aestew/261_pix/52b7c859d6afb73f6e0ba1dfa8eba9891627529a/Screen%20Shot%202025-11-24%20at%203.32.37%20PM.png)\n",
    "\n",
    "Below is a **Summary Interpretation of Mutal Independence Analysis (Top 5 Features)**. A full table of Mutual Independence results (with all features) is located in **Appendix E**\n",
    "| Feature                | MI      | Interpretation                                                                 |\n",
    "|------------------------|---------|-------------------------------------------------------------------------------|\n",
    "| CRS_DEP_TIME           | 0.0366  | Scheduled departure time is the most informative; certain times predict target.|\n",
    "| CRS_ARR_TIME           | 0.0360  | Scheduled arrival time is highly predictive; reflects time-of-day patterns.   |\n",
    "| OP_CARRIER_FL_NUM      | 0.0202  | Specific flight number matters; some flights may consistently differ in outcome.|\n",
    "| HourlyRelativeHumidity | 0.0180  | Weather factor (humidity) influences the target; environmental impact is present.|\n",
    "| ORIGIN_LONG            | 0.0116  | Geographic location of the departure airport contributes to prediction.       |\n",
    "\n",
    "Below is also a heatmap of all the selected features used in the Logistic Regression model\n",
    "\n",
    "![](https://raw.githubusercontent.com/aestew/261_pix/762179622bc8cd2c4cc7e9d753436bdafc15542f/heat_map_lr.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fdcbdf7a-6c36-471f-abd9-e0de241c936c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Data Leakage\n",
    "\n",
    "Data leakage occurs when information from the target variable (`ARR_DEL15`) or information that would not be available at the time of prediction (1 hour before schedule departure) is included in the features during model training. An example of this would be to use a delay reason to predict whether a delayed flight has occurred, which would only be information available after the flight has departed. Because our goal is to be able to predict whether a flight will be delayed before its scheduled departure, including these features would create a trivial model.\n",
    "\n",
    "To prevent data leakage, we reviewed all features and removed any flight operational data that would typically not be known prior to the scheduled flight departure. This included fields that are determined during or after the flight has departed, such as:\n",
    "\n",
    "| Flight Info After Scheduled Departure | Delay Indicator Flags |\n",
    "|---|---|\n",
    "| - `DEP_TIME`<br>- `TAXI_OUT`<br>- `WHEELS_OFF`<br>- `WHEELS_ON`<br>- `TAXI_IN`<br>- `ARR_TIME` <br>- `ACTUAL_ELAPSED_TIME`<br>- `AIR_TIME` | - `DEP_DELAY` <br>- `DEP_DEL15`<br>- `DEP_DELAY_GROUP`<br>- `ARR_DELAY`<br>- `ARR_DEL15`<br>- `ARR_DELAY_GROUP`<br>- `DIVERTED`<br>- `CANCELLED`<br>- `CANCELLATION_CODE`<br>- `LATE_AIRCRAFT_DELAY`<br>- `WEATHER_DELAY`<br>- `NAS_DELAY`<br>- `SECURITY_DELAY`<br>- `CARRIER_DELAY` |\n",
    "\n",
    "In fact, initial training attempts showed that leaving the delay types in the dataset led the model to predict the delays almost perfectly, with > 0.98 scores across the board. This is misleading because a perfect prediction on training data when using future information suggests that the model is directly learning from the answer and is no better from including the target variable in the training dataset as well. Because these features act as a proxy for the target variable, we removed the features entirely from all datasets.\n",
    "\n",
    "The additional temporal lag features were created based on the performance of the previous flight flown by the same aircraft. We defined a prediction cutoff time 1 hour from the current flight's scheduled departure time, and only the actual arrival data of the previous flight was used to calculate the new features if the previous flight's actual arrival occurred before the prediction cutoff. Otherwise, the feature was set to null to guarantee that no information from an event that occurred too close to or after the prediction event was used.\n",
    "\n",
    "To note, we currently calculated the graph pagerank using the entire 5 year dataset, but are propsing to update this to calcualte on only the training set and re-join to the test set. Currently data leakage here is at a minimum as flight trends from major airports have not changed significantly in this time frame. Additionally, to optimize this feature, it should be calculated on only the training set prior to the validation for each specific instanct. It's proposed to update in the next iteration.\n",
    "\n",
    "Aside from feature selection, we also designed our data engineering pipeline to handle data leakage. Our time-series cross validation used rolling windows where the training subset always consisted of scheduled flights occurring before the flights in the validation subset. The UTC conversion of the scheduled departure time was key to correctly define these splits. Each train and validation subset within the rolling windows also were scaled according to the training data in scope within the window. In other words, validation data was only scaled according to the train data in the same window, and scaling was never shared across other windows. When building the vectorized feature field for our models, we also ensured that the target variable was not accidentally included in the training.\n",
    "\n",
    "Similarly, we used this time-aware strategy when designing the final training and test datasets from the overall 5-year flight data. The training data was explicitly section to occur before Jan 1, 2019 UTC and the test data consisted only of flights following after in 2019, ensuring that the test set truly represented unseen, future conditions.\n",
    "\n",
    "| Feature Name                                       | Description                                                     |\n",
    "|----------------------------------------------------|-----------------------------------------------------------------|\n",
    "| prev_flight_arr_delay_clean                        | Previous flight’s arrival delay in minutes                     |\n",
    "| actual_to_crs_time_to_next_flight_diff_mins_clean  | Actual turnaround time in minutes (current scheduled - previous actual arrival) |\n",
    "| prev_crs_arr_time_utc                              | Previous flight’s scheduled arrival time in UTC                |\n",
    "| prev_crs_arr_time_utc_unix                         | Previous flight’s scheduled arrival time (UNIX timestamp)      |\n",
    "| crs_time_to_next_flight_diff_mins_log              | Log-transformed scheduled turnaround time (optional/log version) |\n",
    "| actual_to_crs_time_to_next_flight_diff_mins_clean_log | Log-transformed actual turnaround time (optional/log version) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd79b4b9-9693-42fb-96f3-bd6c5077cf49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Machine Learning and Engineering Pipeline\n",
    "\n",
    "### Classification Approach\n",
    "\n",
    "For our project, we chose to do a binary classification problem using `ARR_DEL_15` as the target variable. This field was chosen since it has a binary outcome of 1 (Delayed) or 0 (On-time) based on if the flight arrival time is 15 min or greater than the scheduled arrival time. Additionally, the arrival time, which `ARR_DEL_15` is based on, represents the final outcome that determines whether passengers will miss their flight connections and determines whether compensation is needed. Departure delay is also a major contributing factor, but pilots often attempt to recover lost time en route by increasing cruising speed. The arrival delay therefore is the most comprehensive metric since it incorporates all contributing factors to the flight, such as weather delay, NAS delay, etc.\n",
    "\n",
    "While a regression model could help predict how much a flight is delayed, we opted for binary classification because it directly addresses the concern of whether the delay exceeds 15 minutes and will help simplify training on our models. Stakeholders only need to know if the event will occur, whether preventative steps can be taken, or if an intervention is needed. Binary classification will also have more reliable outcomes than regression, especially if the target variable has a wide range and infinite possibilities of variance. \n",
    "\n",
    "Overall, the goal of our machine learning pipeline is to handle data at scale, reduce and prevent data leakage, and provide a logical, clean and repeatable ML pipeline. Given the significant amount of data manipulation, specifically for weather conditions, data transformations and pipeline needed to be thoughtfully done to preserve temporal integrity and avoid information leakage between training, validation, and unseen test sets.\n",
    "\n",
    "### Overall Pipeline Architecture\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/aestew/261_pix/8103182e1e2251a2be7fc7e93ecd708428e4095e/updated_pipeline.jpeg\" alt=\"Overall Pipeline Architecture\" />\n",
    "\n",
    "### Train - Validation - Test Split\n",
    "As mentioned previously, we created a custom joined dataset called **FASW** for our model training. Since flight data is inherently time-dependent, the final data was split chronologically by scheduled departure time in UTC to prevent data leakage from future observations, in which roughly 80% of the data was used for training and the remaining 20% was set aside as unseen test data for final model evaluation. Specifically, the overall training data covers data from 2015-2018, while the unseen test covers data from 2019. Validation data was also split from the 80% train data during the time-series cross validation phase.\n",
    "\n",
    "### Cross Validation\n",
    "We leveraged a **time-series cross validation** strategy using rolling windows, in which both training and validation windows move forward through time, always training on past flights and validating on future flights to closely match real operational forecasting conditions. Each window uses a fixed-size block of historical data used for training, then shifts forward by the validation block size, while maintaining temporal order and avoiding leakage from future observations. This method better captures evolving seasonal patterns, airport-specific congestion cycles, and weather-driven temporal structure. Rolling windows improved model generalization during evaluation, provided more realistic performance estimates, and reduced overfitting risk by ensuring that every validation test simulates a true future-prediction scenario. Each timeframe follows a different split for time-series cross-validation since the idea is to analyze patterns as time progresses and test the model on diverse forecast periods, giving us a more realistic estimate of the model's performance. The time-series validation was mainly performed on 1 year and 5 years of data when training the data, with 3 months and 6 months as a reference point for quality checks. While 6-month and 1-year training tend to follow a monthly split for rolling windows, the 5-year training data has an expanded rolling window to observe year over year trends and seasonality. If additional data been available past this timeframe, we could have experimented with and optimized the length of the validation folds to better capture both short-term and longer-term temporal dynamics.\n",
    "\n",
    "<br>\n",
    "<img src=\"https://raw.githubusercontent.com/aestew/261_pix/f3fe8128ca629cb3d67709b6751ead7b14baf121/cv_window_strategy.png\" alt=\"Time-Series CV\" width=\"800\"/>\n",
    "\n",
    "### Feature Engineering and Model Preparation\n",
    "Feature engineering was conducted for each train and validation set **within each rolling window** for consistency. We applied the same preprocessing pipeline (scaling and transformations) of the training set to the validation set within the same window to maintain a consistent scale and data distribution.\n",
    "\n",
    "#### Scaling and One-Hot Encoding\n",
    "Transformations included scaling of numerical features within each window to ensure consistent representation across variable and prevent data leakage. Signed logarithmic and standard scaling helped to normalize highly skewed data distributions within each rolling window to help provide meaningful patterns and relationships in the data and reduce noise when training the models.\n",
    "\n",
    "Categorical variables consisted mostly of weather and flight info types, and additional feature engineering was performed to create new binary groups, such as grouping snow-related weather conditions to a single snow feature. Because Hourly Sky and Present Weather columns were heavily encoded with concatenated codes and inconsistent formatting, we utilized regex-based parsing to standardize and map them to decoded values (e.g., \"RA:61,TS:95\" to \"Rain, Thunderstorm\") and a human readable column for convience. This decoding pre-process was required to create clear categorical features, enhancing both data readability and model interpretability.\n",
    "\n",
    "Once transformations were processed for the necessary features, the columns were vectorized, and separate vectorized columns of the selected features were created for different models. Logistic regression and neural network models used the scaled vectorized feature columns, whereas tree models used fully unscaled vectorized feature columns as they are inherently built to handle unscaled data.\n",
    "\n",
    "### Class Imbalance Handling\n",
    "From previous EDA results in Phase 2, our joined datasets exhibited significant class imbalance, where the minority class (delayed flights) occur only ~18-22% of the time across 3-month, 1-year, and 5-year period. This ratio presented significant modeling challenges, resulting in a strong bias toward predicting the majority class (on-time flights) and poor learning for the minority class.\n",
    "<br>\n",
    "<img src=\"https://raw.githubusercontent.com/aestew/261_pix/refs/heads/main/ClassImbalancesAllDFs.png\" alt=\"Time-Series CV\" />\n",
    "\n",
    "#### Pivoted Route: Downsampling\n",
    "We initially tested SMOTE and upsampling to address class imbalance, but both methods proved computationally infeasible for our large, distributed datasets. Due to excessive runtime and resource constraints, we discontinued these approaches in favor of downsampling.\n",
    "\n",
    "Given the requirement for scalability across the entire 5-year dataset and the computational complexity & limitation with oversampling methods, we implemented downsampling of the majority class instead as the final strategy simply because it was the most resource-efficient method.  Downsampling drastically reduced the overall data volume, but also accelerated all model training and mitigates the computational bottlenecks. While this introduced the risk of information loss from the majority class and potential underfitting, the compromise was necessary to ensure the entire pipeline could operate within resource limits. From downsampling, we were able to achieve a more balanced dataset and still retain at least 60% of the original train data.\n",
    "\n",
    "### Overall Pipeline Checkpoint Strategy\n",
    "\n",
    "All key phases are checkpointed in the mounted databricks drive `dbfs:/student-groups/Fall_2025_Group_02_01` to reduce continued resources and time spent on previous data processing phases. All processing has been performed by manually scheduled jobs. All checkpoint stages are documented below for each timeframe of 3 months, 6 months, 1 year, and 5 years of the FASW (Flight-Airport-Stations-Weather) data and includes checkpoints for both data engineering and modeling:\n",
    "\n",
    "(Note: {timeframe} indicates either 3m = 3 months, 6m = 6 months, 1y = 1 year, or '' for 5-year data)\n",
    "\n",
    "**1st Checkpoint:**\n",
    "<br>Weather, flight, station, and airport codes data are joined into FASW  dataset and saved to folder **fasw_{timeframe}/final_join**. Included steps:\n",
    "  - Removed duplicate flight records and filtered on airports that are within the US\n",
    "  - Conversion of local times to UTC\n",
    "  - Joined weather conditions within a 3-4 hour window before flight departure\n",
    "  - Addressed flight times with 24:00 time and converted to next day 0:00 time\n",
    "  - Used repartitionByRange() and spark configurations to optimize join and write operations\n",
    "\n",
    "**2nd Checkpoint:**\n",
    "<br>Null handling, feature engineering and feature selection to prepare FASW dataset for model training and saved to folder **fasw_{timeframe}/preprocessed**. Included steps:\n",
    "  - Added holiday periods with a 2 day window to consider flexible travel schedules\n",
    "  - Grouping and feature engineering of columns within the same feature families (e.g. weather for snow features were grouped into one feature indicating snow)\n",
    "  - Graph and time-based feature engineering\n",
    "  - Limiting columns to consider in model and manual null handling of these columns\n",
    "  - Datatype conversions (more notably binary columns to integers instead of double or string)\n",
    "  - Conversion of wind direction degree to cardinal directions\n",
    "  - Handled nulls using imputation, standard values, and zero-fill\n",
    "  - Cleanup of target column where nulls are set to 0\n",
    "\n",
    "**3rd Checkpoint:**\n",
    "<br>Data is split according to their timeframe. Relativedelta() function is used on UTC scheduled departure time to split train and test datasets and saved in separate file locations **fasw_{timeframe}/train_test/split=train** and **fasw_{timeframe}/train_test/train/split=test.**\n",
    "\n",
    "**4th Checkpoint:**\n",
    "<br>Original train data is used to create time-series cross validation that includes a train and validation set within each rolling window. Rolling windows are sized according to their timeframe, created using relativedelta() with UTC scheduled departure time, and saved to **fasw_{timeframe}/rolling_windows**.\n",
    "\n",
    "**5th Checkpoint:**\n",
    "<br>Additional feature engineering and scaling to create separate vectorized columns for different models and downsampling of train data. Data is saved to **fasw_{timeframe}/processed_rolling_windows**. Included steps:\n",
    "  - Signed log scaling and standard scaling for numerical fields where skew > 1 for logistic regression and NN models\n",
    "  - One-hot encoding of categorical columns\n",
    "  - Used pipeline to initiate build stages for fitting train data and transform validation data\n",
    "  - Vector assembly for 3 separate vectorized feature columns used for different model requirements\n",
    "  - Down sampling of train data to balance classes at 50:50\n",
    "\n",
    "**6th Checkpoint:**\n",
    "<br>Processed train test with similar feature engineering steps as 5th checkpoint. The overall train is used for transforming unseen test data. Both transformed datasets are saved to separate file locations **fasw_{timeframe}/processed_train_test/train** and **fasw_{timeframe}/processed_train_test/train/test**. Included steps:\n",
    "  - Signed log scaling and standard scaling for numerical fields where skew > 1 for logistic regression and NN models\n",
    "  - One-hot encoding of categorical columns\n",
    "  - Used pipeline to initiate build stages for fitting overall train data and transformed unseen test\n",
    "  - Vector assembly for 3 separate vectorized feature columns used for different model requirements\n",
    "  - Final train is downsampled to balance classes at 50:50\n",
    "\n",
    "**7th Checkpoint:**\n",
    "<br>Models are trained using different hyper parameter tuning methods (e.g. Gridsearch) via MLflow. Model training results and their best parameters are saved to the **experiments** folder in DBFS in their respective model sub-folder (e.g. experiments/xgb). The best parameter of each model for 1-year data is re-used to train on the overall downsampled train dataset, which follows the same pipeline and transformation setup, and evaluated against the unseen test set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0cc03eb4-bb16-4f2d-8bc0-cd97325edb10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Model Comparison Strategy\n",
    "During time-series cross validation, the training and validation metrics of each model will be averaged across the board. All candidate models will first be benchmarked against the baseline model (sigmoid logistic regression) performance metrics to establish a minimum acceptable threshold. The models will be conducted across various time frames (6M, 1Y, and 5Y), and only model results that outperform the baseline will be considered for further analysis. Once we had decided on the model with the best generalizability on 1-year of data, we leveraged the best parameters and the same pipeline setup to train the overall train data of the 5-year dataset and evaluate the final unseen test results.\n",
    "\n",
    "As anticipated from the preliminary EDA, the data has a strong class imbalance, with on-time flights greatly outnumbering delayed flights. The evaluation strategy will focus on the minority class of delays because the cost of a false negative (a missed delay prediction) is substantially higher than the cost of a false positive (an incorrect delay prediction). For this reason, the models will be evaluated using metrics that measure performance on the actual delayed flights (true positive). To compare the models among each other, we will be ranking them on the following evaluation metrics:\n",
    "\n",
    "| Priority      | Metric    | Formula                                      | Context |\n",
    "|---------------|-----------|----------------------------------------------|---------|\n",
    "| Main          | Recall    | $${Recall} = \\frac{TP}{TP + FN}$$ | This will be our **main** metric to ensure that all delayed flights are correctly flagged. In a worst case scenario, a flight that was not flagged is actually delayed (false negative), which could have massive financial repercussions if the delay cannot be recovered and ends up affecting connecting flights as well. We would like to minimize costly false negatives for the airlines as this would minimize the compensation and operation costs from managing a delayed flight. Low recall percentages could lead to increased compensation to passengers, lost connections, and decreased customer satisfaction. |\n",
    "| Secondary     | Precision | $${Precision} = \\frac{TP}{TP + FP}$$ | To avoid falsely flagging delayed flights. Although, a flight that is flagged as delayed but is actually on-time is a nice surprise. However, falsely flagging delayed flights may cause leadership to spend additional operational costs on preventative measures for a predicted delayed flight. |\n",
    "| Supplementary | F2 Score   | $$F = \\frac{5 * Precision \\cdot Recall}{4 * Precision + Recall}$$ | Balances precision and recall and penalizes low values in either, which is useful for handling imbalanced datasets and optimizing delays. Used as another indicator for model performance. |\n",
    "| Supplementary | PR AUC    | $$PR \\space AUC = \\int_{0}^{1} Precision(r)dr$$ <br> _Note: r = recall_ | Evaluating the highest score will help summarize the precision and recall trade-off across all thresholds and is the best indicator of our model performance given that the dataset is imbalanced. |\n",
    "\n",
    "\n",
    "The results for each metric will be averaged across all rolling time-series cross-validation windows for a representative performance score, and only the models with the best scores will proceed to the final stage, where they will be used on our unseen 20% test dataset for final evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87d2b957-0217-468d-839e-5ddfeea172b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Model Algorithms, Training & Results\n",
    "This section provides an overview of the algorithms selected for our flight delay prediction task, details the model training process, and summarizes the key results and insights from our experiments. This includes best parameters, wall times for cross-validation training and overall training, and grid search parameter sets. For our use case, we specifically employ the following models: sigmoid logistic regression (which serves as our baseline), random forest, decision tree, XGBoost, Multi-Layer Perceptron (MLP) neural network, and Feature Tokenizer (FT) Transformer neural network.\n",
    "\n",
    "### Compute Resources\n",
    "\n",
    "The below cluster was used to train all models:\n",
    "\n",
    "**Standard Cluster**\n",
    "- 2-8 Workers: 32-128 GB Memory, 8-32 Cores\n",
    "- 1 Driver: 16 GB Memory, 4 Cores\n",
    "- Runtime: 16.4 LTS\n",
    "- **Later upgraded to:**\n",
    "  - 6-12 Workers: 192-384 GB Memory, 48-96 Cores\n",
    "  - 1 Driver: 64 GB Memory, 16 Cores\n",
    "  - Runtime: 16.4 LTS\n",
    "\n",
    "MLP, FT-Transformer and Logistic Regression models with 5 year data were trained using and NVIDIA G4 GPU with 16 GB GDDR6 memory. GPU optimized models only used 5-12GB for training. GPU was required to run the FT-Transformer model as the improved CPU cluster took over 15hrs and still did not complete training both windows.\n",
    "\n",
    "The GPU cluster didn't perform well with tree-based models as they inherently build trees in sequence, which conflicts with the GPU cluster's parallelized processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdfd4d44-5e26-47dd-9843-3e5eda504a2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Baseline Model: Sigmoid Logistic Regression\n",
    "Sigmoid Logistic Regression takes a complicated regression model and transforms it into a probability between 0 and 1. This is one of the simplest models we can use to identify if a flight arrived 15 minutes later than scheduled and will be a great first step in identifying the most impactful features to in our data set to flight delays as it performs better with fewer imputs. Tuning options in this model include regularization, adjusting the learning rate, feature scaling, and feature selection. \n",
    "\n",
    "##### Implementation\n",
    "We implemented a Logistic Regression model in PySpark using rolling time windows to evaluate model stability over time. For each window, we cleaned the data, added cyclic temporal features, and performed a grid search over key LR hyperparameters (maxIter, regParam, elasticNetParam). Models were trained on each train window and evaluated on both train and validation sets using a custom cv_eval() function that computes Recall, Precision, F2, and PR-AUC. We also visualized performance across windows by plotting train and validation PR-AUC to assess temporal generalization.\n",
    "\n",
    "##### Feature Engineering & Feature Selection\n",
    "Our feature engineering process focused on preparing meaningful, non-redundant predictors for Logistic Regression. We began by removing highly correlated features using Variance Inflation Factor (VIF) to reduce multicollinearity. Cyclic transformations were applied to time-based variables—such as MONTH and DAY_OF_WEEK to capture seasonality using sine and cosine encodings. Binary indicators and numerical travel-related attributes were standardized, and log-scaled versions were used where appropriate to reduce skew. We also evaluated nonlinear relationships using Mutual Information (MI) and selected only the most informative features for model training across all rolling windows. The results reported below for our models are all on our 5-year custom joined dataset (FASW) from 2015 to 2019.\n",
    "\n",
    "**Top Features and Hyperparameters**\n",
    "- maxIter=50\n",
    "- regParam=0.01\n",
    "- elasticNetParam=0.0\n",
    "- dest_pagerank\n",
    "- snow \n",
    "\n",
    "##### Performance\n",
    "Across rolling windows and the final downsampled model, performance exhibits a consistent pattern: recall is generally moderate to strong, precision is consistently weak, and downstream metrics reflect this imbalance. In Rolling Window 1, recall remains high on both train (0.683) and validation (0.670), but precision drops sharply on validation (0.262), resulting in a validation F2 score of 0.511 and PR-AUC of 0.302. Rolling Window 2 demonstrates a similar dynamic. Recall holds at 0.659 (train) and 0.514 (validation) with validation precision at 0.255. While this configuration yields slightly stronger F2 (0.539) and PR-AUC (0.514) than Window 1, the precision deficit persists, indicating the model systematically overpredicts delays.\n",
    "\n",
    "The final downsampled model provides the most balanced view across all three splits. Train and test precision stay high (≈0.878), while validation precision again collapses (0.308), confirming that precision instability is tied to temporal drift rather than model configuration. Recall is moderate across all sets (0.531–0.664), and the resulting F2 scores land between 0.512 and 0.659. PR-AUC values remain modest (0.279–0.636), reinforcing that the classifier struggles to produce well-calibrated probability rankings for the minority delay class. Collectively, these patterns indicate that while the model reliably identifies delayed flights, its ability to precisely target true delays is highly sensitive to the temporal conditions of each rolling window, leading to material performance variability over time.\n",
    "\n",
    "The table compares the mean performance across the rolling cross-validation windows (Train/Validation) with the final evaluation on the completely unseen **Blind Test Set**.\n",
    "\n",
    " **Experiment** | **Configs** | **Best Parameters** | **Data** | **Metric** | **Train** | **Validation** | **Test** |\n",
    " :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |\n",
    " **Rolling Window #1 <br> (Depth Exploration)** | `maxIter`= 50 <br> `regParam` = 0.1 <br> `elasticNetParam` = 0.0 <br> | snow | 5-year | **Recall** | 0.683 | 0.670 | -- |\n",
    " Wall Time per Rolling Window: <br> 2 min 0 sec | | | | **Precision** | 0.594 | 0.262 | -- |\n",
    " | | | | | **F2 Score** | 0.6630 | 0.511 | -- |\n",
    " | | | | | **PR-AUC** | 0.631 | 0.302 | -- |\n",
    " **Rolling Window #2 <br> (Node Size Exploration)** | `maxIter`= 50 <br> `regParam` = 0.1 <br> `elasticNetParam` = 0.0 <br> | dest_pagerank | 5-year | **Recall** | 0.659 | 0.514 | -- |\n",
    " Wall Time per Rolling Window: <br> 2 min 18 sec | | | | **Precision** | 0.602 | 0.255 | -- |\n",
    " | | | | | **F2 Score** | 0.674 | 0.539 | -- |\n",
    " | | | | | **PR-AUC** | 0.659 | 0.514| -- |\n",
    " **Final Model - Best Params <br> (Downsampled)** | `maxIter`= 50 <br> `regParam` = 0.1 <br> `elasticNetParam` = 0.0 <br> | dest_pagerank | 5-year | **Recall** | 0.5313 | 0.664 | 0.5313 |\n",
    " Wall Time: <br> ~2 min 11 sec | | | | **Precision** | 0.8777 | 0.308 | 0.877 |\n",
    " | | | | | **F2 Score** | 0.659 | 0.512 | 0.577 |\n",
    " | | | | | **PR-AUC** | 0.636 | 0.279 | 0.288 |\n",
    "\n",
    "##### Key Observations\n",
    "The optimal configuration shows strong recall across both training and validation, indicating the model reliably identifies delayed flights even under shifting temporal windows. However, precision degrades substantially in validation compared to training, confirming that precision instability is tied to temporal drift rather than model setup. F2 and PR-AUC follow the same pattern, with noticeably stronger scores on training data and weaker performance on validation and blind test periods. The blind test precision rebounds sharply due to class balancing in the final model configuration, but recall drops in exchange. Taken together, these patterns indicate that temporal distribution shifts, rather than parameter choices, drive most of the performance volatility across splits.\n",
    "\n",
    "Below is a table for **Logistic Regression Performance Summary**\n",
    "\n",
    "| Metric      | Train Score (Optimal) | Validation Score (Optimal) | Final Blind Test Result |\n",
    "|-------------|------------------------|-----------------------------|--------------------------|\n",
    "| **F2 Score** | 0.674              | 0.539                  | **0.577**                |\n",
    "| **Recall**   | 0.683                  | 0.670                       | **0.5313**               |\n",
    "| **Precision**| 0.602                  | 0.262                       | **0.877**                |\n",
    "| **PR-AUC**   | 0.659                  | 0.514                       | **0.288**                |\n",
    "\n",
    "\n",
    "##### Limitations\n",
    "Although Logistic Regression is easy to interpret and efficient, it has several limitations. It assumes a linear relationship between features and the log-odds of the outcome, which can lead to poor performance when nonlinear patterns are present. The model is also sensitive to multicollinearity, requiring careful feature selection and preprocessing. Logistic Regression can struggle with high-dimensional or sparse feature spaces—especially when many one-hot encoded variables are included—and performance can degrade when classes are highly imbalanced. Additionally, LR is less flexible than modern machine learning models, therefore it serves as a baseline rather than a top performer on our complex datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "76d4165f-e343-4898-9881-d67ee442288e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Improved Model: Random Forest\n",
    "##### Overview\n",
    "We later chose Random Forest as an improved model from our baseline because it constructs multiple decision trees during training and outputs the mode of individual tree predictions for classification tasks. The model addresses the critical weaknesses of single decision trees—overfitting and instability—through two key randomization mechanisms. \n",
    "The final prediction is made through majority voting, where the class receiving the most votes becomes the ensemble's output. This aggregation leverages the wisdom of crowds principle, while individual trees may make errors or overfit to particular patterns, averaging across many diverse trees tends to cancel out these errors while preserving the signal, yielding more stable and reliable predictions.\n",
    "##### Implementation\n",
    "With the first iteration of our training parameters, our hyperparameter optimization process employed grid search with cross-validation across all of our rolling time windows while exploring combinations of key hyperparameters to identify the best combination that maximized our primary metric, the `Recall` and `F2 Score`. The initial search space included maximum tree depth ranging from shallow trees (`maxDepth` 5) to deeper structures (`maxDepth` 10), number of trees current at `numTrees` 10 (for testing purpose but later will be expanded), maximum bins for discretizing continuous features at a fixed `maxBins` 100 for now along with a fixed `minInstancesPerNode` of 5 per node, and `featureSubsetStrategy` comparing `'sqrt'`.\n",
    "\n",
    "Following extensive hyperparameter tuning using grid search, the optimal configuration that yielded the best result was identified as:\n",
    "- Maximum Tree Depth (`maxDepth`): 10\n",
    "- Number of Trees (`numTrees`): 20\n",
    "- Maximum Bins (`maxBins`): 400\n",
    "- Minimum Instances Per Node (`minInstancesPerNode`): 5\n",
    "- Feature Subset Strategy (`featureSubsetStrategy`): `'sqrt'`\n",
    "\n",
    "##### Feature Selection & Features Importance\n",
    "For Random Forest specifically, feature selection was guided by predictive power, computational scalability, and operational interpretability, with a focus on ensuring that there is \"perfect\" feature alignment across all rolling windows and the blind test set.  Our final feature set included a mix of temporal features, operational features, weather features, and engineered graph features. The primary challenge was ensuring categorical features like `carrier` and `airport` maintained consistent encodings across windows, as new values could appear in later time periods or the test set. Another advantage we have with Random Forest is its built-in feature importance mechanism inherently performs variance-based feature selection by evaluating each feature's contribution to impurity reduction across all trees, naturally down-weighting features with low predictive power. Last but not least, despite this redundant test, we also used cardinality testing to identify and handle high-cardinality categorical features that could cause dimensionality explosion to ensure computational feasibility across our large-scale dataset, which thankfully we did not need to eliminate any feature based on this result.\n",
    "\n",
    "The feature importance analysis for the optimized model confirmed the strong predictive power of operational and historical features. The top four most important features, cumulatively accounting for more than half of the total feature importance, were:\n",
    "- `actual_to_crs_time_to_next_flight_diff_mins_clean` (0.2836)\n",
    "- `crs_time_to_next_flight_diff_mins` (0.1688)\n",
    "- `CRS_ARR_TIME_BLOCK_idx` (0.0804)\n",
    "- `CRS_DEP_TIME_BLOCK_idx` (0.0568)\n",
    "\n",
    "Other notable network features, including `origin_pagerank` (0.0164), `origin_out_degree` (0.0126), `dest_in_degree` (0.0104), and `dest_pagerank` (0.0097), consistently registered as important predictors providing quantifiable context on an airport's structural importance within the national network. And weather features, such as `HourlyAltimeterSetting` (0.0178) and `lowest_cloud_ft` (0.0130) also contributed significantly by demonstrating that the model is effectively integrating all categories of predictors.\n",
    "\n",
    "##### Performance\n",
    "The performance metrics demonstrate strong generalization with minimal overfitting. This is evidenced by the fact that the Blind Test `F2 Score` of 0.545 aligns remarkably well with the Validation `F2 Score` of 0.539, validating our cross-validation approach and confirming that the model's performance on unseen data is highly predictable. The difference between the Training `F2 Score` (0.674) and the validation score is 0.135, which is an expected consequence of building a robust model that learns generalized patterns rather than memorizing noise in the training set, a risk mitigated by the optimal parameter choice of a maximum depth of 10.\n",
    "\n",
    "In terms of `Recall`, the blind test result of 0.673 exceeds the validation score of 0.664, indicating the model successfully identifies over 67% of delayed flights in completely unseen data. Meanwhile, `Precision` of 0.310 means approximately one in three delay predictions is correct, reflecting our deliberate optimization for recall through the `F2 Score` metric. Since these are the final, post-tuning metrics, they represent the best achievable results for this model architecture, demonstrating successful hyperparameter tuning.\n",
    "\n",
    "The table compares the mean performance across the rolling cross-validation windows (Train/Validation) with the final evaluation on the completely unseen **Blind Test Set**.\n",
    "\n",
    " **Experiment** | **Configs** | **Best Parameters** | **Data** | **Metric** | **Train** | **Validation** | **Test** |\n",
    " :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |\n",
    " **Grid Search #1 <br> (Depth Exploration)** | `numTrees` = 20 <br> `maxBins` = 400 <br> `minInstancesPerNode` = 5 <br> `featureSubsetStrategy` = 'sqrt' <br> **`maxDepth` = 5, 8, 10** | `maxDepth` = 10 | 5-year | **Recall** | 0.681 | 0.664 | -- |\n",
    " Wall Time per Rolling Window: <br> 1 min 1 sec | | | | **Precision** | 0.650 | 0.308 | -- |\n",
    " | | | | **F2 Score** | 0.674 | 0.539 | -- |\n",
    " | | | | **PR-AUC** | 0.691 | 0.358 | -- |\n",
    " **Grid Search #2 <br> (Node Size Exploration)** | `numTrees` = 20 <br> `maxBins` = 400 <br> `maxDepth` = 10 <br> `featureSubsetStrategy` = 'sqrt' <br> **`minInstancesPerNode` = 5, 10, 20** | `minInstancesPerNode` = 5 | 5-year | **Recall** | 0.681 | 0.664 | -- |\n",
    " Wall Time per Rolling Window: <br> 1 min 0 sec | | | | **Precision** | 0.650 | 0.308 | -- |\n",
    " | | | | **F2 Score** | 0.674 | 0.539 | -- |\n",
    " | | | | **PR-AUC** | 0.691 | 0.358 | -- |\n",
    " **Final Model - Best Params <br> (Downsampled)** | `maxDepth` = 10 <br> `numTrees` = 20 <br> `maxBins` = 400 <br> `minInstancesPerNode` = 5 <br> `featureSubsetStrategy` = 'sqrt' | - | 5-year | **Recall** | 0.681 | 0.664 | 0.673 |\n",
    " Wall Time: <br> 1 min 10 sec | | | | **Precision** | 0.650 | 0.308 | 0.310 |\n",
    " | | | | **F2 Score** | 0.674 | 0.539 | 0.545 |\n",
    " | | | | **PR-AUC** | 0.691 | 0.358 | 0.366 |\n",
    "\n",
    "##### Key Observations\n",
    "The final performance summary provides clear evidence regarding the model's effectiveness and stability as the `F2 Score` is a key indicator, with the Validation Score of 0.5390 being nearly identical to the final Blind Test Score of 0.5453. This strong consistency between the two unseen datasets confirms that the model generalizes well and is not overfit to the training data. \n",
    "\n",
    "Furthermore, the `Recall` is high and stable across all evaluation sets, which indicates that the model is successful at its core objective: correctly identifying approximately 67% of all truly delayed flights. But on the downside, the lower `Precision` scores around 0.31 are an expected result of optimizing for `F2 Score`, which tolerates more False Positives in order to minimize False Negatives. Overall, the results demonstrate a robust model that effectively prioritizes the identification of delayed flights, consistently performing well on new data.\n",
    "\n",
    " Metric | Train Score (Optimal Run) | Val Score (Optimal Run) | **Final Blind Test Result** |\n",
    " :--- | :--- | :--- | :--- |\n",
    " **F2 Score** | **0.6745** | **0.5390** | **0.5453** |\n",
    " **Recall** | 0.6808 | 0.6638 | **0.6728** |\n",
    " **Precision** | 0.6501 | 0.3076 | **0.3102** |\n",
    " **PR-AUC** | 0.6910 | 0.3578 | **0.3662** |\n",
    "\n",
    "##### Considerable Limitations\n",
    "The primary limitation of the Random Forest model is its reduced interpretability compared to single decision trees. While individual trees allow for clear visualization and explanation of decision paths, a forest of many trees (which we plan to expand further in Phase 3) cannot be easily interpreted or visualized . Predictions result from the aggregate votes of the ensemble, making it challenging to explain specific outcomes to stakeholders.  Additionally,prediction requires evaluating all trees in the ensemble, which is slower than the single calculation needed for simpler models like logistic regression. However, for our use case, where predictions are made per scheduled flight, this added latency is not a significant concern.\n",
    "\n",
    "Last, during our grid search period, Random Forest also required more memory than simpler algorithms, as they must store many full tree structures. This memory requirement leads directly to our main operational constraint, **scalability issues**, within the Spark implementation (specifically related to the memory handling for complex tree structures). Therefore, we are unable to scale our current parameters (e.g., increasing the number of trees or max depth) beyond the current configuration. This hard limit restricts our ability to potentially capture further predictive power from larger ensembles. In our current state, with the number of features and the optimal parameters identified, memory usage was manageable, but we remain mindful of this constraint for future feature engineering or scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b4303bfa-18ad-459e-ba1a-bf76538dcb51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Improved Model: Decision Tree\n",
    "##### Overview\n",
    "We selected a decision tree as the next model to evaluate because it offers a meaningful step between our Phase II models (Logistic Regression and Random Forest). It is less complex than a Random Forest but structurally distinct from Logistic Regression, allowing us to explore a different decision boundary without introducing excessive model complexity. A decision tree’s deterministic, rule-based structure provides clear visibility into how operational, temporal, weather, and network-related features drive delay outcomes. This interpretability makes the model a valuable diagnostic tool and a strong reference point for assessing the incremental value of more complex ensemble or deep learning models later in the project.\n",
    "\n",
    "However, single decision trees are known to have high variance and are prone to overfitting, especially in high-dimensional and noisy datasets such as flight operations and weather data. To address this, we explicitly regularize the tree and tune its hyperparameters using time-aware validation.\n",
    "\n",
    "##### Implementation\n",
    "We performed an explicit grid search over the tree’s key structural hyperparameters. This grid search was conducted using rolling-window cross-validation, in which each validation set occurs strictly after its corresponding training set in time. This approach avoids temporal leakage and better reflects real-world deployment, where predictions must generalize to future data.\n",
    "\n",
    "We exhaustively evaluated combinations of maximum tree depth (maxDepth), minimum instances per node (minInstancesPerNode), and minimum information gain (minInfoGain). The maximum number of bins (maxBins) was fixed at 128 based on earlier categorical cardinality analysis. Each configuration was trained on the combined rolling-window training data and evaluated on the combined rolling-window validation holdouts. The optimal hyperparameters were selected by maximizing the validation F2 score, which prioritizes recall of delayed flights.\n",
    "\n",
    "The final selected configuration was:\n",
    "\n",
    "- **maxDepth:** 10  \n",
    "- **minInstancesPerNode:** 100  \n",
    "- **minInfoGain:** 0.0  \n",
    "- **maxBins:** 128  \n",
    "\n",
    "\n",
    "These parameters balance expressiveness and regularization. Because recall is prioritized, enforcing a positive minInfoGain removed low-gain but informative splits, reducing recall. The selection of minInfoGain = 0.0 indicates that depth and minimum node size provided sufficient regularization.\n",
    "\n",
    "##### Feature Selection and Importance\n",
    "Feature selection followed consistent engineering constraints applied throughout the project, including temporal stability across rolling windows, computational feasibility, and domain relevance. The final Decision Tree includes a mix of operational, temporal, weather, categorical, and graph-based airport connectivity features.\n",
    "\n",
    "Feature importance was extracted from the trained tree based on total impurity reduction across splits. Unlike ensemble models, which spread importance across many trees, a single Decision Tree concentrates most of its influence in a small number of highly discriminative features.\n",
    "\n",
    "The most important features were:\n",
    "- *actual_to_crs_time_to_next_flight_diff_mins_clean*\n",
    "- *crs_time_to_next_flight_diff_mins*\n",
    "- *CRS_ARR_TIME_BLOCK_idx*\n",
    "- *CRS_DEP_TIME_BLOCK_idx*\n",
    "- *prev_flight_arr_delay_clean*\n",
    "\n",
    "Together, the top two operational features account for nearly 70% of the total feature importance, showing that delay propagation and aircraft turnaround timing dominate the model’s decisions. Graph-based features such as dest_pagerank and origin_pagerank also appear among the top-ranked features, indicating that airport connectivity and structural network effects provide additional, though secondary, predictive value. Weather features such as snow and altimeter pressure contribute further refinements but are less influential than operational scheduling signals\n",
    "\n",
    "##### Performance\n",
    "\n",
    "Model performance was evaluated on three datasets: combined rolling-window training data, combined rolling-window validation holdouts, and a completely unseen blind test set.\n",
    "\n",
    "On the combined training data, the model achieved an F2 score of 0.6480, with precision of 0.6584 and recall of 0.6454. Performance on the rolling-window validation holdouts decreased to an F2 score of 0.5257, with recall remaining high at 0.6394 but precision dropping to 0.3071. This gap indicates moderate overfitting, which is expected for a single Decision Tree despite regularization.\n",
    "\n",
    "On the blind test set, performance degraded substantially, with an F2 score of 0.1316. While precision increased to 0.7257, recall collapsed to 0.1092, indicating that the model became extremely conservative under temporal distribution shift, predicting delays only when highly confident.\n",
    "\n",
    "| Metric        | Training Results | Validation Results | Blind Test Result |\n",
    "| :------------ | :--------------- | :----------------- | :---------------- |\n",
    "| **F2 Score**  | 0.6480           | **0.5257**         | **0.1316**        |\n",
    "| **Recall**    | 0.6454           | **0.6394**         | **0.1092**        |\n",
    "| **Precision** | 0.6584           | **0.3071**         | **0.7257**        |\n",
    "| **PR-AUC**    | 0.7061           | **0.3900**         | **0.4097**        |\n",
    "\n",
    "##### Key Observations\n",
    "The Decision Tree offers strong interpretability and clearly identifies core operational and temporal drivers of flight delays. Rolling-window validation demonstrates that the model can maintain high recall on near-future data, confirming the value of time-aware evaluation. However, blind test results highlight the model’s sensitivity to temporal drift and its inability to generalize robustly to unseen future conditions. Feature importance is heavily concentrated in a small number of operational features, while graph and weather features play supporting roles.\n",
    "\n",
    "##### Considerable Limitations\n",
    "The primary limitations of the Decision Tree stem from its single-model structure. The model exhibits high variance and instability, with performance sensitive to changes in training data. It lacks the ability to average out noise or capture complex interactions across many features, leading to poor generalization under temporal shift. The sharp recall collapse on the blind test demonstrates why a single Decision Tree is insufficient for production-grade delay prediction. These limitations motivate the use of ensemble methods such as Random Forests and Gradient-Boosted Trees, which preserve interpretability while significantly improving stability and predictive performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3fbdc260-43e3-4fed-a621-a208d53f0187",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Boosted Trees: XGBoost\n",
    "##### Overview\n",
    "Because our initial Decision Tree model was prone to high variance and subsequent overfitting, we transitioned to the optimized boosted tree model, XGBoost, which builds trees sequentially and focuses on weak learners of the data. The model aims to reduce bias by having each new tree correct the residual errors made by the previous ensemble of trees, minimizing the overall loss function.\n",
    "\n",
    "A special feature of XGBoost is the automatic inclusion of L2 (Ridge) regularization (set at a default value of 1) in its function, which penalizes the complexity of newly added trees to reduce sensitivity to noise in the data and helps to mitigate overfitting. L1 (Lasso) regularization can also be added, but is defaulted as 0. Although nulls and missing data were handled during the pre-processing stage, XGBoost also includes built-in methods for handling null and missing values, allowing flexibility and the option of skipping extensive pre-processing if desired.\n",
    "\n",
    "##### Implementation\n",
    "Our initial experiment involved a simple configuration using 100 estimators (`n_est`), a learning rate (`rate`) of 0.1 , and a maximum depth (`depth`) of 10. This model was trained across several rolling windows across a year of data and included training and validation data within each window. The inclusion of new graph features significantly increased model scores across the board, which led us to refine the vectorized columns to include these features. Specifically, average recall increased by approximately 0.1 points, while average precision increased by 0.06-0.08 points.\n",
    "\n",
    "Due to time constraints, we performed a grid search over a restricted set of hyperparameters using time-series cross-validation. The search focused on maximizing recall and the F2 score. We began by first searching over `n_est`, `rate`, and `depth`, and later expanded the parameter set to include `subsample` and `colsample_bytree`. (1) `subsample` and (2) `colsample_bytree` are considered to be regularization techniques that (1) introduce randomness into the tree-building process by controlling the percentage of training data that is randomly sampled to build each new decision tree or (2) controls the fraction of features (columns) that will be randomly sampled when building each new decision tree. Out of curiosity, we also later introduced additional regularization parameters (`alpha` - L1 and `lambda` - L2) to analyze their effect on overall model performance.\n",
    "\n",
    "The optimal hyperparameters were selected primarily by maximizing the recall score (the primary metric), with the F2 score and PR-AUC used to evaluate the model performance. Simultaneously, we monitored the precision (our secondary metric) to ensure it was not heavily thrown off balance.\n",
    "\n",
    "The final selected configuration was:\n",
    "- `n_est` = 200\n",
    "- `rate` = 0.01\n",
    "- `depth` = 10\n",
    "- `colsample_bytree` = 0.9\n",
    "\n",
    "These final parameters were chosen based on achieving an effective balance between an improvement in the evaluation metrics and efficient training time. To prioritize model simplicity and efficiency, we also removed any parameters that did not meaningfully contribute to model performance but increased computation time. The final parameter set was then used to train the entire 5-year training dataset before being evaluated against the final unseen test dataset.\n",
    "\n",
    "##### Feature Selection\n",
    "Aside from using `colsample_bytree`, feature selection was determined after each experiment by analyzing information gain of the current best parameters to assess the contribution of each feature. Features were pruned based on how much total gain they contributed to the model.\n",
    "\n",
    "While the contribution of other features shifted depending on various parameters, two features from the graph family were consistently at the top of the list:\n",
    "- actual_to_crs_time_to_next_flight_diff_mins_clean\n",
    "- crs_time_to_next_flight_diff_mins\n",
    "\n",
    "The importance of these two features were clearly shown when training the best parameters across all datasets. For the 1-year dataset, these two features alone accounted for 37.7% of the total information gain for the model. The 5-year training results further reflected their importance, with these two features contributing an even greater total gain of 70.5%.\n",
    "\n",
    "Another factor influencing our final feature selection was the computation resources required for training the massive 5-year dataset. Because the team had to share computational resources across the same cluster, we implemented an additional restriction for this model, where only features that contributed to 90% of the cumulative total gain for the model would be included. This approach was to ensure model efficiency while minimizing training time.\n",
    "\n",
    "##### Performance\n",
    "The table documents the experiments taken after employing the grid search and implementing the graph features on the standard cluster. Only the results that yielded the best results among the parameter sets are shown below. Additionally, only the chosen best parameters were evaluated against the unseen test set:\n",
    "\n",
    "| **Experiment**         | **Configs** | **Best Parameters** | **Data** | **Metric**    | **Train** | **Validation** | **Test** |\n",
    "----------------------- |--------------------------|---------------------|----------|-------------- |-----------|---------------|----------|\n",
    "**Grid Search #1 <br> (Downsampled**) | **n_est = 100, 200 <br> rate = 0.1, 0.01 <br> depth = 5, 10, 15** | n_est = 200 <br> rate = 0.01 <br> depth = 10 | 1-year | **Recall**    |  0.702  |  0.641  |  --  |\n",
    "|Wall Time per Rolling Window: <br> 4-5 min|||| **Precision**  |  0.706  |  0.349  |  --  |\n",
    "||||| **F2 Score**   |  0.704  |  0.548  |  --  |\n",
    "||||| **PR-AUC**     |  0.784  |  0.457  |  --  |\n",
    "**Grid Search #2 <br> (Downsampled)** | n_est = 200 <br> rate = 0.01 <br> depth = 10 <br> **subsample = 0.7, 0.9 <br> colsample_bytree = 0.7, 0.9** | n_est = 200 <br> rate = 0.01 <br> depth = 10 <br> subsample = 0.7 <br> colsample_bytree = 0.9 | 1-year | **Recall**    |  0.694  |  0.600  |  --  |\n",
    "|Wall Time per Rolling Window: <br> 16-19 min|||| **Precision**  |  0.705  |  0.368  |  --  |\n",
    "||||| **F2 Score**   |  0.698  |  0.546  |  --  |\n",
    "||||| **PR-AUC**     |  0.781  |  0.489  |  --  |\n",
    "**Grid Search #3 <br> (Downsampled)** | n_est = 200 <br> rate = 0.01 <br> depth = 10 <br> subsample = 0.7 <br> colsample_bytree = 0.9 <br> **lambda = 1.0, 5.0 <br> alpha = 0.01, 1.0** | n_est = 200 <br> rate = 0.01 <br> depth = 10 <br> subsample = 0.7 <br> colsample_bytree = 0.9 <br> lambda = 1.0 (default value) <br> alpha = 0.01 | 5-year | **Recall**    |  0.704  |  0.640  |  --  |\n",
    "|Wall Time per Rolling Window: <br> 18-22 min|||| **Precision**  |  0.706  |  0.351  |  --  |\n",
    "||||| **F2 Score**   |  0.704  |  0.548  |  --  |\n",
    "||||| **PR-AUC**     |  0.786  |  0.460  |  --  |\n",
    "**Final Model - Best Params <br> (Downsampled)** | n_est = 200 <br> rate = 0.01 <br> depth = 10 <br> colsample_bytree = 0.9 | - | 5-year | **Recall**    |  0.680  |  0.600  |  0.679  |\n",
    "|Overall Wall Time: <br> ~16 min|||| **Precision**  |  0.640  |  0.304  |  0.296  |\n",
    "||||| **F2 Score**   |  0.672  |  0.552  |  0.539  |\n",
    "||||| **PR-AUC**     |  0.714  |  0.441  |  0.420  |\n",
    "\n",
    "\n",
    "##### Key Observations\n",
    "During time-series cross validation, we observed that window 3 consistenly performed the best for the 1-year dataset no matter which parameters we chose. This outcome is logical as the training period (March-May) and the validation period (June) fall outside of heavy holiday travel season, and flight pattern abhormalities are not expected during this timeframe. On the other hand, rolling windows falling during heavy travel periods, such as during holidays, demonstrated slightly poorer scores while evaluating the validation data.\n",
    "\n",
    "The inclusion of the `subsample` parameter did not contribute meaningful improvements or changes to the model and instead increase computational time. Similarly, adding additional regularization did not benefit the model very much, and instead would degrade the performance depending on values. Given these observations, we decided to reduce the final parameter set to prioritize simplicity and efficiency. Overall, the XGBoost model demonstrated its ability to clearly identy the most valuable operational features, and the heavy concentration of information gain in just two features confirms that rather than hyperparameter tuning, the feature engineering was the primary driver of performance.\n",
    "\n",
    "Rolling window validation also confirmed that the model effectively maintains a high recall score on near-future data, validating the effectiveness of including graph features for time-series predictions. While recall aligned rather well between all datasets, precision suffered most, suggesting that the model is biased towards predicting delayed flights. The overall goal is to minimize the number of missed delays (false negatives), however the F2 score suggests that it would be preferable to reduce the number of false alarms that may result from the model.\n",
    "\n",
    "##### Limitations\n",
    "While certain features significantly contributed to the model's predictive power, there still appears to be insufficient unique information to clearly separate the delayed flighted from the on-time flights, suggesting that there is a high degree of overlap in the feature space. As a result, the decision boundary is heavily mixed, which causes the model to pick up many false positives, hurting the precision scores on the validation and test datasets. This is built on top of XGBoost's tendency to overfit on the training data due to its nature of splitting at the point with the highest information gain.\n",
    "\n",
    "Similar to the random forest model, a huge limitation of XGBoost is the amount of memory consumption required on the executor nodes and the additional memory needed to process each tree. Because we were consistently hitting executor out-of-memory errors during final training of the model, we had to repartition the data and configure additional parameters like `max_bin` and `num_workers` to successfully complete the training on the train data of the 5-year dataset. While experimenting with the GPU cluster, we observed that out-of-memory errors occurred even quicker. While XGBoost can parallelize the computation of best splits, the fundamental process of building the decision trees is sequential, and when trees grow very large, it can quickly consume the limited VRAM of the GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d21dd2bd-35e8-4397-a6e7-a861630226d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Neural Networks\n",
    "Two different types of neural networks were analyzed under various architectures: Multi-Layer Perceptron  (MLP) and Feature Tokenizer Transformer (FTT). Neural Networks capture nonlinear relationships and feature interactions. While tree models are excellent at categorization, they require clean splits in the data to help understand outcomes. Neural Networks are able to interpret more complex and nuanced relationships (e.g. flights Thursday evening from Atlanta are usually delayed) which provide significantly better generalization.\n",
    "\n",
    "Here, two architectures were explored, MLP with a more shallow and more complex network as well as a Feature Tokenizer - Transformer with multi-head self attention using two different loss functions (Binary Cross Entropy and Focal Loss). Below we detail outcomes with both models.\n",
    "\n",
    "\n",
    "## Multi-Layer Perceptron\n",
    "#### Overview\n",
    "\n",
    "\n",
    "MLP and Neural Networks differ from LR and Tree models because they learn differently from the features. Tree Models look at hard yes-no thresholds and rule driven patterns to make decisions whereas MLP and NN models look at smooth, continuous decision boundaries to identify subtle interaction-heavy relationships. However vanilla MLPs are not optimized for tabular data - the data leveraged in this project and many MLPs can struggle with the significant categorical data, OHE-vectors, and fixed Softmax Loss.\n",
    "\n",
    "\n",
    "The Spark `MultiLayerProceptron()` function has fixed architecture: hidden layers always use ReLU and final outputs leverage Softmax(). To calculate loss, Spark MLP model uses Multiclass Cross Entropy Loss. Training and customization options for MLP include increasing or decreasing layer size and number of layers to learn more or less information about the data, number of iterations, step size (learning rate) and block size. Functions of other neural networks not available through this method include - a dropout layer, batch normalization, custom activations, and custom losses. These tools would help significantly improve the NN model.\n",
    "\n",
    "\n",
    "Feature engineering also plays a significant role in how MLP models perform. This includes ensuring all inputs are scaled to prevent the model from focusing features with a larger or higher range and preventing single features from dominating model optimization. All MLP features must have outliers and missing values handled.\n",
    "\n",
    "\n",
    "Generally, MLPs are a great first step into training a Neural Network model. However, in practice they perform similarly as trees, but require significantly more time and computation.\n",
    "\n",
    "\n",
    "#### Implementation\n",
    "\n",
    "\n",
    "With limited levers, our team focused on ensuring all data was properly transformed, nulls were removed and the pipeline was repeatable for feature engineering, optimization and feature removal or addition. Initial experiments with 3 month data included a wider neural network `[526, 256, 256, 128, 2]`, and adding in encoded  `ORIGIN` and `DEST` fields. However, neither model was performing as well as XGBoost. An optimized model removing `ORIGIN` and `DEST` using a smaller neural network was used to run the '5 year' dataset.\n",
    "\n",
    "\n",
    "Downsampled data was used for training and a threshold analysis was run to ensure optimization showing that 0.5 was the best overall, however the best F2 was achieved with a threshold of 0.45. The threshold for the experiments and test were kept at 0.5 for consistency.\n",
    "\n",
    "\n",
    "| Threshold | Precision | Recall | F1     | F2     |\n",
    "|-----------|-----------|--------|--------|--------|\n",
    "| **0.45**  | 0.2973    | 0.6126 | 0.4003 | 0.5054 |\n",
    "| **0.50**  | 0.3204    | 0.5113 | 0.3939 | 0.4569 |\n",
    "| **0.55**  | 0.3354    | 0.4594 | 0.3877 | 0.4278 |\n",
    "| **0.65**  | 0.3799    | 0.3277 | 0.3519 | 0.3370 |\n",
    "| **0.75**  | 0.4448    | 0.1404 | 0.2134 | 0.1627 |\n",
    "| **0.80**  | 0.5046    | 0.0442 | 0.0813 | 0.0541 |\n",
    "| **0.85**  | 0.5364    | 0.0001 | 0.0003 | 0.0002 |\n",
    "\n",
    "\n",
    "For our final implementations of the MLP model, we used a medium neural network (MLP1) and a shallow neural network (MLP2) to balance overfittings while still providing solid results compared to other tree models.\n",
    "\n",
    "\n",
    "#### Feature Engineering\n",
    "To allow for more streamlined feature engineering, a customized model pipeline using the rolling window data was created. Here, we used the non-null, raw data to transform into the scaled, embedded, vectorized features.\n",
    "\n",
    "\n",
    "All features were split into numerical (previously logged), numerical raw, categorical OHE, binary and categorical high and excluded. Numerical, raw, categorical and binary were transformed in the data pipeline and assembled into a final vector.\n",
    "\n",
    "\n",
    "Duplicate, co-linear features were removed including tail number, year, delays (for leakage), and specific departure times and time blocks.\n",
    "\n",
    "\n",
    "Finally the pipeline assembles a vector to use for training.\n",
    "\n",
    "\n",
    "#### Performance\n",
    "\n",
    "\n",
    "The medium network (MLP1) consisted of 4 layers: `[input_dim, 128, 64, 2]` and a step size of 0.01 vs a more shallow model (MLP2) of 3 layers `[input_dim, 32, 2]` with a smaller step size of 0.005. MLP2 prevented overfitting and resulted in improved F2, PR-AUC and ROC-AUC and recall. Generalization between the Training and Validation set showed overfitting for the Training set, however the model was fairly stable as results from the validation were repeatable in the Final test set. Results for both architectures are shown below:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "| Metric      | MLP1 Train | MLP1 Val | MLP2 Train | MLP2 Val | Final Test (MLP2) |\n",
    "|-------------|------------|----------|------------|----------|--------------------|\n",
    "| Recall      | 0.5575     | 0.5468   | 0.5814     | 0.5674   | 0.5625             |\n",
    "| Precision   | 0.6546     | 0.3171   | 0.6643     | 0.3176   | 0.3263             |\n",
    "| F1 Score    | 0.6298     | 0.7250   | 0.6426     | 0.7184   | 0.7211             |\n",
    "| F2 Score    | 0.5745     | 0.4776   | 0.5963     | 0.4902   | 0.4914             |\n",
    "| PR-AUC      | 0.6656     | 0.3384   | 0.6785     | 0.3398   | 0.3464             |\n",
    "| ROC-AUC     | 0.6633     | 0.6732   | 0.6820     | 0.6807   | 0.6812             |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Detailed model configurations, metrics and layer notes are included in the Experiment Details table here:\n",
    "\n",
    "\n",
    "| **Experiment**        | **Configs**                           | **Best Parameters**     | **Data**   | **Metric** | **Train** | **Validation** | **Test** |\n",
    "|-----------------------|----------------------------------------|--------------------------|------------|------------|-----------|----------------|----------|\n",
    "| **MLP (Downsampled)** | Layers: [input, 128, 64, 2], LR=0.005 | Downsampled positives    | Window 2   | F2 Score   | 0.5759    | 0.4669         | —        |\n",
    "|                       |                                        |                          |            | Recall     | 0.5562    | 0.5275         | —        |\n",
    "|                       |                                        |                          |            | Precision  | 0.6711    | 0.3199         | —        |\n",
    "|                       |                                        |                          |            | PR-AUC     | 0.6792    | 0.3342         | —        |\n",
    "| **MLP (Small)**       | Layers: [input, 32, 2]                | —                        | Window 2   | F2 Score   | 0.6006    | 0.4890         | 0.4914   |\n",
    "|                       |                                        |                          |            | Recall     | 0.5859    | 0.5673         | 0.5625   |\n",
    "|                       |                                        |                          |            | Precision  | 0.6673    | 0.3152         | 0.3263   |\n",
    "|                       |                                        |                          |            | PR-AUC     | 0.6834    | 0.3393         | 0.3464   |\n",
    "                         |\n",
    "\n",
    "\n",
    "##### Limitations\n",
    "MLP performed as well as XGBoost model, but required significantly more compute. MLP loss functions are limited to Multiclass Cross Entropy, activation to ReLU and output to Softmax. While these tools are powerful, they are not optimized for the tabular, imbalanced data in our dataset and therefore are prone to overfitting. Because results are similar to XGBoost but model training requires so much more compute, this model is not recommended.\n",
    "\n",
    "\n",
    "# Feature - Tokenizer Transformer with Multi-head Attention Model\n",
    "### Overview\n",
    "Our final, and best learning model is the Feature Tokenizer Transformer Model. This model had excellent generalization across training and validation, indicating that true patterns were being learned.\n",
    "\n",
    "Feature Tokenizer Transformer (FTT) models work similar to BERT in LLMs in that features are tokenized and a multi-head, self-attention blocks with feed-forward layers are used to understand relationships between the features. FTT models allow the users to customize and choose the best hidden layer, loss and output layer algorithms based on model requirements. This allows significant flexibility when designing the model. Further model modifications include dropout layers, head and block sizes, batch sizes and early stopping enablement, and regularization.\n",
    "\n",
    "FTTs are transformers built for analyzing tabular data and do best with an extremely large corpus of data. To do this, each feature is embedded into a vector, enabling transformers to operate on tabular columns. Categorical features require calculating cardinality to allow for embedding tables. This enables the transformer to capture cross-feature interactions natively. This is excellent when looking at flight features including airport, hour and weather interactions.\n",
    "\n",
    "\n",
    "### Implementation\n",
    "\n",
    "The Feature Tokenizer Transformer model was built with class imbalance and streamlined feature engineering in mind. A customized feature pipeline scaled numerical columns and counted cardinality for embedding categorical columns. Additionally, rolling windows were rebuilt without downsampling, to allow for class imbalance handling at the model level. This provided significantly more success than downsampling. Loss was initially calculated with Binary Cross Entropy, but later changed to Focal Loss and natively accounts for class imbalance through in-pipeline calculations of alpha, proving more successful. \n",
    "\n",
    "Due to compute limitations, the pipeline was only fit on 10% of the overall testing data. Some risks of this include not capturing all cardinalities for columns and fitting on skewed data. This should be further explored in other iterations. Additonally, early stopping was implemented with a patience of 2 epochs with no improvement on PR-AUC. This saved significant computer when trialing various architecture \n",
    "\n",
    "Initial experiments had a learning rate of 0.1, but were quickly aborted when results showed no learning. The learning rate was adjusted to 3e-4 and results improved significantly. Initial models leveraged out of the box configurations including 256 model dimensions, 8 attention heads with 3 layers and a dropout and attention dropout rate.\n",
    "Final implementations challenges included changing data from spark to pandas to Torch tensors for FTT model to use. This was achieved through using `.toPandas()` then the data was batched and loaded with `DataLoader`.\n",
    "\n",
    "\n",
    "##### Feature Engineering\n",
    "\n",
    "\n",
    "Similar to MLP - data was segmented into four classes: numerical log, numerical raw (17 numerical total), categorical OHE (11) and binary (15) resulting in 43 total features. Preprocessing pipeline was implemented to ensure data was properly formatted for the transformer and to allow for further feature engineering and tuning. Numerical columns were vectorized only to allow for scaling and categorial columns indexed to prepare for Tokenization.\n",
    "\n",
    "\n",
    "Different from previous models, the Feature Tokenizer Transformer converts each row of tabular data into a sequence of feature tokens rather than a single flattened vector.\n",
    "\n",
    "\n",
    "Numerical and binary data are grouped into individual vectors by row then projected into a single dense token of 192 dimensions:\n",
    "\n",
    "\n",
    "$$\n",
    "x_{\\text{num}} \\mapsto t_{\\text{num}} = W_{\\text{num}} x_{\\text{num}} + b\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Categorical tokens are not grouped. Each category receives its own embedded 192-dimension token. Each row includes a learnable classification (CLS) token as a global summary token for the Transformer.\n",
    "\n",
    "\n",
    "The full sequence of tokens is processed by the Transformer encoder via multi-head self-attention, and the final CLS embedding is used for downstream classification.\n",
    "\n",
    "\n",
    "Tokenization allows the transformer to learn interactions between heterogeneous feature types (numerical, categorical, binary) using self-attention, instead of forcing everything into a single fixed vector. This gives the model the ability to capture relationships that tree models and MLPs struggle with, such as time × weather × airline interactions.\n",
    "\n",
    "\n",
    "### Performance\n",
    "\n",
    "\n",
    "For functionality, the initial model was run with the 3 month rolling window dataset. Datasize limitations prevented the model from learning any measurable outcomes.\n",
    "\n",
    "\n",
    "The first experiment using the Feature Tokenizer Transformer was run on an NVIDIA T4 (16 GB GDDR6) GPU using the full 5 year dataset - with 4 years split into 2 rolling training windows to capture year over year interactions for 2015-2018 data with test data as 2019 reserved. The end to end model pipeline took ~4 hours to complete. Interestingly, we attempted to use the CPU to complete another iteration and stopped training after 15+ hours. Note that we did not use the downsampled dataset - that the imbalanced but processed dataset was used.\n",
    "\n",
    "\n",
    "Initial loss function was Binary Cross Entropy, but changed to Focal Loss to account for data imbalance. The final tuned model updated the gamma parameter from 2-> 1 for marginal improvement of F2 and PR-AUC. While final results for the Test dataset were similar to that of XGBoost and MLP, the very strong generalization across the board highlighted how the Feature Tokenizer Transformer model was able to learn nuances and relationships between features to result in a model with temporal learning.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "| **Experiment**                              | **Configs**                          | **Best Parameters**                | **Data**      | **Metric**   | **Train**     | **Validation** | **Test**    |\n",
    "|-------------------------------------------|----------------------------------|--------------------------------|-----------|----------|-----------|------------|----------|\n",
    "| FT-Transformer (BCE Loss)                 | Default FT-Transformer           | BCE Loss                       | Window 1  | F2 Score | —         | 0.5340     | —        |\n",
    "|                                           |                                  |                                |           | PR-AUC   | —         | 0.4352     | —        |\n",
    "|                                           |                                  |                                |           |          |           |            |          |\n",
    "| FT-Transformer (Focal γ=2)                | α≈0.8, γ=2.0                     | FocalLoss γ=2                  | Window 1  | F2 Score | 0.5334*   | 0.5334     | —        |\n",
    "|                                           |                                  |                                |           | PR-AUC   | 0.4379*   | 0.4357     | —        |\n",
    "|                                           |                                  |                                |           |          |           |            |          |\n",
    "| FT-Transformer (Focal γ=1, GPU Optimized) | α≈0.8, γ=1.0                     | FocalLoss γ=1, GPU tuning      | Window 1  | F2 Score | 0.5375*   | 0.5375     | 0.5267   |\n",
    "|                                           |                                  |                                |           | PR-AUC   | 0.4423*   | 0.4382     | 0.4516   |\n",
    "\n",
    "\n",
    "\n",
    "###  Limitations\n",
    "\n",
    "\n",
    "Current configurations of the FT-Transformer model allows for significant temporal learning through understanding interactions between features. However, significant compute is required to realize these results. Further improved learning can come from additional graph and temporal features, including modifying the weather data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5f9cf3de-7033-46ef-8cdb-8462e285f9f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Final Summary Table\n",
    "The below table documents the best train and test results for each model:\n",
    "\n",
    "| Model Name                     | Recall Train | Recall Test | Precision Train | Precision Test | F2 Train | F2 Test | PR-AUC Train | PR-AUC Test |\n",
    "|--------------------------------|-------------|------------|----------------|----------------|----------|---------|--------------|-------------|\n",
    "| |$${Recall} = \\frac{TP}{TP + FN}$$| |$${Precision} = \\frac{TP}{TP + FP}$$ | |$$F = \\frac{5 * Precision \\cdot Recall}{4 * Precision + Recall}$$| |$$PR \\space AUC = \\int_{0}^{1} Precision(r)dr$$ _Note: r = recall_ | |\n",
    "| Logistic Regression (Baseline) | 0.67        | 0.53       | 0.60           | 0.88           | 0.66     | 0.58    | 0.64         | 0.29        |\n",
    "| Random Forest                  | 0.68        | 0.67       | 0.65           | 0.31           | 0.67     | 0.55    | 0.69         | 0.367       |\n",
    "| Decision Tree                   | 0.65        | 0.11       | 0.66           | 0.73           | 0.65     | 0.13    | 0.71         | 0.41        |\n",
    "| XGBoost                         | 0.68        | 0.68       | 0.64           | 0.30           | 0.67     | 0.55    | 0.71         | 0.44        |\n",
    "| MLP                             | 0.59        | 0.56       | 0.67           | 0.33           | 0.60     | 0.49    | 0.68         | 0.35        |\n",
    "| FT-Transformer **(Best model)**     | 0.54        | 0.59       | 0.33           | 0.36           | 0.54     | 0.53    | 0.44         | 0.45        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e405f00f-4ac0-4c47-a46d-78a8e851de58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Final Evaluation for Best Model\n",
    "\n",
    "Given the customer’s requirements for high recall, acceptable precision, and stable performance over time, our team prioritized models that balance sensitivity with strong generalization. Although tree-based models delivered competitive recall, their precision and PR-AUC degraded substantially across temporal splits. In contrast, the FT-Transformer achieved the most consistent performance, with the strongest or second-strongest precision and PR-AUC metrics while maintaining high recall. This combination of stability and balanced predictive power makes it the most aligned with the customer’s operational needs.\n",
    "\n",
    "While downsampling to achieve a 50/50 class balance between the minority and majority class helped tree models increase recall on the minority class, this also impacts precision through increasing the number of delays overall predicted leading to lower precision.\n",
    "\n",
    "For this reason, we are proposing to move forward with the FT-Transformer model due to superior generalization and consistent performance for training, validation and test data. This is preferable, as high recall alone isn't sufficient as it can lead to significant false positives. This provides a temporally stable model across years to use for predicting future flight delays.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1cfe97e0-c68e-47f7-a167-7e6fc436a905",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Conclusions and Next Steps\n",
    "Based on our objective to deliver a robust, generalizable, and operationally actionable model for identifying delay risk, we recommend moving forward with the Feature Tokenizer Transformer for predicting arrival delays greater than 15 minutes. This model demonstrates the strongest overall generalization performance, consistently ranking first or second across key evaluation metrics. Its architecture effectively captures historical and temporal patterns in flight behavior, positioning it to support proactive, data-driven decision-making across airline operations.\n",
    "\n",
    "Second to the Feature Tokenizer Transformer model, XGBoost, had the highest recall and used significantly less compute. However, a focus on improved recall has a negative impact to precision resulting in poor generalization for that metric. \n",
    "\n",
    "In general, updated tree modeling results show clear progress beyond the original Logistic Regression baseline. While Logistic Regression provided interpretability and established a foundational benchmark, its linear structure limited its ability to capture non-linear interactions. In contrast, our Random Forest model demonstrated substantially stronger performance and better generalization, with validation and test F2 scores closely aligned with training results. This confirms that our shallow-depth ensemble effectively balances bias and variance while identifying a significantly larger share of delayed flights. The model’s recall of ~0.58 on unseen data indicates strong capability in detecting high-risk delays, though precision remains modest by design due to our recall-prioritized F2 optimization.\n",
    "\n",
    "Future iterations should focus on limiting data leakage, calculating features in real-time (such as graph based features), improved feature engineering - specifically for weather and location - flight - airline interactions. Model improvements should be focused on FT -Transformed - due to excelleng generalization and XGBoost due to strong results with minimum compute.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b7c82f5-40f6-4ed1-a020-418e2b3c80e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac2223b1-b87c-40e5-be45-cdea6c76cda8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## References\n",
    "\n",
    "Blmoistawinde. (n.d.). *Classical ML Equations in LaTeX*. Retrieved from https://blmoistawinde.github.io/ml_equations_latex/#classical-ml-equations-in-latex\n",
    " \n",
    "hwangdb. (2020, August 3). *SMOTE implementation in PySpark.* Medium. Retrieved from https://medium.com/@hwangdb/smote-implementation-in-pyspark-76ec4ffa2f1d\n",
    " \n",
    "Deepanshu Rustagi. (2025, July 23). *Data Normalization with Pandas*. GeeksforGeeks. Retrieved from https://www.geeksforgeeks.org/python/data-normalization-with-pandas/\n",
    "\n",
    "Goodman, C. J., & Small Griswold, J. D. (2019). *Meteorological impacts on commercial aviation delays and cancellations in the continental United States*. Journal of Applied Meteorology and Climatology, 58 (3), 479–494. https://doi.org/10.1175/JAMC-D-17-0277.1\n",
    "\n",
    "Ball, M., Barnhart, C., Dresner, M., Hansen, M., Neels, K., Odoni, A. R., Peterson, E., Sherry, L., Trani, A., & Zou, B. (2010, October 1). *Total delay impact study : A comprehensive assessment of the costs and impacts of flight delay in the United States*. University of California, Berkeley Institute of Transportation Studies; National Center for Excellence for Aviation Operations Research (U.S.). Retrieved from https://rosap.ntl.bts.gov/view/dot/6234\n",
    "\n",
    "BTS. Airline On-Time Performance and Causes of Flight Delays.\n",
    "https://www.bts.gov/explore-topics-and-geography/topics/airline-time-performance-and-causes-flight-delays\n",
    "\n",
    "Kim & Park (2024)\n",
    "Kim, S., & Park, E. (2024). Prediction of flight departure delays caused by weather conditions adopting data-driven approaches. Journal of Big Data, 11(11), Article 11. https://doi.org/10.1186/s40537-023-00808-4\n",
    "\n",
    "Bombelli, A., & Sallan, J. M. (2023). Analysis of the effect of extreme weather on the U.S. domestic air network: A delay and cancellation propagation network approach. Journal of Transport Geography, 107, 103541. https://doi.org/10.1016/j.jtrangeo.2023.103541\n",
    "\n",
    "Qu, J., Wu, S., & Zhang, J. (2023). Flight delay propagation prediction based on deep learning. Mathematics, 11(3), 494. https://doi.org/10.3390/math11030494\n",
    "\n",
    "Federal Aviation Administration. (2012). Airport Design: AC 150/5300-13A Change 1, Part 2: Taxiways, Taxilanes, and Other Pavement Areas. U.S. Department of Transportation. https://www.faa.gov/documentLibrary/media/Advisory_Circular/150_5300_13_part2.pdf\n",
    "\n",
    "\n",
    "##### Amy's Notebooks #####\n",
    "EDA: https://dbc-fae72cab-cf59.cloud.databricks.com/editor/notebooks/2286625639680451?o=4021782157704243\n",
    "\n",
    "Flight Data Transformed: https://dbc-fae72cab-cf59.cloud.databricks.com/editor/notebooks/3531767936423819?o=4021782157704243\n",
    "\n",
    "Joined Station to Airport: https://dbc-fae72cab-cf59.cloud.databricks.com/editor/notebooks/2352307875986443?o=4021782157704243\n",
    "\n",
    "Weather Data Transformation: https://dbc-fae72cab-cf59.cloud.databricks.com/editor/notebooks/2352307875986377?o=4021782157704243\n",
    "\n",
    "Graph Features for New Data Engineering Pipeline (folder link to notebooks): https://dbc-fae72cab-cf59.cloud.databricks.com/browse/folders/1792055957781843?o=4021782157704243\n",
    "\n",
    "\n",
    "##### Kristen's Notebooks #####\n",
    "Dirty EDA: https://dbc-fae72cab-cf59.cloud.databricks.com/editor/notebooks/3996078929051707?o=4021782157704243\n",
    "\n",
    "Join Conditions and UTC Analysis: https://dbc-fae72cab-cf59.cloud.databricks.com/editor/notebooks/669506783946165?o=4021782157704243\n",
    "\n",
    "Visualizations: https://dbc-fae72cab-cf59.cloud.databricks.com/editor/notebooks/4473559687182748?o=4021782157704243\n",
    "\n",
    "XGBoost with MLFlow: https://dbc-fae72cab-cf59.cloud.databricks.com/editor/notebooks/1792055957780132?o=4021782157704243\n",
    "\n",
    "New Data Engineering Pipeline (folder link to notebooks): https://dbc-fae72cab-cf59.cloud.databricks.com/browse/folders/1792055957781843?o=4021782157704243\n",
    "\n",
    "\n",
    "##### Chad's Notebooks #####\n",
    "Random Forest Workstation: https://dbc-fae72cab-cf59.cloud.databricks.com/editor/notebooks/4025624374369731?o=4021782157704243\n",
    "\n",
    "Random Forest Final Model (w/ MLFlow): https://dbc-fae72cab-cf59.cloud.databricks.com/editor/notebooks/4336423679577095?o=4021782157704243\n",
    "\n",
    "Smote + Sampling Playground: https://dbc-fae72cab-cf59.cloud.databricks.com/editor/notebooks/2421064614439929?o=4021782157704243\n",
    "\n",
    "EDA (joined w/ Priscilla & Uma): https://dbc-fae72cab-cf59.cloud.databricks.com/editor/notebooks/1792055957779964?o=4021782157704243\n",
    "\n",
    "Master's Final EDA on 5-yr Run: https://dbc-fae72cab-cf59.cloud.databricks.com/editor/notebooks/2867436822485711?o=4021782157704243\n",
    "\n",
    "\n",
    "##### Priscilla's Notebooks #####\n",
    "OTPW EDA: https://dbc-fae72cab-cf59.cloud.databricks.com/editor/notebooks/3996078929051671?o=4021782157704243\n",
    "\n",
    "Logistic Regression Feature Selection & Correlation Analysis: https://dbc-fae72cab-cf59.cloud.databricks.com/editor/notebooks/1739154845296952?o=4021782157704243\n",
    "\n",
    "Logistic Regression Model: https://dbc-fae72cab-cf59.cloud.databricks.com/editor/notebooks/1792055957779349?o=4021782157704243\n",
    "\n",
    "\n",
    "##### Uma's Notebooks #####\n",
    "Descision Tree Notebook: https://dbc-fae72cab-cf59.cloud.databricks.com/editor/notebooks/4093368127198808?o=4021782157704243#command/4093368127198809\n",
    "\n",
    "EDA 5 year (joined with Chad and Priscilla): https://dbc-fae72cab-cf59.cloud.databricks.com/editor/notebooks/1792055957779964?o=4021782157704243\n",
    "\n",
    "EDA 1 year (built off the prior): https://dbc-fae72cab-cf59.cloud.databricks.com/editor/notebooks/1792055957780666?o=4021782157704243\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7209d27c-bb34-4051-bd37-3cac9861c067",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b3fed86-dc2f-45b9-ad52-4fb2d2876095",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Appendix A: Data Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "41171cbf-e147-4f30-b09f-d00a32844c47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## A.1.1 Flight Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "18b68e58-6e2b-43fc-85cf-297452e91331",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "| **Column Name**                   | **Definition**                                                                                                    | **Format**      | **Type** |\n",
    "| --------------------------------- | ----------------------------------------------------------------------------------------------------------------- | --------------- | -------- |\n",
    "| OntimeArrivalPct                  | Percent of flights that arrive on time. Represents percent of on-time arrivals at airports (Origin/Dest-based).   | Percentage      | Float    |\n",
    "| OntimeDeparturePct                | Percent of flights that depart on time. Represents percent of on-time departures at airports (Origin/Dest-based). | Percentage      | Float    |\n",
    "| TimePeriod                        | General time grouping for reporting.                                                                              | YYYY-MM-DD      | Date     |\n",
    "| Year                              | Calendar year.                                                                                                    | YYYY            | Integer  |\n",
    "| Quarter                           | Quarter of the year (1–4).                                                                                        | Integer         | Integer  |\n",
    "| Month                             | Month number (1–12).                                                                                              | Integer         | Integer  |\n",
    "| DayofMonth                        | Day of the month.                                                                                                 | Integer         | Integer  |\n",
    "| DayOfWeek                         | Day of the week (1=Monday, …, 7=Sunday).                                                                          | Integer         | Integer  |\n",
    "| FlightDate                        | Scheduled flight date.                                                                                            | YYYY-MM-DD      | Date     |\n",
    "| Airline                           | Full carrier name.                                                                                                | Text            | String   |\n",
    "| Reporting_Airline                 | Unique carrier code assigned by DOT.                                                                              | 2–3 letter code | String   |\n",
    "| DOT_ID_Reporting_Airline          | DOT-assigned numeric ID identifying a unique airline.                                                             | Numeric         | Integer  |\n",
    "| IATA_CODE_Reporting_Airline       | IATA 2-letter airline code.                                                                                       | 2-letter code   | String   |\n",
    "| Tail_Number                       | Aircraft registration number.                                                                                     | Alphanumeric    | String   |\n",
    "| Flight_Number_Reporting_Airline   | Scheduled flight number.                                                                                          | Numeric         | Integer  |\n",
    "| Origin                            | Origin airport 3-letter IATA code.                                                                                | 3-letter code   | String   |\n",
    "| OriginAirportID                   | Unique numeric ID for origin airport.                                                                             | Numeric         | Integer  |\n",
    "| OriginAirportSeqID                | Sequence ID for origin airport (time-specific).                                                                   | Numeric         | Integer  |\n",
    "| OriginCityMarketID                | City market ID grouping airports serving the same area.                                                           | Numeric         | Integer  |\n",
    "| OriginCityName                    | Origin city name.                                                                                                 | Text            | String   |\n",
    "| OriginState                       | Two-letter state code for origin airport.                                                                         | 2-letter code   | String   |\n",
    "| OriginStateFips                   | FIPS code for origin state.                                                                                       | Numeric         | Integer  |\n",
    "| OriginStateName                   | Full name of origin state.                                                                                        | Text            | String   |\n",
    "| OriginWac                         | World Area Code for origin airport.                                                                               | Numeric         | Integer  |\n",
    "| Dest                              | Destination airport 3-letter IATA code.                                                                           | 3-letter code   | String   |\n",
    "| DestAirportID                     | Unique numeric ID for destination airport.                                                                        | Numeric         | Integer  |\n",
    "| DestAirportSeqID                  | Sequence ID for destination airport (time-specific).                                                              | Numeric         | Integer  |\n",
    "| DestCityMarketID                  | City market ID grouping airports serving the same area.                                                           | Numeric         | Integer  |\n",
    "| DestCityName                      | Destination city name.                                                                                            | Text            | String   |\n",
    "| DestState                         | Two-letter state code for destination airport.                                                                    | 2-letter code   | String   |\n",
    "| DestStateFips                     | FIPS code for destination state.                                                                                  | Numeric         | Integer  |\n",
    "| DestStateName                     | Full name of destination state.                                                                                   | Text            | String   |\n",
    "| DestWac                           | World Area Code for destination airport.                                                                          | Numeric         | Integer  |\n",
    "| CRSDepTime                        | Scheduled departure time (local, hhmm).                                                                           | hhmm            | Integer  |\n",
    "| DepTime                           | Actual departure time (local, hhmm).                                                                              | hhmm            | Integer  |\n",
    "| DepDelay                          | Difference between scheduled and actual departure time (min, can be negative).                                    | Minutes         | Float    |\n",
    "| DepDelayMinutes                   | Delay in minutes (early departures set to 0).                                                                     | Minutes         | Float    |\n",
    "| DepDel15                          | Departure delay indicator (1 = ≥15 min delay).                                                                    | Binary          | Integer  |\n",
    "| DepartureDelayGroups              | Departure delay intervals, every 15 minutes from <−15 to >180.                                                    | Category        | Integer  |\n",
    "| DepTimeBlk                        | Scheduled departure time block (hourly).                                                                          | Text            | String   |\n",
    "| TaxiOut                           | Taxi-out time (minutes).                                                                                          | Minutes         | Float    |\n",
    "| WheelsOff                         | Time wheels left ground (local hhmm).                                                                             | hhmm            | Integer  |\n",
    "| WheelsOn                          | Time wheels touched down (local hhmm).                                                                            | hhmm            | Integer  |\n",
    "| TaxiIn                            | Taxi-in time (minutes).                                                                                           | Minutes         | Float    |\n",
    "| CRSArrTime                        | Scheduled arrival time (local hhmm).                                                                              | hhmm            | Integer  |\n",
    "| ArrTime                           | Actual arrival time (local hhmm).                                                                                 | hhmm            | Integer  |\n",
    "| ArrDelay                          | Difference between scheduled and actual arrival time (minutes, can be negative).                                  | Minutes         | Float    |\n",
    "| ArrDelayMinutes                   | Delay in minutes (early arrivals set to 0).                                                                       | Minutes         | Float    |\n",
    "| ArrDel15                          | Arrival delay indicator (1 = ≥15 min delay).                                                                      | Binary          | Integer  |\n",
    "| ArrivalDelayGroups                | Arrival delay intervals, every 15 minutes from <−15 to >180.                                                      | Category        | Integer  |\n",
    "| ArrTimeBlk                        | Scheduled arrival time block (hourly).                                                                            | Text            | String   |\n",
    "| Cancelled                         | Cancelled flight indicator (1 = Yes).                                                                             | Binary          | Integer  |\n",
    "| CancellationCode                  | Reason for cancellation (A=Carrier, B=Weather, C=NAS, D=Security).                                                | 1-letter code   | String   |\n",
    "| Diverted                          | Diverted flight indicator (1 = Yes).                                                                              | Binary          | Integer  |\n",
    "| CRSElapsedTime                    | Scheduled block time (minutes).                                                                                   | Minutes         | Float    |\n",
    "| ActualElapsedTime                 | Actual block time (minutes).                                                                                      | Minutes         | Float    |\n",
    "| AirTime                           | Airborne time (minutes).                                                                                          | Minutes         | Float    |\n",
    "| Flights                           | Count of flight records.                                                                                          | Numeric         | Integer  |\n",
    "| Distance                          | Great-circle distance between airports (miles).                                                                   | Miles           | Float    |\n",
    "| DistanceGroup                     | Distance grouping (bins of 250 miles).                                                                            | Category        | Integer  |\n",
    "| CarrierDelay                      | Delay due to airline (minutes).                                                                                   | Minutes         | Float    |\n",
    "| WeatherDelay                      | Delay due to weather (minutes).                                                                                   | Minutes         | Float    |\n",
    "| NASDelay                          | Delay due to National Airspace System (minutes).                                                                  | Minutes         | Float    |\n",
    "| SecurityDelay                     | Delay due to security reasons (minutes).                                                                          | Minutes         | Float    |\n",
    "| LateAircraftDelay                 | Delay caused by late arrival of previous aircraft (minutes).                                                      | Minutes         | Float    |\n",
    "| FirstDepTime                      | First gate departure time for gate return/cancelled flight.                                                       | hhmm            | Integer  |\n",
    "| TotalAddGTime                     | Total ground time away from gate for gate return/cancelled flight.                                                | Minutes         | Float    |\n",
    "| LongestAddGTime                   | Longest time away from gate for gate return/cancelled flight.                                                     | Minutes         | Float    |\n",
    "| DivAirportLandings                | Number of diverted airport landings.                                                                              | Numeric         | Integer  |\n",
    "| DivReachedDest                    | Indicator that diverted flight reached scheduled destination (1=Yes).                                             | Binary          | Integer  |\n",
    "| DivActualElapsedTime              | Elapsed time for diverted flight reaching destination.                                                            | Minutes         | Float    |\n",
    "| DivArrDelay                       | Arrival delay for diverted flight reaching destination.                                                           | Minutes         | Float    |\n",
    "| DivDistance                       | Distance between scheduled destination and diverted airport (miles).                                              | Miles           | Float    |\n",
    "| Div1Airport–Div5Airport           | Diversion airport codes (1–5).                                                                                    | 3-letter code   | String   |\n",
    "| Div1AirportID–Div5AirportID       | Numeric IDs for diversion airports (1–5).                                                                         | Numeric         | Integer  |\n",
    "| Div1AirportSeqID–Div5AirportSeqID | Sequence IDs for diversion airports (1–5).                                                                        | Numeric         | Integer  |\n",
    "| Div1WheelsOn–Div5WheelsOn         | Wheels-on times at diversion airports (local hhmm).                                                               | hhmm            | Integer  |\n",
    "| Div1WheelsOff–Div5WheelsOff       | Wheels-off times at diversion airports (local hhmm).                                                              | hhmm            | Integer  |\n",
    "| Div1TotalGTime–Div5TotalGTime     | Total ground time at diversion airports (1–5).                                                                    | Minutes         | Float    |\n",
    "| Div1LongestGTime–Div5LongestGTime | Longest ground time at diversion airports (1–5).                                                                  | Minutes         | Float    |\n",
    "| Div1TailNum–Div5TailNum           | Aircraft tail numbers for diversion airports (1–5).                                                               | Alphanumeric    | String   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "785afa4f-3e71-4aa5-a1d1-e29d9fff3763",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## A.1.2 Airport Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a2d00f5-599b-4f98-b012-cb5575c2c5f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "| Column Name  | Definition                                                                                                                            | Known Selected Features |\n",
    "| ------------ | ------------------------------------------------------------------------------------------------------------------------------------- | ----------------------- |\n",
    "| ident        | Primary identifier for the airport record (often ICAO code or internal ID). Typically unique within the dataset.                      |                         |\n",
    "| type         | Classification of the airport or facility (e.g., “large_airport,” “medium_airport,” “small_airport,” “heliport”).                     | X                       |\n",
    "| name         | Full official name of the airport or facility.                                                                                        |                         |\n",
    "| elevation_ft | Elevation of the airport above mean sea level, measured in feet.                                                                      | X                       |\n",
    "| continent    | Continent code where the airport is located, following UN/LOCODE format (e.g., “NA” for North America, “EU” for Europe).              |                         |\n",
    "| iso_country  | ISO 3166-1 alpha-2 country code representing the country of the airport (e.g., “US” for United States, “CA” for Canada).              |                         |\n",
    "| iso_region   | ISO 3166-2 region code specifying the administrative subdivision (e.g., “US-CA” for California, United States).                       |                         |\n",
    "| municipality | Municipality or city served by the airport. Often used in passenger-facing contexts (e.g., “San Francisco”).                          |                         |\n",
    "| icao_code    | ICAO (International Civil Aviation Organization) airport code — a four-letter code used in air traffic control and flight operations. | X                       |\n",
    "| iata_code    | IATA (International Air Transport Association) airport code — a three-letter code used in passenger systems.                          | X                       |\n",
    "| gps_code     | Code used by GPS navigation systems, often the same as ICAO or local code depending on data source.                                   |                         |\n",
    "| local_code   | Locally used airport code (typically assigned by national aviation authorities when no ICAO/IATA exists).                             |                         |\n",
    "| coordinates  | Geographic coordinates (latitude and longitude) of the airport, often in “lat,lon” format.                                            | X                       |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f1dcba3-a274-4213-8c17-f7d588bdd00b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## A.1.3 Station Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8110062e-2cd5-4329-ab1d-b59d2f4e411b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "| **Column Name**      | **Definition**                                                                 | **Format**              | **Type** |\n",
    "| -------------------- | ------------------------------------------------------------------------------ | ----------------------- | -------- |\n",
    "| usaf                 | USAF (United States Air Force) station identifier for the airport              | 6-digit code            | String   |\n",
    "| wban                 | WBAN (Weather Bureau Army Navy) identifier used by NOAA for station tracking   | 5-digit code            | String   |\n",
    "| station_id           | Combined identifier (often USAF+WBAN or unique key) for the weather station    | Alphanumeric            | String   |\n",
    "| lat                  | Latitude of the airport or station in decimal degrees                          | Decimal (e.g., 37.62)   | Float    |\n",
    "| lon                  | Longitude of the airport or station in decimal degrees                         | Decimal (e.g., -122.38) | Float    |\n",
    "| neighbor_id          | Unique identifier of the closest neighboring airport or weather station        | Alphanumeric            | String   |\n",
    "| neighbor_name        | Common name of the neighboring airport or station                              | Text                    | String   |\n",
    "| neighbor_state       | Two-letter state code of the neighboring station (if in the U.S.)              | 2-character code        | String   |\n",
    "| neighbor_call        | ICAO or FAA call sign (airport code) of the neighboring station                | 3–4 letter code         | String   |\n",
    "| neighbor_lat         | Latitude of the neighboring station in decimal degrees                         | Decimal                 | Float    |\n",
    "| neighbor_lon         | Longitude of the neighboring station in decimal degrees                        | Decimal                 | Float    |\n",
    "| distance_to_neighbor | Distance between the airport and its nearest neighbor (in kilometers or miles) | Numeric (e.g., 12.5)    | Float    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ed2f5e8-3169-471e-a4aa-81e84e07132a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## A.1.4 Data Dictionary for Weather Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4dd0161f-db25-4a19-ba94-7fd292657403",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "| **Column Name**                              | **Definition**                                                                   | **Format**          | **Type**                                      |\n",
    "| -------------------------------------------- | -------------------------------------------------------------------------------- | ------------------- | --------------------------------------------- |\n",
    "| STATION                                      | Unique station identifier (USAF+WBAN concatenation).                             | ID                  | alphanumeric                                  |\n",
    "| DATE                                         | UTC date-time of observation or summary period in ISO-like format.               | YYYY-MM-DD[THH:MMZ] | 0000-01-01 to 9999-12-31                      |\n",
    "| LATITUDE                                     | Latitude of station; south negative.                                             | degrees             | [-90, 90]; scale 0.001 in raw ISD             |\n",
    "| LONGITUDE                                    | Longitude of station; west negative.                                             | degrees             | [-180, 180]; scale 0.001 in raw ISD           |\n",
    "| ELEVATION                                    | Station elevation above mean sea level.                                          | meters              | [-400, 8850]                                  |\n",
    "| NAME                                         | Station name.                                                                    | text                | —                                             |\n",
    "| REPORT_TYPE                                  | Report type code (e.g., METAR, SPECI, SYNOP, etc.).                              | code                | see ISD domain                                |\n",
    "| SOURCE                                       | Data source/merge flag describing origin of observation.                         | code                | 1–9,A–N,O                                     |\n",
    "| HourlyAltimeterSetting                       | Altimeter setting (aviation QNH).                                                | hPa or inHg         | typ ~ 950–1050 hPa                            |\n",
    "| HourlyDewPointTemperature                    | Dew point temperature.                                                           | °C                  | [-98.2, +36.8]; scale 0.1                     |\n",
    "| HourlyDryBulbTemperature                     | Air temperature (dry-bulb).                                                      | °C                  | [-93.2, +61.8]; scale 0.1                     |\n",
    "| HourlyPrecipitation                          | Liquid precipitation during the hour.                                            | mm                  | [0, ~]; scale 0.1 (AA1–AA4)                   |\n",
    "| HourlyPresentWeatherType                     | Present weather code(s) (e.g., RA, SN, FG, TS).                                  | code                | WMO code groups                               |\n",
    "| HourlyPressureChange                         | Pressure change over specified interval.                                         | hPa                 | dataset dependent                             |\n",
    "| HourlyPressureTendency                       | Pressure tendency code (rising/falling/steady).                                  | code                | WMO tendency codes                            |\n",
    "| HourlyRelativeHumidity                       | Relative humidity.                                                               | %                   | [0,100]                                       |\n",
    "| HourlySkyConditions                          | Sky condition summary (layers/ceiling/CAVOK).                                    | code/text           | see ISD domains                               |\n",
    "| HourlySeaLevelPressure                       | Sea-level pressure.                                                              | hPa                 | [860.0, 1090.0]; scale 0.1                    |\n",
    "| HourlyStationPressure                        | Station pressure (at station elevation).                                         | hPa                 | dataset dependent; often scale 0.1            |\n",
    "| HourlyVisibility                             | Prevailing horizontal visibility.                                                | meters              | [0, 160000]; capped at 160000                 |\n",
    "| HourlyWetBulbTemperature                     | Wet-bulb temperature.                                                            | °C                  | dataset dependent; often scale 0.1            |\n",
    "| HourlyWindDirection                          | Wind direction (from which blowing).                                             | degrees (true)      | [1,360] or 999 (missing/variable with type=V) |\n",
    "| HourlyWindGustSpeed                          | Maximum wind gust speed during the hour.                                         | m/s                 | [0,90.0]; scale 0.1                           |\n",
    "| HourlyWindSpeed                              | Average/sustained wind speed.                                                    | m/s                 | [0,90.0]; scale 0.1                           |\n",
    "| Sunrise                                      | Local sunrise time for station location/date.                                    | local time          | HH:MM                                         |\n",
    "| Sunset                                       | Local sunset time for station location/date.                                     | local time          | HH:MM                                         |\n",
    "| DailyAverageDewPointTemperature              | Daily average of hourly dew point.                                               | °C                  | physical range                                |\n",
    "| DailyAverageDryBulbTemperature               | Daily average of hourly air temperature.                                         | °C                  | physical range                                |\n",
    "| DailyAverageRelativeHumidity                 | Daily average relative humidity.                                                 | %                   | [0,100]                                       |\n",
    "| DailyAverageSeaLevelPressure                 | Daily average sea-level pressure.                                                | hPa                 | physical range                                |\n",
    "| DailyAverageStationPressure                  | Daily average station pressure.                                                  | hPa                 | physical range                                |\n",
    "| DailyAverageWetBulbTemperature               | Daily average wet-bulb temperature.                                              | °C                  | physical range                                |\n",
    "| DailyAverageWindSpeed                        | Daily average wind speed.                                                        | m/s                 | [0, ~]                                        |\n",
    "| DailyCoolingDegreeDays                       | Cooling degree-days for the day (dataset base).                                  | degree-days         | >=0                                           |\n",
    "| DailyDepartureFromNormalAverageTemperature   | Departure from normal for daily mean temperature.                                | °C                  | signed                                        |\n",
    "| DailyHeatingDegreeDays                       | Heating degree-days for the day (dataset base).                                  | degree-days         | >=0                                           |\n",
    "| DailyMaximumDryBulbTemperature               | Maximum air temperature of the day.                                              | °C                  | physical range                                |\n",
    "| DailyMinimumDryBulbTemperature               | Minimum air temperature of the day.                                              | °C                  | physical range                                |\n",
    "| DailyPeakWindDirection                       | Direction of the day's peak wind.                                                | degrees (true)      | 1–360 or 999 missing                          |\n",
    "| DailyPeakWindSpeed                           | Peak wind speed during the day.                                                  | m/s                 | >=0; often scale 0.1                          |\n",
    "| DailyPrecipitation                           | Total liquid precipitation for the day.                                          | mm                  | >=0; scale often 0.1                          |\n",
    "| DailySnowDepth                               | Snow depth on ground (reference time).                                           | cm                  | [0,1200]                                      |\n",
    "| DailySnowfall                                | New snowfall during the day.                                                     | mm or cm            | >=0                                           |\n",
    "| DailySustainedWindDirection                  | Direction of sustained wind (defined period).                                    | degrees (true)      | 1–360                                         |\n",
    "| DailySustainedWindSpeed                      | Daily maximum sustained wind speed.                                              | m/s                 | >=0; often scale 0.1                          |\n",
    "| DailyWeather                                 | Daily weather summary codes.                                                     | code/text           | —                                             |\n",
    "| MonthlyAverageRH                             | Monthly average relative humidity.                                               | %                   | [0,100]                                       |\n",
    "| MonthlyDaysWithGT001Precip                   | Count of days with ≥0.01 in (≈0.25 mm) precipitation.                            | days                | [0,31]                                        |\n",
    "| MonthlyDaysWithGT010Precip                   | Count of days with ≥0.10 in (≈2.5 mm) precipitation.                             | days                | [0,31]                                        |\n",
    "| MonthlyDaysWithGT32Temp                      | Count of days with max temp above threshold (dataset uses 32°F or 32°C context). | days                | [0,31]                                        |\n",
    "| MonthlyDaysWithGT90Temp                      | Count of days with max temp >90°F.                                               | days                | [0,31]                                        |\n",
    "| MonthlyDaysWithLT0Temp                       | Count of days with min temp <0°C.                                                | days                | [0,31]                                        |\n",
    "| MonthlyDaysWithLT32Temp                      | Count of days with min temp <32°F.                                               | days                | [0,31]                                        |\n",
    "| MonthlyDepartureFromNormalAverageTemperature | Departure of monthly mean temperature from normal.                               | °C                  | signed                                        |\n",
    "| MonthlyDepartureFromNormalCoolingDegreeDays  | Departure of monthly total CDD from normal.                                      | degree-days         | signed                                        |\n",
    "| MonthlyDepartureFromNormalHeatingDegreeDays  | Departure of monthly total HDD from normal.                                      | degree-days         | signed                                        |\n",
    "| MonthlyDepartureFromNormalMaximumTemperature | Departure of monthly max temperature from normal.                                | °C                  | signed                                        |\n",
    "| MonthlyDepartureFromNormalMinimumTemperature | Departure of monthly min temperature from normal.                                | °C                  | signed                                        |\n",
    "| MonthlyDepartureFromNormalPrecipitation      | Departure of monthly precipitation from normal.                                  | mm                  | signed                                        |\n",
    "| MonthlyDewpointTemperature                   | Monthly average dew point temperature.                                           | °C                  | physical range                                |\n",
    "| MonthlyGreatestPrecip                        | Greatest 24-hour (or daily) precipitation in the month.                          | mm                  | >=0; scale 0.1                                |\n",
    "| MonthlyGreatestPrecipDate                    | Date of greatest precipitation in the month.                                     | MMDD or DD          | 0101–1231 or 01–31                            |\n",
    "| MonthlyGreatestSnowDepth                     | Greatest snow depth observed in the month.                                       | cm                  | [0,1200]                                      |\n",
    "| MonthlyGreatestSnowDepthDate                 | Date of greatest snow depth.                                                     | MMDD or DD          | 0101–1231 or 01–31                            |\n",
    "| MonthlyGreatestSnowfall                      | Greatest daily snowfall in the month.                                            | mm or cm            | >=0                                           |\n",
    "| MonthlyGreatestSnowfallDate                  | Date of greatest snowfall.                                                       | MMDD or DD          | 0101–1231 or 01–31                            |\n",
    "| MonthlyMaxSeaLevelPressureValue              | Maximum sea-level pressure value in the month.                                   | hPa                 | scale 0.1                                     |\n",
    "| MonthlyMaxSeaLevelPressureValueDate          | Date of maximum sea-level pressure.                                              | MMDD or DD          | 0101–1231 or 01–31                            |\n",
    "| MonthlyMaxSeaLevelPressureValueTime          | Time of maximum sea-level pressure (UTC).                                        | HHMM                | 0000–2359                                     |\n",
    "| MonthlyMaximumTemperature                    | Maximum temperature observed in the month.                                       | °C                  | physical range                                |\n",
    "| MonthlyMeanTemperature                       | Mean temperature for the month.                                                  | °C                  | physical range                                |\n",
    "| MonthlyMinSeaLevelPressureValue              | Minimum sea-level pressure value in the month.                                   | hPa                 | scale 0.1                                     |\n",
    "| MonthlyMinSeaLevelPressureValueDate          | Date of minimum sea-level pressure.                                              | MMDD or DD          | 0101–1231 or 01–31                            |\n",
    "| MonthlyMinSeaLevelPressureValueTime          | Time of minimum sea-level pressure (UTC).                                        | HHMM                | 0000–2359                                     |\n",
    "| MonthlyMinimumTemperature                    | Minimum temperature observed in the month.                                       | °C                  | physical range                                |\n",
    "| MonthlySeaLevelPressure                      | Monthly average sea-level pressure.                                              | hPa                 | scale 0.1                                     |\n",
    "| MonthlyStationPressure                       | Monthly average station pressure.                                                | hPa                 | scale 0.1                                     |\n",
    "| MonthlyTotalLiquidPrecipitation              | Total liquid precipitation for the month.                                        | mm                  | [0,5000.0]; scale 0.1                         |\n",
    "| MonthlyTotalSnowfall                         | Total snowfall for the month.                                                    | mm or cm            | >=0                                           |\n",
    "| MonthlyWetBulb                               | Monthly average wet-bulb temperature.                                            | °C                  | physical range                                |\n",
    "| AWND                                         | Average daily wind speed for the month.                                          | m/s                 | >=0                                           |\n",
    "| CDSD                                         | Cooling degree-day statistic for the month (definition varies).                  | degree-days         | >=0 or signed                                 |\n",
    "| CLDD                                         | Cooling degree-days total for the month.                                         | degree-days         | >=0                                           |\n",
    "| DSNW                                         | Number of days with measurable snowfall in the month.                            | days                | [0,31]                                        |\n",
    "| HDSD                                         | Heating degree-day statistic for the month (definition varies).                  | degree-days         | >=0 or signed                                 |\n",
    "| HTDD                                         | Heating degree-days total for the month.                                         | degree-days         | >=0                                           |\n",
    "| NormalsCoolingDegreeDay                      | Long-term normal cooling degree-days for the month.                              | degree-days         | >=0                                           |\n",
    "| NormalsHeatingDegreeDay                      | Long-term normal heating degree-days for the month.                              | degree-days         | >=0                                           |\n",
    "| ShortDurationEndDate005                      | End date/time for 5-minute maximum precipitation event in the month.             | MMDDHHMM (UTC)      | 01010000–12312359                             |\n",
    "| ShortDurationEndDate010                      | End date/time for 10-minute maximum precipitation event.                         | MMDDHHMM (UTC)      | 01010000–12312359                             |\n",
    "| ShortDurationEndDate015                      | End date/time for 15-minute maximum precipitation event.                         | MMDDHHMM (UTC)      | 01010000–12312359                             |\n",
    "| ShortDurationEndDate020                      | End date/time for 20-minute maximum precipitation event.                         | MMDDHHMM (UTC)      | 01010000–12312359                             |\n",
    "| ShortDurationEndDate030                      | End date/time for 30-minute maximum precipitation event.                         | MMDDHHMM (UTC)      | 01010000–12312359                             |\n",
    "| ShortDurationEndDate045                      | End date/time for 45-minute maximum precipitation event.                         | MMDDHHMM (UTC)      | 01010000–12312359                             |\n",
    "| ShortDurationEndDate060                      | End date/time for 60-minute maximum precipitation event.                         | MMDDHHMM (UTC)      | 01010000–12312359                             |\n",
    "| ShortDurationEndDate080                      | End date/time for 80-minute maximum precipitation event.                         | MMDDHHMM (UTC)      | 01010000–12312359                             |\n",
    "| ShortDurationEndDate100                      | End date/time for 100-minute maximum precipitation event.                        | MMDDHHMM (UTC)      | 01010000–12312359                             |\n",
    "| ShortDurationEndDate120                      | End date/time for 120-minute maximum precipitation event.                        | MMDDHHMM (UTC)      | 01010000–12312359                             |\n",
    "| ShortDurationEndDate150                      | End date/time for 150-minute maximum precipitation event.                        | MMDDHHMM (UTC)      | 01010000–12312359                             |\n",
    "| ShortDurationEndDate180                      | End date/time for 180-minute maximum precipitation event.                        | MMDDHHMM (UTC)      | 01010000–12312359                             |\n",
    "| ShortDurationPrecipitationValue005           | Precip amount over 5-minute interval for the recorded maximum.                   | mm                  | [0,300.0]; scale 0.1                          |\n",
    "| ShortDurationPrecipitationValue010           | Precip amount over 10-minute interval for the recorded maximum.                  | mm                  | [0,300.0]; scale 0.1                          |\n",
    "| ShortDurationPrecipitationValue015           | Precip amount over 15-minute interval for the recorded maximum.                  | mm                  | [0,300.0]; scale 0.1                          |\n",
    "| ShortDurationPrecipitationValue020           | Precip amount over 20-minute interval for the recorded maximum.                  | mm                  | [0,300.0]; scale 0.1                          |\n",
    "| ShortDurationPrecipitationValue030           | Precip amount over 30-minute interval for the recorded maximum.                  | mm                  | [0,300.0]; scale 0.1                          |\n",
    "| ShortDurationPrecipitationValue045           | Precip amount over 45-minute interval for the recorded maximum.                  | mm                  | [0,300.0]; scale 0.1                          |\n",
    "| ShortDurationPrecipitationValue060           | Precip amount over 60-minute interval for the recorded maximum.                  | mm                  | [0,300.0]; scale 0.1                          |\n",
    "| ShortDurationPrecipitationValue080           | Precip amount over 80-minute interval for the recorded maximum.                  | mm                  | [0,300.0]; scale 0.1                          |\n",
    "| ShortDurationPrecipitationValue100           | Precip amount over 100-minute interval for the recorded maximum.                 | mm                  | [0,300.0]; scale 0.1                          |\n",
    "| ShortDurationPrecipitationValue120           | Precip amount over 120-minute interval for the recorded maximum.                 | mm                  | [0,300.0]; scale 0.1                          |\n",
    "| ShortDurationPrecipitationValue150           | Precip amount over 150-minute interval for the recorded maximum.                 | mm                  | [0,300.0]; scale 0.1                          |\n",
    "| ShortDurationPrecipitationValue180           | Precip amount over 180-minute interval for the recorded maximum.                 | mm                  | [0,300.0]; scale 0.1                          |\n",
    "| REM                                          | Remarks for the record (flags/notes).                                            | text                | —                                             |\n",
    "| BackupDirection                              | Backup wind direction when primary sensor unavailable.                           | degrees (true)      | 1–360                                         |\n",
    "| BackupDistance                               | Distance associated with backup measurement.                                     | meters/feet         | >=0                                           |\n",
    "| BackupDistanceUnit                           | Unit for backup distance.                                                        | unit                | e.g., m/ft                                    |\n",
    "| BackupElements                               | List of elements provided by backup instrumentation.                             | text/code           | —                                             |\n",
    "| BackupElevation                              | Elevation of backup sensor/location.                                             | meters              | —                                             |\n",
    "| BackupEquipment                              | Identifier of backup instrument used.                                            | text/code           | —                                             |\n",
    "| BackupLatitude                               | Latitude of backup sensor/location.                                              | degrees             | [-90,90]                                      |\n",
    "| BackupLongitude                              | Longitude of backup sensor/location.                                             | degrees             | [-180,180]                                    |\n",
    "| BackupName                                   | Name/ID of backup station/location.                                              | text                | —                                             |\n",
    "| WindEquipmentChangeDate                      | Date of wind equipment change.                                                   | YYYY-MM-DD          | —                                             |\n",
    "| YEAR                                         | Calendar year of record.                                                         | YYYY                | 0000–9999                                     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "68fff477-f10b-4d1a-ace2-bb28abd8601d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Appendix B: Analysis of Null for FASW Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9abadcc4-4477-4566-9892-3d2800f22b46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "| column_name                           | null_count | null_percent           |\n",
    "|---------------------------------------|------------|-----------------------|\n",
    "| MonthlyAverageRH                      | 1401363    | 100                   |\n",
    "| MonthlyMeanTemperature                | 1401363    | 100                   |\n",
    "| ShortDurationEndDate120               | 1401363    | 100                   |\n",
    "| MonthlyMinSeaLevelPressureValue       | 1401363    | 100                   |\n",
    "| MonthlyDaysWithGT001Precip            | 1401363    | 100                   |\n",
    "| MonthlyMinSeaLevelPressureValueDate   | 1401363    | 100                   |\n",
    "| ShortDurationEndDate150               | 1401363    | 100                   |\n",
    "| MonthlyMinSeaLevelPressureValueTime   | 1401363    | 100                   |\n",
    "| MonthlyDaysWithGT010Precip            | 1401363    | 100                   |\n",
    "| MonthlyMinimumTemperature             | 1401363    | 100                   |\n",
    "| ShortDurationEndDate180               | 1401363    | 100                   |\n",
    "| MonthlySeaLevelPressure               | 1401363    | 100                   |\n",
    "| MonthlyDaysWithGT32Temp               | 1401363    | 100                   |\n",
    "| MonthlyStationPressure                | 1401363    | 100                   |\n",
    "| ShortDurationPrecipitationValue005    | 1401363    | 100                   |\n",
    "| MonthlyTotalLiquidPrecipitation       | 1401363    | 100                   |\n",
    "| MonthlyDaysWithGT90Temp               | 1401363    | 100                   |\n",
    "| MonthlyTotalSnowfall                  | 1401363    | 100                   |\n",
    "| ShortDurationPrecipitationValue010    | 1401363    | 100                   |\n",
    "| MonthlyWetBulb                        | 1401363    | 100                   |\n",
    "| MonthlyDaysWithLT0Temp                | 1401363    | 100                   |\n",
    "| AWND                                  | 1401363    | 100                   |\n",
    "| ShortDurationPrecipitationValue015    | 1401363    | 100                   |\n",
    "| CDSD                                  | 1401363    | 100                   |\n",
    "| MonthlyDaysWithLT32Temp               | 1401363    | 100                   |\n",
    "| CLDD                                  | 1401363    | 100                   |\n",
    "| ShortDurationPrecipitationValue020    | 1401363    | 100                   |\n",
    "| DSNW                                  | 1401363    | 100                   |\n",
    "| MonthlyDepartureFromNormalAverageTemperature | 1401363 | 100             |\n",
    "| HDSD                                  | 1401363    | 100                   |\n",
    "| ShortDurationPrecipitationValue030    | 1401363    | 100                   |\n",
    "| HTDD                                  | 1401363    | 100                   |\n",
    "| MonthlyDepartureFromNormalCoolingDegreeDays | 1401363 | 100             |\n",
    "| NormalsCoolingDegreeDay               | 1401363    | 100                   |\n",
    "| ShortDurationPrecipitationValue045    | 1401363    | 100                   |\n",
    "| NormalsHeatingDegreeDay               | 1401363    | 100                   |\n",
    "| MonthlyDepartureFromNormalHeatingDegreeDays | 1401363 | 100             |\n",
    "| ShortDurationEndDate005               | 1401363    | 100                   |\n",
    "| ShortDurationPrecipitationValue060    | 1401363    | 100                   |\n",
    "| ShortDurationEndDate010               | 1401363    | 100                   |\n",
    "| MonthlyDepartureFromNormalMaximumTemperature | 1401363 | 100             |\n",
    "| ShortDurationEndDate015               | 1401363    | 100                   |\n",
    "| ShortDurationPrecipitationValue080    | 1401363    | 100                   |\n",
    "| ShortDurationEndDate020               | 1401363    | 100                   |\n",
    "| MonthlyDepartureFromNormalMinimumTemperature | 1401363 | 100             |\n",
    "| ShortDurationEndDate030               | 1401363    | 100                   |\n",
    "| ShortDurationPrecipitationValue100    | 1401363    | 100                   |\n",
    "| ShortDurationEndDate045               | 1401363    | 100                   |\n",
    "| MonthlyDepartureFromNormalPrecipitation | 1401363  | 100                   |\n",
    "| ShortDurationEndDate060               | 1401363    | 100                   |\n",
    "| ShortDurationPrecipitationValue120    | 1401363    | 100                   |\n",
    "| ShortDurationEndDate080               | 1401363    | 100                   |\n",
    "| MonthlyDewpointTemperature            | 1401363    | 100                   |\n",
    "| ShortDurationEndDate100               | 1401363    | 100                   |\n",
    "| ShortDurationPrecipitationValue150    | 1401363    | 100                   |\n",
    "| MonthlyGreatestPrecip                 | 1401363    | 100                   |\n",
    "| ShortDurationPrecipitationValue180    | 1401363    | 100                   |\n",
    "| MonthlyGreatestPrecipDate             | 1401363    | 100                   |\n",
    "| MonthlyGreatestSnowDepth              | 1401363    | 100                   |\n",
    "| MonthlyGreatestSnowDepthDate          | 1401363    | 100                   |\n",
    "| MonthlyGreatestSnowfall               | 1401363    | 100                   |\n",
    "| MonthlyGreatestSnowfallDate           | 1401363    | 100                   |\n",
    "| MonthlyMaxSeaLevelPressureValue       | 1401363    | 100                   |\n",
    "| MonthlyMaxSeaLevelPressureValueDate   | 1401363    | 100                   |\n",
    "| MonthlyMaxSeaLevelPressureValueTime   | 1401363    | 100                   |\n",
    "| MonthlyMaximumTemperature             | 1401363    | 100                   |\n",
    "| DailyWeather                          | 1399830    | 99.89060650238375     |\n",
    "| DailyAverageSeaLevelPressure          | 1399299    | 99.85271482121335     |\n",
    "| DailyAverageDewPointTemperature       | 1399296    | 99.8525007439186      |\n",
    "| DailyAverageRelativeHumidity          | 1399296    | 99.8525007439186      |\n",
    "| DailyAverageWetBulbTemperature        | 1399296    | 99.8525007439186      |\n",
    "| DailySnowDepth                        | 1399190    | 99.84493667950417     |\n",
    "| DailySnowfall                         | 1399190    | 99.84493667950417     |\n",
    "| DailyDepartureFromNormalAverageTemperature | 1398104 | 99.76744069880537 |\n",
    "| DailyPeakWindDirection                | 1398102    | 99.76729798060889     |\n",
    "| DailyPeakWindSpeed                    | 1398101    | 99.76722662151063     |\n",
    "| Sunrise                               | 1398099    | 99.76708390331413     |\n",
    "| Sunset                                | 1398098    | 99.76701254421589     |\n",
    "| DailyAverageDryBulbTemperature        | 1398091    | 99.76651303052813     |\n",
    "| DailyCoolingDegreeDays                | 1398091    | 99.76651303052813     |\n",
    "| DailyHeatingDegreeDays                | 1398091    | 99.76651303052813     |\n",
    "| DailyMinimumDryBulbTemperature        | 1398091    | 99.76651303052813     |\n",
    "| DailySustainedWindDirection           | 1398090    | 99.76644167142989     |\n",
    "| DailyAverageStationPressure           | 1398090    | 99.76644167142989     |\n",
    "| DailySustainedWindSpeed               | 1398090    | 99.76644167142989     |\n",
    "| DailyAverageWindSpeed                 | 1398090    | 99.76644167142989     |\n",
    "| DailyMaximumDryBulbTemperature        | 1398090    | 99.76644167142989     |\n",
    "| DailyPrecipitation                    | 1398090    | 99.76644167142989     |\n",
    "| FIRST_DEP_TIME                        | 1392386    | 99.3594093750156      |\n",
    "| TOTAL_ADD_GTIME                       | 1392386    | 99.3594093750156      |\n",
    "| LONGEST_ADD_GTIME                     | 1392386    | 99.3594093750156      |\n",
    "| CANCELLATION_CODE                     | 1357914    | 96.89951854016411     |\n",
    "| HourlyWindGustSpeed                   | 1219336    | 87.01071742296607     |\n",
    "| HourlyPresentWeatherType              | 1192764    | 85.11456346428442     |\n",
    "| CARRIER_DELAY                         | 1115288    | 79.58594596831799     |\n",
    "| WEATHER_DELAY                         | 1115288    | 79.58594596831799     |\n",
    "| NAS_DELAY                             | 1115288    | 79.58594596831799     |\n",
    "| SECURITY_DELAY                        | 1115288    | 79.58594596831799     |\n",
    "| LATE_AIRCRAFT_DELAY                   | 1115288    | 79.58594596831799     |\n",
    "| BackupElevation                       | 1035303    | 73.87828849484394     |\n",
    "| BackupLatitude                        | 1017797    | 72.62907612089087     |\n",
    "| BackupLongitude                       | 1017797    | 72.62907612089087     |\n",
    "| HourlyPressureChange                  | 929956     | 66.36082157156996     |\n",
    "| HourlyPressureTendency                | 929956     | 66.36082157156996     |\n",
    "| BackupEquipment                       | 914022     | 65.22378570006487     |\n",
    "| BackupDirection                       | 898899     | 64.14462205723999     |\n",
    "| BackupDistance                        | 898899     | 64.14462205723999     |\n",
    "| BackupDistanceUnit                    | 898899     | 64.14462205723999     |\n",
    "| BackupElements                        | 861164     | 61.451886484800866    |\n",
    "| BackupName                            | 839997     | 59.94142845215693     |\n",
    "| WindEquipmentChangeDate               | 489423     | 34.92478394249027     |\n",
    "| HourlyPrecipitation                   | 159028     | 11.348094676397192    |\n",
    "| HourlySeaLevelPressure                | 153456     | 10.950481780951831    |\n",
    "| HourlyAltimeterSetting                | 63215      | 4.510965395832486     |\n",
    "| ARR_DELAY                             | 46601      | 3.325405337517831     |\n",
    "| ARR_DELAY_NEW                         | 46601      | 3.325405337517831     |\n",
    "| ARR_DEL15                             | 46601      | 3.325405337517831     |\n",
    "| ARR_DELAY_GROUP                       | 46601      | 3.325405337517831     |\n",
    "| ACTUAL_ELAPSED_TIME                   | 46601      | 3.325405337517831     |\n",
    "| AIR_TIME                              | 46601      | 3.325405337517831     |\n",
    "| WHEELS_ON                             | 44316      | 3.1623497980180724    |\n",
    "| TAXI_IN                               | 44316      | 3.1623497980180724    |\n",
    "| ARR_TIME                              | 44316      | 3.1623497980180724    |\n",
    "| TAXI_OUT                              | 43119      | 3.0769329574136037    |\n",
    "| WHEELS_OFF                            | 43119      | 3.0769329574136037    |\n",
    "| DEP_TIME                              | 42306      | 3.0189180105368845    |\n",
    "| DEP_DELAY                             | 42306      | 3.0189180105368845    |\n",
    "| DEP_DELAY_NEW                         | 42306      | 3.0189180105368845    |\n",
    "| DEP_DEL15                             | 42306      | 3.0189180105368845    |\n",
    "| DEP_DELAY_GROUP                       | 42306      | 3.0189180105368845    |\n",
    "| HourlySkyConditions                   | 32882      | 2.346429868635036     |\n",
    "| HourlyWetBulbTemperature              | 10258      | 0.732001629841804     |\n",
    "| HourlyStationPressure                 | 9624       | 0.6867599615517178    |\n",
    "| TAIL_NUM                              | 8187       | 0.5842169373674059    |\n",
    "| HourlyWindDirection                   | 6071       | 0.43322108547178717   |\n",
    "| HourlyRelativeHumidity                | 4721       | 0.3368863028351683    |\n",
    "| HourlyWindSpeed                       | 4646       | 0.33153437046646733   |\n",
    "| HourlyDewPointTemperature             | 4573       | 0.32632515629426495   |\n",
    "| HourlyDryBulbTemperature              | 4457       | 0.31804750089734063   |\n",
    "| HourlyVisibility                      | 4087       | 0.29164463454508216   |\n",
    "| REM                                   | 564        | 0.04024653141263185   |\n",
    "| CRS_ELAPSED_TIME                      | 2          | 0.0001427181964986945 |\n",
    "| YEAR                                  | 0          | 0                    |\n",
    "| QUARTER                               | 0          | 0                    |\n",
    "| MONTH                                 | 0          | 0                    |\n",
    "| dest_type                             | 0          | 0                    |\n",
    "| origin_airport_name                   | 0          | 0                    |\n",
    "| DAY_OF_MONTH                          | 0          | 0                    |\n",
    "| origin_station_name                   | 0          | 0                    |\n",
    "| _row_desc                             | 0          | 0                    |\n",
    "| origin_station_id                     | 0          | 0                    |\n",
    "| DAY_OF_WEEK                           | 0          | 0                    |\n",
    "| origin_iata_code                      | 0          | 0                    |\n",
    "| dest_region                           | 0          | 0                    |\n",
    "| origin_icao                           | 0          | 0                    |\n",
    "| FL_DATE                               | 0          | 0                    |\n",
    "| origin_type                           | 0          | 0                    |\n",
    "| CRS_DEP_TIME                          | 0          | 0                    |\n",
    "| origin_region                         | 0          | 0                    |\n",
    "| OP_UNIQUE_CARRIER                     | 0          | 0                    |\n",
    "| origin_station_lat                    | 0          | 0                    |\n",
    "| dest_station_lat                      | 0          | 0                    |\n",
    "| origin_station_lon                    | 0          | 0                    |\n",
    "| OP_CARRIER_AIRLINE_ID                 | 0          | 0                    |\n",
    "| origin_airport_lat                    | 0          | 0                    |\n",
    "| DEP_TIME_BLK                          | 0          | 0                    |\n",
    "| origin_airport_lon                    | 0          | 0                    |\n",
    "| OP_CARRIER                            | 0          | 0                    |\n",
    "| origin_station_dis                    | 0          | 0                    |\n",
    "| dest_station_lon                      | 0          | 0                    |\n",
    "| dest_airport_name                     | 0          | 0                    |\n",
    "| OP_CARRIER_FL_NUM                     | 0          | 0                    |\n",
    "| dest_station_name                     | 0          | 0                    |\n",
    "| CRS_ARR_TIME                          | 0          | 0                    |\n",
    "| dest_station_id                       | 0          | 0                    |\n",
    "| ORIGIN_AIRPORT_ID                     | 0          | 0                    |\n",
    "| dest_iata_code                        | 0          | 0                    |\n",
    "| dest_airport_lat                      | 0          | 0                    |\n",
    "| dest_icao                             | 0          | 0                    |\n",
    "| ORIGIN_AIRPORT_SEQ_ID                 | 0          | 0                    |\n",
    "| ARR_TIME_BLK                          | 0          | 0                    |\n",
    "| ORIGIN_CITY_MARKET_ID                 | 0          | 0                    |\n",
    "| dest_airport_lon                      | 0          | 0                    |\n",
    "| ORIGIN                                | 0          | 0                    |\n",
    "| CANCELLED                             | 0          | 0                    |\n",
    "| ORIGIN_CITY_NAME                      | 0          | 0                    |\n",
    "| dest_station_dis                      | 0          | 0                    |\n",
    "| ORIGIN_STATE_ABR                      | 0          | 0                    |\n",
    "| DIVERTED                              | 0          | 0                    |\n",
    "| ORIGIN_STATE_FIPS                     | 0          | 0                    |\n",
    "| sched_depart_date_time                | 0          | 0                    |\n",
    "| ORIGIN_STATE_NM                       | 0          | 0                    |\n",
    "| FLIGHTS                               | 0          | 0                    |\n",
    "| ORIGIN_WAC                            | 0          | 0                    |\n",
    "| sched_depart_date_time_UTC            | 0          | 0                    |\n",
    "| DEST_AIRPORT_ID                       | 0          | 0                    |\n",
    "| DISTANCE                              | 0          | 0                    |\n",
    "| DEST_AIRPORT_SEQ_ID                   | 0          | 0                    |\n",
    "| four_hours_prior_depart_UTC           | 0          | 0                    |\n",
    "| DEST_CITY_MARKET_ID                   | 0          | 0                    |\n",
    "| DISTANCE_GROUP                        | 0          | 0                    |\n",
    "| DEST                                  | 0          | 0                    |\n",
    "| two_hours_prior_depart_UTC            | 0          | 0                    |\n",
    "| DEST_CITY_NAME                        | 0          | 0                    |\n",
    "| STATION                               | 0          | 0                    |\n",
    "| DEST_STATE_ABR                        | 0          | 0                    |\n",
    "| DATE                                  | 0          | 0                    |\n",
    "| DEST_STATE_FIPS                       | 0          | 0                    |\n",
    "| LATITUDE                              | 0          | 0                    |\n",
    "| DEST_STATE_NM                         | 0          | 0                    |\n",
    "| LONGITUDE                             | 0          | 0                    |\n",
    "| DEST_WAC                              | 0          | 0                    |\n",
    "| ELEVATION                             | 0          | 0                    |\n",
    "| NAME                                  | 0          | 0                    |\n",
    "| REPORT_TYPE                           | 0          | 0                    |\n",
    "| SOURCE                                | 0          | 0                    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd03bf8c-50a0-4b65-8618-c79fa0ea064b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Appendix C: Features Families and Their Selected Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4bdee0ce-dcc3-4f16-9578-b090de0cc4c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "| Category                     | Features                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | Description                                                                                                                                                                                               |\n",
    "| ---------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Time-based**               | YEAR, QUARTER, MONTH, DAY_OF_MONTH, DAY_OF_WEEK, IS_US_HOLIDAY, CRS_DEP_TIME_BLOCK, CRS_DEP_DATETIME_UTC, CRS_ARR_TIME_BLOCK                                                                                                                                                                                                                                                                                                                                                                                                         | Captures when a flight occurs, allowing the model to learn seasonal, monthly, weekly, and hourly delay patterns. Time-of-day and holiday markers often correlate strongly with congestion and delay risk. |\n",
    "| **Flight**                   | OP_UNIQUE_CARRIER, TAIL_NUM, ORIGIN, ORIGIN_STATE_ABR, DEST, DEST_STATE_ABR, ARR_DEL15, CRS_ELAPSED_TIME, DISTANCE, ORIGIN_LAT, ORIGIN_LONG, ORIGIN_ELEVATION_FT, ORIGIN_SIZE, DEST_LAT, DEST_LON, DEST_ELEVATION_FT, DEST_SIZE, prev_flight_arr_delay_clean, actual_to_crs_time_to_next_flight_diff_mins_clean, crs_time_to_next_flight_diff_mins                                                                                                                    | These features describe the physical flight, carrier, and airport characteristics. They help the model learn patterns related to congestion, geography, aircraft turnaround cycles, and systemic delays.  |\n",
    "| **Weather**                  | overall_cloud_frac_0_1, lowest_cloud_ft, highest_cloud_ft, has_few, has_sct, has_bkn, has_ovc, HourlyAltimeterSetting, HourlyWindCardinalDirection, HourlyWindGustSpeed, HourlyWindSpeed, light, heavy, thunderstorm, rain_or_drizzle, freezing_conditions, snow, hail_or_ice, reduced_visibility, spatial_effects, unknown_precip                                                                                                                                                                                                   | Captures local meteorological conditions that influence airport and airspace operations. Weather is one of the strongest contributors to delay severity and variability.                                  |\n",
    "| **Graph Features**           | origin_pagerank, dest_pagerank, origin_out_degree, dest_in_degree                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | These quantify airport importance and connectivity within the national flight network. They help identify systemic bottlenecks and flow-through effects of delays.                                        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cdab7ee7-be77-4185-92a2-fc18aac9a110",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Appendix D: Selected Features for Logistic Regression (via Variance Inflation Factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e7ce63e-2c30-4d85-8f74-5cfce7f7cfd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "| Feature                  | VIF Score | Feature Family |\n",
    "|--------------------------|-----------|----------------|\n",
    "| OP_UNIQUE_CARRIER_idx    | 1.0892    | Flight         |\n",
    "| HourlySeaLevelPressure   | 3.2234    | Weather        |\n",
    "| HourlyWindDirection      | 1.1054    | Weather        |\n",
    "| ORIGIN_LONG              | 1.6490    | Flight         |\n",
    "| drizzle                  | 1.1493    | Weather        |\n",
    "| HourlyPressureChange     | 1.2281    | Weather        |\n",
    "| intensity_heavy          | 1.3146    | Weather        |\n",
    "| has_sct                  | 1.1361    | Weather        |\n",
    "| mist                     | 2.1971    | Weather        |\n",
    "| has_bkn                  | 2.2353    | Weather        |\n",
    "| DEST_LAT                 | 1.2903    | Flight         |\n",
    "| has_few                  | 1.1593    | Weather        |\n",
    "| squalls                  | 1.0062    | Weather        |\n",
    "| haze                     | 4.2923    | Weather        |\n",
    "| smoke                    | 4.2665    | Weather        |\n",
    "| HourlyPrecipitation      | 1.2770    | Weather        |\n",
    "| ORIGIN_LAT               | 1.3620    | Flight         |\n",
    "| has_ovc                  | 1.4556    | Weather        |\n",
    "| DEST_idx                 | 2.7530    | Flight         |\n",
    "| HourlyRelativeHumidity   | 1.6260    | Weather        |\n",
    "| DEST_SIZE_idx            | 2.4565    | Flight         |\n",
    "| is_us_holiday            | 1.5499    | Time-based     |\n",
    "| OP_CARRIER_FL_NUM        | 1.1917    | Flight         |\n",
    "| DEST_STATE_ABR_idx       | 1.4283    | Flight         |\n",
    "| ORIGIN_STATE_ABR_idx     | 1.4648    | Flight         |\n",
    "| desc_showers             | 1.3133    | Weather        |\n",
    "| rain                     | 3.1157    | Weather        |\n",
    "| ORIGIN_SIZE_idx          | 2.4545    | Flight         |\n",
    "| snow                     | 1.0901    | Weather        |\n",
    "| dust                     | 1.0041    | Weather        |\n",
    "| small_hail_graupel       | 1.1652    | Weather        |\n",
    "| CRS_ARR_TIME             | 1.6942    | Time-based     |\n",
    "| CRS_DEP_TIME             | 1.9485    | Time-based     |\n",
    "| desc_shallow             | 1.0015    | Weather        |\n",
    "| HourlyWindSpeed          | 1.1292    | Weather        |\n",
    "| DEST_LON                 | 1.5110    | Flight         |\n",
    "| fog                      | 1.2584    | Weather        |\n",
    "| ORIGIN_idx               | 2.8154    | Flight         |\n",
    "| HourlyVisibility         | 2.7723    | Weather        |\n",
    "| HourlyStationPressure    | 1.5241    | Weather        |\n",
    "| intensity_light          | 2.7773    | Weather        |\n",
    "| HourlyAltimeterSetting   | 3.1424    | Weather        |\n",
    "| Ceiling_ft_agl           | 2.1583    | Weather        |\n",
    "| HourlyPressureTendency   | 1.4396    | Weather        |\n",
    "| desc_patches             | 1.0958    | Weather        |\n",
    "| rain_showers             | 1.1461    | Weather        |\n",
    "| MONTH_cos                | 1.5792    | Time-based     |\n",
    "| DOW_sin                  | 1.0129    | Time-based     |\n",
    "| DOW_cos                  | 1.0255    | Time-based     |\n",
    "| MONTH_sin                | 1.0573    | Time-based     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72bcddc0-56f8-43de-8545-d03863c84e8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Appendix E: Mutual Independence Results for Features Selected for Logistic Regression\n",
    "\n",
    "| Feature                     | MI                     | Feature Family |\n",
    "|------------------------------|-----------------------|----------------|\n",
    "| CRS_DEP_TIME                 | 0.036607836400408766  | Time-based     |\n",
    "| CRS_ARR_TIME                 | 0.03596206133690227   | Time-based     |\n",
    "| OP_CARRIER_FL_NUM            | 0.02018135099260765   | Flight         |\n",
    "| HourlyRelativeHumidity       | 0.01799995948011257   | Weather        |\n",
    "| ORIGIN_LONG                  | 0.01163129744134328   | Flight         |\n",
    "| ORIGIN_idx                   | 0.010710873787992625  | Flight         |\n",
    "| ORIGIN_LAT                   | 0.010151557007437306  | Flight         |\n",
    "| ORIGIN_STATE_ABR_idx         | 0.009289709874593433  | Flight         |\n",
    "| HourlyAltimeterSetting       | 0.008335158560744516  | Weather        |\n",
    "| HourlyStationPressure        | 0.007790565419905082  | Weather        |\n",
    "| DEST_idx                     | 0.007687121130170782  | Flight         |\n",
    "| HourlySeaLevelPressure       | 0.007028691141545584  | Weather        |\n",
    "| has_ovc                      | 0.006619485348874576  | Weather        |\n",
    "| OP_UNIQUE_CARRIER_idx        | 0.006279085219459635  | Flight         |\n",
    "| mist                         | 0.0058320991531704    | Weather        |\n",
    "| HourlyVisibility             | 0.005341095049899547  | Weather        |\n",
    "| has_bkn                      | 0.005264489677138329  | Weather        |\n",
    "| DEST_LON                     | 0.0044212917003920715 | Flight         |\n",
    "| desc_patches                 | 0.004075731151856665  | Weather        |\n",
    "| rain_showers                 | 0.003473307301372408  | Weather        |\n",
    "| has_few                      | 0.0032912514192298126 | Weather        |\n",
    "| fog                          | 0.003254736679890735  | Weather        |\n",
    "| HourlyPressureChange         | 0.003119128575661101  | Weather        |\n",
    "| DEST_STATE_ABR_idx           | 0.0025849307760221762 | Flight         |\n",
    "| MONTH_sin                    | 0.0023191480322857227 | Time-based     |\n",
    "| desc_showers                 | 0.0022956417191386524 | Weather        |\n",
    "| DOW_cos                      | 0.0022519054962120144 | Time-based     |\n",
    "| DEST_SIZE_idx                | 0.002229856053145074  | Flight         |\n",
    "| smoke                        | 0.0015754195305257568 | Weather        |\n",
    "| rain                         | 0.0015656376195531951 | Weather        |\n",
    "| small_hail_graupel           | 0.001485099107554122  | Weather        |\n",
    "| is_us_holiday                | 0.0014683867433864517 | Time-based     |\n",
    "| has_sct                      | 0.0011921762599886865 | Weather        |\n",
    "| MONTH_cos                     | 0.0009078770869890285 | Time-based     |\n",
    "| DEST_LAT                     | 0.0007269299705585652 | Flight         |\n",
    "| haze                         | 0.0007146189308495643 | Weather        |\n",
    "| Ceiling_ft_agl               | 0.0005551163092007982 | Weather        |\n",
    "| HourlyPressureTendency       | 0.0004762849189530183 | Weather        |\n",
    "| DOW_sin                      | 0.0004254247622159646 | Time-based     |\n",
    "| squalls                      | 0.0004134265771051915 | Weather        |\n",
    "| HourlyWindDirection          | 0.00015919796674523923| Weather        |\n",
    "| drizzle                      | 0                     | Weather        |\n",
    "| HourlyPrecipitation          | 0                     | Weather        |\n",
    "| intensity_heavy              | 0                     | Weather        |\n",
    "| snow                         | 0                     | Weather        |\n",
    "| dust                         | 0                     | Weather        |\n",
    "| desc_shallow                 | 0                     | Weather        |\n",
    "| ORIGIN_SIZE_idx              | 0                     | Flight         |\n",
    "| intensity_light              | 0                     | Weather        |\n",
    "| HourlyWindSpeed              | 0                     | Weather        |\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Group 2_1 FP Phase 3 Project Plan",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}